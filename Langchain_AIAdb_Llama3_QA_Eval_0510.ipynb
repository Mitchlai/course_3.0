{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mitchlai/course_3.0/blob/main/Langchain_AIAdb_Llama3_QA_Eval_0510.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956ff3a4",
      "metadata": {
        "id": "956ff3a4"
      },
      "source": [
        "# Building AIA Chatbot by using retrieval augmented generation (RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step1 : 安裝相關套件"
      ],
      "metadata": {
        "id": "o_t8jTbWRds1"
      },
      "id": "o_t8jTbWRds1"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install langchain\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "UVpBQm34lbnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdce1c89-722c-490c-8614-95e70ba22d5c"
      },
      "id": "UVpBQm34lbnr",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.28.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.19)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.56)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.7.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.111.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.11.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.3)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.63.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.3)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.3.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.3)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (5.9.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (2.1.1)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi>=0.95.2->chromadb) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
        "# openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "#確認是否成功load api key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aoMYSx9vXyM4",
        "outputId": "7e19a708-8f9c-45d9-ec56-a0bb4d5db75b"
      },
      "id": "aoMYSx9vXyM4",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
              "  var reloading = false;\n",
              "  var Bokeh = root.Bokeh;\n",
              "\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks;\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "    if (js_modules == null) js_modules = [];\n",
              "    if (js_exports == null) js_exports = {};\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    if (!reloading) {\n",
              "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    }\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "    window._bokeh_on_load = on_load\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    var skip = [];\n",
              "    if (window.requirejs) {\n",
              "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
              "      require([\"jspanel\"], function(jsPanel) {\n",
              "\twindow.jsPanel = jsPanel\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-modal\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-tooltip\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-hint\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-layout\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-contextmenu\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-dock\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"gridstack\"], function(GridStack) {\n",
              "\twindow.GridStack = GridStack\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"notyf\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      root._bokeh_is_loading = css_urls.length + 9;\n",
              "    } else {\n",
              "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
              "    }\n",
              "\n",
              "    var existing_stylesheets = []\n",
              "    var links = document.getElementsByTagName('link')\n",
              "    for (var i = 0; i < links.length; i++) {\n",
              "      var link = links[i]\n",
              "      if (link.href != null) {\n",
              "\texisting_stylesheets.push(link.href)\n",
              "      }\n",
              "    }\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
              "\ton_load()\n",
              "\tcontinue;\n",
              "      }\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    var existing_scripts = []\n",
              "    var scripts = document.getElementsByTagName('script')\n",
              "    for (var i = 0; i < scripts.length; i++) {\n",
              "      var script = scripts[i]\n",
              "      if (script.src != null) {\n",
              "\texisting_scripts.push(script.src)\n",
              "      }\n",
              "    }\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
              "\tif (!window.requirejs) {\n",
              "\t  on_load();\n",
              "\t}\n",
              "\tcontinue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (var i = 0; i < js_modules.length; i++) {\n",
              "      var url = js_modules[i];\n",
              "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
              "\tif (!window.requirejs) {\n",
              "\t  on_load();\n",
              "\t}\n",
              "\tcontinue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (const name in js_exports) {\n",
              "      var url = js_exports[name];\n",
              "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
              "\tif (!window.requirejs) {\n",
              "\t  on_load();\n",
              "\t}\n",
              "\tcontinue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      element.textContent = `\n",
              "      import ${name} from \"${url}\"\n",
              "      window.${name} = ${name}\n",
              "      window._bokeh_on_load()\n",
              "      `\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    if (!js_urls.length && !js_modules.length) {\n",
              "      on_load()\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
              "  var js_modules = [];\n",
              "  var js_exports = {};\n",
              "  var css_urls = [];\n",
              "  var inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {} // ensure no trailing comma for IE\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "\ttry {\n",
              "          inline_js[i].call(root, root.Bokeh);\n",
              "\t} catch(e) {\n",
              "\t  if (!reloading) {\n",
              "\t    throw e;\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "      // Cache old bokeh versions\n",
              "      if (Bokeh != undefined && !reloading) {\n",
              "\tvar NewBokeh = root.Bokeh;\n",
              "\tif (Bokeh.versions === undefined) {\n",
              "\t  Bokeh.versions = new Map();\n",
              "\t}\n",
              "\tif (NewBokeh.version !== Bokeh.version) {\n",
              "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
              "\t}\n",
              "\troot.Bokeh = Bokeh;\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    }\n",
              "    root._bokeh_is_initializing = false\n",
              "  }\n",
              "\n",
              "  function load_or_wait() {\n",
              "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
              "    // versions of Bokeh and its dependencies at the same time.\n",
              "    // In recent versions we use the root._bokeh_is_initializing flag\n",
              "    // to determine whether there is an ongoing attempt to initialize\n",
              "    // bokeh, however for backward compatibility we also try to ensure\n",
              "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
              "    // before older versions are fully initialized.\n",
              "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
              "      root._bokeh_is_initializing = false;\n",
              "      root._bokeh_onload_callbacks = undefined;\n",
              "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
              "      load_or_wait();\n",
              "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
              "      setTimeout(load_or_wait, 100);\n",
              "    } else {\n",
              "      root._bokeh_is_initializing = true\n",
              "      root._bokeh_onload_callbacks = []\n",
              "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
              "      if (!reloading && !bokeh_loaded) {\n",
              "\troot.Bokeh = undefined;\n",
              "      }\n",
              "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
              "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "\trun_inline_js();\n",
              "      });\n",
              "    }\n",
              "  }\n",
              "  // Give older versions of the autoload script a head-start to ensure\n",
              "  // they initialize before we start loading newer version.\n",
              "  setTimeout(load_or_wait, 100)\n",
              "}(window));"
            ],
            "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/javascript": [
              "\n",
              "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
              "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
              "}\n",
              "\n",
              "\n",
              "    function JupyterCommManager() {\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
              "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        comm_manager.register_target(comm_id, function(comm) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        });\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        });\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
              "          var messages = comm.messages[Symbol.asyncIterator]();\n",
              "          function processIteratorResult(result) {\n",
              "            var message = result.value;\n",
              "            console.log(message)\n",
              "            var content = {data: message.data, comm_id};\n",
              "            var buffers = []\n",
              "            for (var buffer of message.buffers || []) {\n",
              "              buffers.push(new DataView(buffer))\n",
              "            }\n",
              "            var metadata = message.metadata || {};\n",
              "            var msg = {content, buffers, metadata}\n",
              "            msg_handler(msg);\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "          return messages.next().then(processIteratorResult);\n",
              "        })\n",
              "      }\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
              "      if (comm_id in window.PyViz.comms) {\n",
              "        return window.PyViz.comms[comm_id];\n",
              "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
              "        if (msg_handler) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        }\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
              "        comm.open();\n",
              "        if (msg_handler) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        }\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
              "        comm_promise.then((comm) => {\n",
              "          window.PyViz.comms[comm_id] = comm;\n",
              "          if (msg_handler) {\n",
              "            var messages = comm.messages[Symbol.asyncIterator]();\n",
              "            function processIteratorResult(result) {\n",
              "              var message = result.value;\n",
              "              var content = {data: message.data};\n",
              "              var metadata = message.metadata || {comm_id};\n",
              "              var msg = {content, metadata}\n",
              "              msg_handler(msg);\n",
              "              return messages.next().then(processIteratorResult);\n",
              "            }\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "        }) \n",
              "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
              "          return comm_promise.then((comm) => {\n",
              "            comm.send(data, metadata, buffers, disposeOnDone);\n",
              "          });\n",
              "        };\n",
              "        var comm = {\n",
              "          send: sendClosure\n",
              "        };\n",
              "      }\n",
              "      window.PyViz.comms[comm_id] = comm;\n",
              "      return comm;\n",
              "    }\n",
              "    window.PyViz.comm_manager = new JupyterCommManager();\n",
              "    \n",
              "\n",
              "\n",
              "var JS_MIME_TYPE = 'application/javascript';\n",
              "var HTML_MIME_TYPE = 'text/html';\n",
              "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
              "var CLASS_NAME = 'output';\n",
              "\n",
              "/**\n",
              " * Render data to the DOM node\n",
              " */\n",
              "function render(props, node) {\n",
              "  var div = document.createElement(\"div\");\n",
              "  var script = document.createElement(\"script\");\n",
              "  node.appendChild(div);\n",
              "  node.appendChild(script);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when a new output is added\n",
              " */\n",
              "function handle_add_output(event, handle) {\n",
              "  var output_area = handle.output_area;\n",
              "  var output = handle.output;\n",
              "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "    return\n",
              "  }\n",
              "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "  if (id !== undefined) {\n",
              "    var nchildren = toinsert.length;\n",
              "    var html_node = toinsert[nchildren-1].children[0];\n",
              "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var scripts = [];\n",
              "    var nodelist = html_node.querySelectorAll(\"script\");\n",
              "    for (var i in nodelist) {\n",
              "      if (nodelist.hasOwnProperty(i)) {\n",
              "        scripts.push(nodelist[i])\n",
              "      }\n",
              "    }\n",
              "\n",
              "    scripts.forEach( function (oldScript) {\n",
              "      var newScript = document.createElement(\"script\");\n",
              "      var attrs = [];\n",
              "      var nodemap = oldScript.attributes;\n",
              "      for (var j in nodemap) {\n",
              "        if (nodemap.hasOwnProperty(j)) {\n",
              "          attrs.push(nodemap[j])\n",
              "        }\n",
              "      }\n",
              "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
              "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
              "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
              "    });\n",
              "    if (JS_MIME_TYPE in output.data) {\n",
              "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
              "    }\n",
              "    output_area._hv_plot_id = id;\n",
              "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
              "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
              "    } else {\n",
              "      window.PyViz.plot_index[id] = null;\n",
              "    }\n",
              "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "    var bk_div = document.createElement(\"div\");\n",
              "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var script_attrs = bk_div.children[0].attributes;\n",
              "    for (var i = 0; i < script_attrs.length; i++) {\n",
              "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "    }\n",
              "    // store reference to server id on output_area\n",
              "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when an output is cleared or removed\n",
              " */\n",
              "function handle_clear_output(event, handle) {\n",
              "  var id = handle.cell.output_area._hv_plot_id;\n",
              "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
              "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
              "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
              "  if (server_id !== null) {\n",
              "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
              "    return;\n",
              "  } else if (comm !== null) {\n",
              "    comm.send({event_type: 'delete', 'id': id});\n",
              "  }\n",
              "  delete PyViz.plot_index[id];\n",
              "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
              "    var doc = window.Bokeh.index[id].model.document\n",
              "    doc.clear();\n",
              "    const i = window.Bokeh.documents.indexOf(doc);\n",
              "    if (i > -1) {\n",
              "      window.Bokeh.documents.splice(i, 1);\n",
              "    }\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle kernel restart event\n",
              " */\n",
              "function handle_kernel_cleanup(event, handle) {\n",
              "  delete PyViz.comms[\"hv-extension-comm\"];\n",
              "  window.PyViz.plot_index = {}\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle update_display_data messages\n",
              " */\n",
              "function handle_update_output(event, handle) {\n",
              "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
              "  handle_add_output(event, handle)\n",
              "}\n",
              "\n",
              "function register_renderer(events, OutputArea) {\n",
              "  function append_mime(data, metadata, element) {\n",
              "    // create a DOM node to render to\n",
              "    var toinsert = this.create_output_subarea(\n",
              "    metadata,\n",
              "    CLASS_NAME,\n",
              "    EXEC_MIME_TYPE\n",
              "    );\n",
              "    this.keyboard_manager.register_events(toinsert);\n",
              "    // Render to node\n",
              "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "    render(props, toinsert[0]);\n",
              "    element.append(toinsert);\n",
              "    return toinsert\n",
              "  }\n",
              "\n",
              "  events.on('output_added.OutputArea', handle_add_output);\n",
              "  events.on('output_updated.OutputArea', handle_update_output);\n",
              "  events.on('clear_output.CodeCell', handle_clear_output);\n",
              "  events.on('delete.Cell', handle_clear_output);\n",
              "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
              "\n",
              "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "    safe: true,\n",
              "    index: 0\n",
              "  });\n",
              "}\n",
              "\n",
              "if (window.Jupyter !== undefined) {\n",
              "  try {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  } catch(err) {\n",
              "  }\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='0eb67b95-ac32-4fba-baaf-ac3444668f29'>\n",
              "  <div id=\"ebc219e3-854d-4049-a08d-b6967d748063\" data-root-id=\"0eb67b95-ac32-4fba-baaf-ac3444668f29\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"54d96e7f-5ef7-4db8-a8eb-c413a9227ae9\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"0eb67b95-ac32-4fba-baaf-ac3444668f29\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"767d6678-fbbc-45b6-9fcf-e4180469d6e2\",\"attributes\":{\"plot_id\":\"0eb67b95-ac32-4fba-baaf-ac3444668f29\",\"comm_id\":\"6c78d05efd90426d959515c29aad5705\",\"client_comm_id\":\"364b12da8d714b92ba997801ed2ed4b8\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"54d96e7f-5ef7-4db8-a8eb-c413a9227ae9\",\"roots\":{\"0eb67b95-ac32-4fba-baaf-ac3444668f29\":\"ebc219e3-854d-4049-a08d-b6967d748063\"},\"root_ids\":[\"0eb67b95-ac32-4fba-baaf-ac3444668f29\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ],
            "application/vnd.holoviews_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "0eb67b95-ac32-4fba-baaf-ac3444668f29"
            }
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "_ASGLNkSZCvE"
      },
      "id": "_ASGLNkSZCvE",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step2 : 建立多種Emmbedings model"
      ],
      "metadata": {
        "id": "Kiz6QzcXdbn8"
      },
      "id": "Kiz6QzcXdbn8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、nomic-embed-text-v1.5"
      ],
      "metadata": {
        "id": "AXP8zgDMtz5l"
      },
      "id": "AXP8zgDMtz5l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "確保有跟PrimeHub vectorDB使用的模型一致：nomic-embed-text-v1.5"
      ],
      "metadata": {
        "id": "0QJRmQ6TsBW7"
      },
      "id": "0QJRmQ6TsBW7"
    },
    {
      "cell_type": "code",
      "source": [
        "# install package\n",
        "!pip install -U langchain-nomic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMMicHriS1PA",
        "outputId": "d3eb1e6a-115c-4828-bd26-7b25a2a61dcb"
      },
      "id": "RMMicHriS1PA",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-nomic in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain-nomic) (0.1.52)\n",
            "Requirement already satisfied: nomic<4.0.0,>=3.0.12 in /usr/local/lib/python3.10/dist-packages (from langchain-nomic) (3.0.27)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (8.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.1.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (4.0.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (0.7.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (13.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (4.66.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (14.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (9.4.0)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-nomic) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-nomic) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-nomic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-nomic) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-nomic) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.12->langchain-nomic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.12->langchain-nomic) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.12->langchain-nomic) (2024.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->nomic<4.0.0,>=3.0.12->langchain-nomic) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nomic embdding 服務需要先申請 api key: https://atlas.nomic.ai\n",
        "from langchain_nomic.embeddings import NomicEmbeddings\n",
        "os.environ['NOMIC_API_KEY'] = 'nk-BCjzlgQXfYdZNA6kUZ-6Jeq1NIG2JhlQJaTe9BedpDc'\n",
        "embedding = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")"
      ],
      "metadata": {
        "id": "RwIlTKYqWcHf"
      },
      "id": "RwIlTKYqWcHf",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#確認embedding model版本='nomic.embeddings\n",
        "print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFUJ4BCBTij7",
        "outputId": "8a3f692b-2c9f-43e7-c1b8-58f19b346aa0"
      },
      "id": "HFUJ4BCBTij7",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain_nomic.embeddings.NomicEmbeddings object at 0x7e88cb00c820>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#查看該文字轉換後的向量\n",
        "# doc_result = embedding.embed_documents([text]) 查看完整多維度向量\n",
        "text = \"This is a test document.\"\n",
        "query_result = embedding.embed_query(text)\n",
        "query_result[:3] #確認文字已經可以轉為向量"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qWpJKp4eBzm",
        "outputId": "f40d8acf-1d86-4dd6-d981-47513b69a1aa"
      },
      "id": "3qWpJKp4eBzm",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.045318604, 0.038726807, -0.20007324]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step3 : 建立向量資料庫"
      ],
      "metadata": {
        "id": "RcijGleDVhze"
      },
      "id": "RcijGleDVhze"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 連線至本地端PrimeHub vectorDB"
      ],
      "metadata": {
        "id": "3oQj3qj0bkDR"
      },
      "id": "3oQj3qj0bkDR"
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from langchain.vectorstores import Chroma\n",
        "# 連線設定\n",
        "httpClient = chromadb.HttpClient(\n",
        "  host='64.176.47.89', port=8000,\n",
        "  settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic_authn.BasicAuthClientProvider\",chroma_client_auth_credentials=\"admin:admin\")\n",
        "  )\n",
        "\n",
        "# collections = httpClient.list_collections() #資料庫列表\n",
        "#httpClient.delete_collection(name=\"xt131028\") #刪除資料庫\n",
        "#collection = httpClient.create_collection(\"xt131028\") #可創建個人資料庫\n",
        "\n",
        "# tell LangChain to use our client and collection name\n",
        "db = Chroma(\n",
        "    client=httpClient,\n",
        "    collection_name=\"xt131028_v1\",\n",
        "    embedding_function=embedding,\n",
        ")\n",
        "# db.get() #查看所有資料"
      ],
      "metadata": {
        "id": "CvC6npWwbsn8"
      },
      "id": "CvC6npWwbsn8",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#查詢AIA本地端db\n",
        "# query = \"大型語言模型實作\"\n",
        "query = \"技術領袖培訓全域班\"\n",
        "documents = db.similarity_search(query)\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgMlsOZ4c5_S",
        "outputId": "1bfc60eb-8bc5-4824-fb5f-8b1b2625b983"
      },
      "id": "tgMlsOZ4c5_S",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='常見問題: 申請退費\\n回答: 親愛的學員你好，很遺憾你無法與我們一起為接下來的課程努力。\\n退費的標準，我們會依照學員手冊退費辦法辦理。\\n此外，請將學員證與發票退回至行政人員，也請告知匯款帳戶，以利我們作業。', metadata={'row': 12, 'source': 'QA_課中.csv'}),\n",
              " Document(page_content='RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 日， 8 月 17 日 ， 8 月 24 日 每週六，共 4 週。上課方式實體課程，上課時間為 9:00 - 17:30 ( 提供午餐 ) ，4週共 30小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain', metadata={'class_name': '大型語言模型實作進階班 (第四期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw/'}),\n",
              " Document(page_content='AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程成果圖：學員專題成果，地端檢索增強生成 (Retrieval-Augmented Generation, RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10', metadata={'class_name': '大型語言模型實作進階班 (第四期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw/'}),\n",
              " Document(page_content='日 週六 14:00~15:10 ( 2023/12/15 至 2024/01/04 當天報名者 )考試內容：以程式設計為主，希望確認應試者的程式設計能力，以Python作為作答的程式語言。考試的形式包括選擇題與程式撰寫。更多考試須知請點這裏第一次入學考未通過的考生，我們將主動通知您再參加第二梯次入學考試。錄取通知：(以電子郵件與簡訊寄發)第一梯次考試於 2023 年 12 月 20 日 週三 17:00 後寄發錄取通知第二梯次考試於 2024 年 01 月 10 日 週三 17:00', metadata={'class_name': '技術領袖培訓全域班第四期招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-tech-all4-tw/'})]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 查詢向量資料庫的三種方式"
      ],
      "metadata": {
        "id": "ng_DUmw1kJBR"
      },
      "id": "ng_DUmw1kJBR"
    },
    {
      "cell_type": "code",
      "source": [
        "#以字串查詢vectordb，回傳page_content內的資料\n",
        "# question = \"大型語言模型實作\"\n",
        "question = \"技術領袖培訓全域班\"\n",
        "embedding_vector=embedding.embed_query(question)\n",
        "research=db.similarity_search(question,k=3)\n",
        "print(research[0].page_content)\n",
        "print(research[1].page_content)\n",
        "print(research[2].page_content)"
      ],
      "metadata": {
        "id": "nkY2MkEZgSkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641e7ecf-e3bf-4b02-8179-65430eb1009a"
      },
      "id": "nkY2MkEZgSkX",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "常見問題: 申請退費\n",
            "回答: 親愛的學員你好，很遺憾你無法與我們一起為接下來的課程努力。\n",
            "退費的標準，我們會依照學員手冊退費辦法辦理。\n",
            "此外，請將學員證與發票退回至行政人員，也請告知匯款帳戶，以利我們作業。\n",
            "RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 日， 8 月 17 日 ， 8 月 24 日 每週六，共 4 週。上課方式實體課程，上課時間為 9:00 - 17:30 ( 提供午餐 ) ，4週共 30小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain\n",
            "AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程成果圖：學員專題成果，地端檢索增強生成 (Retrieval-Augmented Generation, RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b7a409bf",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "b7a409bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb393ad-7d00-4a1e-e2d3-90b2a9c63772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "常見問題: 申請退費\n",
            "回答: 親愛的學員你好，很遺憾你無法與我們一起為接下來的課程努力。\n",
            "退費的標準，我們會依照學員手冊退費辦法辦理。\n",
            "此外，請將學員證與發票退回至行政人員，也請告知匯款帳戶，以利我們作業。\n",
            "RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 日， 8 月 17 日 ， 8 月 24 日 每週六，共 4 週。上課方式實體課程，上課時間為 9:00 - 17:30 ( 提供午餐 ) ，4週共 30小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain\n",
            "AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程成果圖：學員專題成果，地端檢索增強生成 (Retrieval-Augmented Generation, RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10\n"
          ]
        }
      ],
      "source": [
        "#將問題變為向量，以向量去查詢vectordb，回傳page_content內的資料\n",
        "embedding_vector=embedding.embed_query(question)\n",
        "research = db.similarity_search_by_vector(embedding_vector,k=3)\n",
        "print(research[0].page_content)\n",
        "print(research[1].page_content)\n",
        "print(research[2].page_content)\n",
        "# len(research)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#以向量相似度（距離）去查詢vectordb，回傳page_content內的資料\n",
        "research = db.similarity_search_with_score(question,k=3)\n",
        "for research in research:\n",
        "  print(research[0].page_content,research[1])"
      ],
      "metadata": {
        "id": "C-upOYOFi5Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77dcb38-6922-4af0-fb4d-7d39ea92ef4e"
      },
      "id": "C-upOYOFi5Rq",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "常見問題: 申請退費\n",
            "回答: 親愛的學員你好，很遺憾你無法與我們一起為接下來的課程努力。\n",
            "退費的標準，我們會依照學員手冊退費辦法辦理。\n",
            "此外，請將學員證與發票退回至行政人員，也請告知匯款帳戶，以利我們作業。 0.5076097846031189\n",
            "RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 日， 8 月 17 日 ， 8 月 24 日 每週六，共 4 週。上課方式實體課程，上課時間為 9:00 - 17:30 ( 提供午餐 ) ，4週共 30小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain 0.5420759916305542\n",
            "AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程成果圖：學員專題成果，地端檢索增強生成 (Retrieval-Augmented Generation, RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 0.5507479906082153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step4 : 建立多個LLM Model進行比較\n"
      ],
      "metadata": {
        "id": "kBdzn9GgWBBJ"
      },
      "id": "kBdzn9GgWBBJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、Call Groq_Llama3_8B"
      ],
      "metadata": {
        "id": "V5JHMCDtsG6b"
      },
      "id": "V5JHMCDtsG6b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ULaDQStjxt3",
        "outputId": "74abee3b-2fbd-46b1-e170-2375b892fcea"
      },
      "id": "3ULaDQStjxt3",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.5.0)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.45 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.1.52)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (8.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain-groq) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_Groq_llama3 = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"llama3-8b-8192\")\n",
        "#MODEL_NAME = \"llama3-70b-8192\" or \"llama3-8b-8192\"\n",
        "# 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\n",
        "# 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\n",
        "\n",
        "system = \"You are a helpful assistant.\"\n",
        "human = \"{text}\"\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
        "\n",
        "chain = prompt | llm_Groq_llama3\n",
        "chain.invoke({\"text\": \"什麼是大型語言模型？使用正體中文回答\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9iPwsSdsHon",
        "outputId": "0f2690f3-fc39-4014-e892-a948cde59206"
      },
      "id": "x9iPwsSdsHon",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='😊\\n\\n大型語言模型（Large Language Model，LLM）是一種使用深度學習技術訓練的語言模型，它可以處理和生成大量的自然語言文本。這種模型通常是基於神經網路架構，使用大量的文本資料進行訓練，以學習文本的語義、語法和語言特徵。\\n\\n大型語言模型的特點包括：\\n\\n1. 巨大規模：這些模型通常需要訓練數十億到數百億個參數，以捕捉文本的複雜性和多樣性。\\n2. 自然語言處理：這些模型可以處理和生成自然語言文本，包括文本的生成、文本的理解和文本的翻譯等。\\n3. 深度學習：這些模型使用深度學習技術，例如卷積神經網路（CNN）和循環神經網路（RNN），以學習文本的語義和語法。\\n4. 高度自適性：這些模型可以根據文本的上下文和語境進行自適性處理，例如實現文本的生成和理解。\\n\\n大型語言模型的應用包括：\\n\\n1. 自然語言處理：這些模型可以應用於文本的生成、文本的理解和文本的翻譯等。\\n2.  chatbot 和客服系統：這些模型可以應用於客服系統和chatbot中，以提供更好的客戶服務。\\n3. 文本分析和挖掘：這些模型可以應用於文本分析和挖掘，以發掘文本中的隱藏信息和趨勢。\\n\\n總之，大型語言模型是一種強大的工具，可以幫助我們更好地理解和處理自然語言文本，並應用於各種領域中。', response_metadata={'token_usage': {'completion_time': 0.528, 'completion_tokens': 425, 'prompt_time': 0.022, 'prompt_tokens': 35, 'queue_time': None, 'total_time': 0.55, 'total_tokens': 460}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_873a560973', 'finish_reason': 'stop', 'logprobs': None}, id='run-5ff5d0c4-b2ca-4785-a998-fbe2c92d01a2-0')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、Call PrimeHub_Llama3_8B"
      ],
      "metadata": {
        "id": "f49K06XkWi_J"
      },
      "id": "f49K06XkWi_J"
    },
    {
      "cell_type": "code",
      "source": [
        "#透過langchain 建立後續要使用的 LLM model\n",
        "!pip install -q langchain-community\n",
        "!pip install -q langchain\n",
        "!pip install -q requests\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_community.llms import Ollama"
      ],
      "metadata": {
        "id": "1oW7DQ1vWvHx"
      },
      "id": "1oW7DQ1vWvHx",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#測試該url是否可以正常訪問\n",
        "import requests\n",
        "\n",
        "url = \"https://75a8-140-109-17-42.ngrok-free.app\" #http://3ece-140-109-17-42.ngrok-free.app/\n",
        "\n",
        "try:\n",
        "    requests.get(url)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"Invalid URL: {e}\")"
      ],
      "metadata": {
        "id": "xaE-MSeJfgdd"
      },
      "id": "xaE-MSeJfgdd",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_primehub_llama3 = Ollama(model=\"llama3\", base_url=\"http://3ece-140-109-17-42.ngrok-free.app\") #http://3ece-140-109-17-42.ngrok-free.app\n",
        "llm_primehub_llama3.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w8y5Lvk2WsoM",
        "outputId": "baf045fd-f03c-460b-b6ca-0301d017ce7b"
      },
      "id": "w8y5Lvk2WsoM",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why couldn\\'t the bicycle stand up by itself?\\n\\nBecause it was two-tired!\\n\\n(Sorry, I know it\\'s a bit of a \"dad\" joke, but I hope it brought a smile to your face!)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step5 : 建立多種retriever進行比較"
      ],
      "metadata": {
        "id": "Dw7ZKKY6QyxX"
      },
      "id": "Dw7ZKKY6QyxX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for printing docs\n",
        "def pretty_print_docs(docs):\n",
        "    print(\n",
        "        f\"\\n{'-' * 100}\\n\".join(\n",
        "            [\n",
        "                f\"Document {i+1}:\\n\\n\"\n",
        "                + f\"Content:\\n{d.page_content}\\n\\n\"\n",
        "                + f\"Metadata:\\n{d.metadata}\\n\"\n",
        "                for i, d in enumerate(docs)\n",
        "            ]\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "WIJ3nytJd7Fm"
      },
      "id": "WIJ3nytJd7Fm",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  lark langchain-chroma"
      ],
      "metadata": {
        "id": "yagp0dwk8ZFX"
      },
      "id": "yagp0dwk8ZFX",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、Vector store-backed retriever\n",
        "\n"
      ],
      "metadata": {
        "id": "gzetZ55HT9I_"
      },
      "id": "gzetZ55HT9I_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "最基本的是Vector store-backed retriever ，使用向量存儲實現的搜索方法（如相似性搜索和MMR）來查詢向量存儲中的文字。参数都是与检索过程相关的"
      ],
      "metadata": {
        "id": "K2v_zOmeUDj_"
      },
      "id": "K2v_zOmeUDj_"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 設定返回最相關的3個結果,啟用reduce_op_recursive模式,並啟用搜索質量反射\n",
        "retriever = db.as_retriever(search_kwargs={\"fetch_k\": 10, #使用MMR 設定最多检索10个相关文档\n",
        "                                           \"k\": 3, #並且返回3个最相关和最多样化的文档\n",
        "                                           \"mmr_score_cache\": True, #启用MMR分数缓存\n",
        "                                           \"mmr_rerank_top_k\": 30},#从相似度排序的前30个结果中选择候选文档进行MMR重新排序\n",
        "                            retriever_mode=\"reduce_op_recursive\",#启用reduce_op_recursive检索模式\n",
        "                            #search_quality_reflection=True, #检索器在返回结果时会包含一个额外的search_quality_reflection字段,其中包含一个0到1之间的分数,表示检索质量的评估。分数越高,表示检索结果越能很好地回答查询。\n",
        "                            # search_type 二擇一\n",
        "                            # search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5} #以向量相似度（距離）去查詢vectordb，僅返回分數高於該閾值的文檔\n",
        "                            search_type=\"mmr\")     #使用MMR搜索策略\n",
        "\n",
        "docs = retriever.invoke(\"大型語言模型實作進階班\")\n",
        "# len(docs)\n",
        "\n",
        "pretty_print_docs(docs)\n",
        "\n",
        "# print(docs[0].metadata)\n",
        "# print(docs[1].metadata)\n",
        "# print(docs[2].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIR4QgwIstDy",
        "outputId": "af79e92f-011d-4502-fa34-8ff1c283cd95"
      },
      "id": "oIR4QgwIstDy",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Content:\n",
            "大型語言模型實作初階班 (第三期)\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作初階班 (第三期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llma-tw3/'}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Content:\n",
            "大型語言模型實作進階班 (第二期) 招生簡章🚀透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。💪👍🤝課程大綱立即報名課程簡介基於上百家企業需求想要用大型語言模型建置企業內部的「企業大腦」，因各企業的資料有機敏性與獨特性，無法使用公開的大型語言模型。此外微調及部署大型語言模型服務有一定的門檻在，不論是在設備上、資料處理上、技術上等。台灣人工智慧學校深知大型語言模型在當今 AI\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "Content:\n",
            "大課程主題與方法：理解大型語言模型微調大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程效益能創建企業聊天機器人：設計和開發能夠理解並回應企業內部查詢的聊天機器人。實現機器人與公司數據庫的集成，以提供實時的查詢回應。進行機器人效能測試並根據反饋進行優化。能可微調開源大型語言模型：選擇適合的開源大型語言模型並進行微調，以符合公司特定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關數據集。評估微調後的大型語言模型效\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、Contextual compression retriever\n"
      ],
      "metadata": {
        "id": "02jYFZWXXThs"
      },
      "id": "02jYFZWXXThs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "檢索的一個挑戰是，通常您不知道將數據攝取到系統中時文檔存儲系統將面臨的特定查詢。這意味著與查詢最相關的資訊可能隱藏在包含大量不相關文本的文件中。通過應用程式傳遞完整文檔可能會導致更昂貴的LLM呼叫和更差的回應。\n",
        "\n",
        "上下文壓縮旨在解決此問題。這個想法很簡單：您可以使用給定查詢的上下文壓縮它們，以便僅返回相關信息，而不是立即按原樣返回檢索到的文檔。這裡的「壓縮」是指壓縮單個文件的內容和過濾掉整個文件。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "使用上下文壓縮器，以下LLMChainExtractor 和 LLMChainFilter 二擇一"
      ],
      "metadata": {
        "id": "RhTZ1y0tn-o5"
      },
      "id": "RhTZ1y0tn-o5"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.retrievers.document_compressors import LLMChainFilter"
      ],
      "metadata": {
        "id": "iTQPIBFMoLcd"
      },
      "id": "iTQPIBFMoLcd",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1 LLMChainExtractor"
      ],
      "metadata": {
        "id": "VslumTCSpyz1"
      },
      "id": "VslumTCSpyz1"
    },
    {
      "cell_type": "code",
      "source": [
        "#選擇要使用的LLM\n",
        "# llm = llm_primehub_llama3\n",
        "llm = llm_Groq_llama3\n",
        "\n",
        "#添加一個 LLMChainExtractor ，它將遍歷最初返回的文檔，並僅從每個文檔中提取與查詢相關的內容。\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever_1 = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever_1.invoke(\"摘要大型語言模型實作進階班的內容\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aKLBmZrUgjx",
        "outputId": "420697fd-8faa-4bdf-bbe8-f84e0bd03ed2"
      },
      "id": "3aKLBmZrUgjx",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Content:\n",
            "Extracted relevant parts:\n",
            "\n",
            "大型語言模型實作初階班 (第三期)\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作初階班 (第三期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llma-tw3/'}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Content:\n",
            ">>>\n",
            "大型語言模型實作進階班 (第二期) 招生簡章🚀透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。💪👍🤝課程大綱立即報名課程簡介基於上百家企業需求想要用大型語言模型建置企業內部的「企業大腦」，因各企業的資料有機敏性與獨特性，無法使用公開的大型語言模型。此外微調及部署大型語言模型服務有一定的門檻在，不論是在設備上、資料處理上、技術上等。台灣人工智慧學校深知大型語言模型在當今 AI\n",
            ">>>\n",
            "\n",
            "Note: The extracted parts are the original text as-is, without any editing.\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "Content:\n",
            ">>>\n",
            "大課程主題與方法：理解大型語言模型微調大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。\n",
            "主題性的專題實作，培養專案實作的能力。\n",
            "課程效益能創建企業聊天機器人：設計和開發能夠理解並回應企業內部查詢的聊天機器人。\n",
            "實現機器人與公司數據庫的集成，以提供實時的查詢回應。\n",
            "進行機器人效能測試並根據反饋進行優化。\n",
            "能可微調開源大型語言模型：選擇適合的開源大型語言模型並進行微調，以符合公司特定的需求和應用場景。\n",
            "收集和整理適用於微調開源大型語言模型的業務相關數據集。\n",
            "評估微調後的大型語言模型效\n",
            ">>>\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2 LLMChainFilter"
      ],
      "metadata": {
        "id": "4ZjdRShfp3kT"
      },
      "id": "4ZjdRShfp3kT"
    },
    {
      "cell_type": "code",
      "source": [
        "#選擇要使用的LLM\n",
        "# llm = llm_primehub_llama3\n",
        "llm = llm_Groq_llama3\n",
        "\n",
        "#添加一個 LLMChainFilter，該壓縮器稍微簡單一些，但更強大，它使用LLM鏈來決定要過濾掉哪些最初檢索的文檔以及要返回哪些文檔，而無需操作文檔內容。\n",
        "_filter = LLMChainFilter.from_llm(llm)\n",
        "compression_retriever_2 = ContextualCompressionRetriever(\n",
        "    base_compressor=_filter, base_retriever=retriever\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever_2.invoke(\"摘要大型語言模型實作進階班的內容\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ-L7qhqn41P",
        "outputId": "ae98e446-6a37-42ea-bee1-2480c8a6191f"
      },
      "id": "QJ-L7qhqn41P",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Content:\n",
            "大型語言模型實作初階班 (第三期)\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作初階班 (第三期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llma-tw3/'}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Content:\n",
            "大型語言模型實作進階班 (第二期) 招生簡章🚀透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。💪👍🤝課程大綱立即報名課程簡介基於上百家企業需求想要用大型語言模型建置企業內部的「企業大腦」，因各企業的資料有機敏性與獨特性，無法使用公開的大型語言模型。此外微調及部署大型語言模型服務有一定的門檻在，不論是在設備上、資料處理上、技術上等。台灣人工智慧學校深知大型語言模型在當今 AI\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "Content:\n",
            "大課程主題與方法：理解大型語言模型微調大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程效益能創建企業聊天機器人：設計和開發能夠理解並回應企業內部查詢的聊天機器人。實現機器人與公司數據庫的集成，以提供實時的查詢回應。進行機器人效能測試並根據反饋進行優化。能可微調開源大型語言模型：選擇適合的開源大型語言模型並進行微調，以符合公司特定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關數據集。評估微調後的大型語言模型效\n",
            "\n",
            "Metadata:\n",
            "{'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、MultiQueryRetriever\n",
        "using an LLM to generate multiple queries from different perspectives for a given user input query.\n",
        "\n",
        "通過 MultiQueryRetriever 給定的使用者輸入查詢，由LLM從不同角度生成多個查詢，自動執行提示調整過程。對於每個查詢，它都會檢索一組相關文檔，並在所有查詢中採用唯一的聯合，以獲得更大的潛在相關文檔集。通過對同一問題生成多個視角， MultiQueryRetriever 可能能夠克服基於距離的檢索的一些局限性，並獲得更豐富的結果集。"
      ],
      "metadata": {
        "id": "CcTYOCVJ-JLX"
      },
      "id": "CcTYOCVJ-JLX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/MultiQueryRetriever/"
      ],
      "metadata": {
        "id": "fT_nrDJ-O48P"
      },
      "id": "fT_nrDJ-O48P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1 MultiQuery_retriever_from_llm_1"
      ],
      "metadata": {
        "id": "_28arKGcOMvl"
      },
      "id": "_28arKGcOMvl"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "question = \"What are the approaches to Task Decomposition?\"\n",
        "llm = llm_Groq_llama3\n",
        "MultiQuery_retriever_from_llm_1 = MultiQueryRetriever.from_llm(\n",
        "    retriever=db.as_retriever(), llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "xbtt7vn0-get"
      },
      "id": "xbtt7vn0-get",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set logging for the queries\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "iXeyYVeq-NYd"
      },
      "id": "iXeyYVeq-NYd",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_docs = MultiQuery_retriever_from_llm_1.invoke(question)\n",
        "len(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow89AcMc_iZy",
        "outputId": "4467916b-f426-41a5-93db-8a64bc679926"
      },
      "id": "Ow89AcMc_iZy",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three alternative versions of the original question:', '', 'What are the strategies for breaking down complex tasks into manageable sub-tasks?', '', 'What are the methods for decomposing large tasks into smaller, more manageable components?', '', 'How do experts approach the process of decomposing complex tasks into smaller, more manageable tasks?', '', 'These alternative questions aim to capture different aspects of the original question, such as the focus on strategies, methods, and expert approaches. By generating multiple perspectives on the user question, we can increase the chances of retrieving relevant documents from the vector database that may not have been retrieved by the original question alone.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2 MultiQuery_retriever_from_llm_2"
      ],
      "metadata": {
        "id": "tw3F9j1jPLbC"
      },
      "id": "tw3F9j1jPLbC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "提供您自己的提示"
      ],
      "metadata": {
        "id": "9RVtHno8Ulrr"
      },
      "id": "9RVtHno8Ulrr"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# # Output parser will split the LLM result into a list of queries\n",
        "# class LineList(BaseModel):\n",
        "#     # \"lines\" is the key (attribute name) of the parsed output\n",
        "#     lines: List[str] = Field(description=\"Lines of text\")\n",
        "\n",
        "\n",
        "# class LineListOutputParser(JsonOutputParser):\n",
        "#     def __init__(self) -> None:\n",
        "#         super().__init__(pydantic_object=LineList)\n",
        "\n",
        "#     def parse(self, text: str) -> LineList:\n",
        "#         lines = text.strip().split(\"\\n\")\n",
        "#         return LineList(lines=lines)\n",
        "\n",
        "\n",
        "# output_parser = LineListOutputParser()\n",
        "\n",
        "QUERY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant. Your task is to generate three\n",
        "    different versions of the given user question to retrieve relevant documents from a vector\n",
        "    database. By generating multiple perspectives on the user question, your goal is to help\n",
        "    the user overcome some of the limitations of the distance-based similarity search.\n",
        "    Provide these alternative questions separated by newlines. Please answer in Chinese.\n",
        "    Original question: {question}\"\"\",\n",
        ")\n",
        "\n",
        "llm = llm_Groq_llama3\n",
        "\n",
        "# Chain\n",
        "# llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=output_parser)\n",
        "llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT) #使用llm_chain會跑很慢\n",
        "\n",
        "# Other inputs\n",
        "question = \"摘要大型語言模型實作進階班的內容\""
      ],
      "metadata": {
        "id": "RFdcKQo__7Fh"
      },
      "id": "RFdcKQo__7Fh",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "MultiQuery_retriever_from_llm_2 = MultiQueryRetriever(\n",
        "    retriever=db.as_retriever(), llm_chain=llm_chain, parser_key=\"lines\"\n",
        ")  # \"lines\" is the key (attribute name) of the parsed output\n",
        "\n",
        "# Results\n",
        "# unique_docs = MultiQuery_retriever_from_llm.invoke(query=\"摘要大型語言模型實作進階班的內容\")\n",
        "unique_docs = MultiQuery_retriever_from_llm_2.invoke(\"摘要大型語言模型實作進階班的內容\")\n",
        "len(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLh0wF3NATb0",
        "outputId": "11cde598-b9e5-4d7e-aa9d-254c526e8a7e"
      },
      "id": "YLh0wF3NATb0",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: Here are three alternative versions of the original question:\n",
            "\n",
            "摘要大型語言模型實作進階班的內容\n",
            "\n",
            "大型語言模型實作進階班的摘要內容\n",
            "\n",
            "進階班大型語言模型實作的摘要內容\n",
            "\n",
            "These alternative questions aim to capture different aspects of the original question, such as:\n",
            "\n",
            "* Emphasizing the summary aspect of the content\n",
            "* Swapping the order of the words to create a different perspective\n",
            "* Focusing on the advanced nature of the course\n",
            "\n",
            "By generating these alternative questions, we can increase the chances of retrieving relevant documents from the vector database that may not have been retrieved by the original question alone.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other"
      ],
      "metadata": {
        "id": "rjrpVS-3ODZw"
      },
      "id": "rjrpVS-3ODZw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb"
      ],
      "metadata": {
        "id": "O6DHg3BuO2QC"
      },
      "id": "O6DHg3BuO2QC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step6 : 建立 PromptTemplate\n"
      ],
      "metadata": {
        "id": "P76Ie938S_B-"
      },
      "id": "P76Ie938S_B-"
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立 PromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# template = \"\"\"You are a customer support agent. You are designed to be as helpful as possible while providing only factual information. You should be friendly, but not overly chatty. Context information is below. Given the context information and not prior knowledge, answer the query. Always say \"thanks for asking!\" at the end of the answer.\n",
        "# template = \"\"\"Context information is below. Given the context information and not prior knowledge. Please answer the question by zh-tw language If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. Please answer in Chinese. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template)"
      ],
      "metadata": {
        "id": "wUqMbEfRTIhD"
      },
      "id": "wUqMbEfRTIhD",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step7 : 建立問答鏈 RetrievalQA"
      ],
      "metadata": {
        "id": "CV4K0o67YWtV"
      },
      "id": "CV4K0o67YWtV"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# question = \"大型語言模型實作進階班的開課日期是什麼時候？\"\n",
        "# question = \"介紹技術領袖培訓全域班第五期的課程內容和修業期間\"\n",
        "# question = \"介紹大型語言模型實作\"\n",
        "# question = \"介紹經理人週末研修班課程\"\n",
        "# question = \"我已完成報名繳費,何時可以收到發票?\"\n",
        "# question = \"我要如何申請退費?\"\n",
        "question=\"摘要大型語言模型實作進階班的內容\"\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm_Groq_llama3, #選擇要使用的 llm_Groq_llama3、llm_primehub_llama3\n",
        "                                       retriever=MultiQuery_retriever_from_llm_2, # 多擇一 retriever or compression_retriever_1 or compression_retriever_2 or MultiQuery_retriever_from_llm_1 or MultiQuery_retriever_from_llm_2\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type=\"stuff\", #map_reduce\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"] #查看結果"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "N_MsRBtaQoh5",
        "outputId": "38a02102-0849-4960-b08b-438c6a1c4782"
      },
      "id": "N_MsRBtaQoh5",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: Here are three alternative versions of the original question:\n",
            "\n",
            "摘要大型語言模型實作進階班的內容\n",
            "\n",
            "大型語言模型實作進階班的摘要內容\n",
            "\n",
            "進階班大型語言模型實作的摘要內容\n",
            "\n",
            "These alternative questions aim to capture different aspects of the original question, such as:\n",
            "\n",
            "* Emphasizing the summary aspect of the content\n",
            "* Swapping the order of the words to create a different perspective\n",
            "* Focusing on the advanced nature of the course\n",
            "\n",
            "By generating these alternative questions, we can increase the chances of retrieving relevant documents from the vector database that may not have been retrieved by the original question alone.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a summary of the content of the Large Language Model Implementation Advanced Course (LLM-B):\\n\\n**Course Overview**\\n\\n* The course is designed for those who want to learn how to implement large language models in their work.\\n* The course covers the basics of large language models, including their applications and limitations.\\n* The course also covers the implementation of large language models using Python and PyTorch.\\n\\n**Course Outline**\\n\\n* Week 1: Introduction to Large Language Models\\n* Week 2: Implementation of Large Language Models using Python and PyTorch\\n* Week 3: Applications of Large Language Models\\n* Week 4: Advanced Topics in Large Language Models\\n\\n**Course Objectives**\\n\\n* To understand the basics of large language models\\n* To learn how to implement large language models using Python and PyTorch\\n* To understand the applications and limitations of large language models\\n* To learn how to use large language models in real-world applications\\n\\n**Course Prerequisites**\\n\\n* Basic knowledge of Python and PyTorch\\n* Familiarity with'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "retriever ANS : 本課程主要涵蓋大型語言模型的設計、優化和應用，透過實作和專題實作導引，學習如何將大型語言模型應用於實際問題中。課程內容包括大型語言模型的運作原理、微調和部署等。 thanks for asking!\n",
        "\n",
        "compression_retriever_1 ANS : 大型語言模型實作進階班的內容包括：理解大型語言模型微調、實作問答機器人、部署上機實作、熟悉大語言模型的技術能力、主題性的專題實作、企業聊天機器人設計和開發、機器人與公司數據庫的集成、機器人效能測試、微調開源大型語言模型等。 thanks for asking!\n",
        "\n",
        "compression_retriever_2 ANS : 本課程主要內容是大型語言模型的微調和部署，學習如何將大型語言模型應用於實際問題中，開發具有價值的 AI 應用。課程中還涵蓋了機器人設計和開發、集成公司數據庫、機器人效能測試和優化等內容。課程的目的是培養學生的專案實作能力和技術能力。\n",
        "Thanks for asking!\n",
        "\n",
        "MultiQuery_retriever_from_llm_1 ANS : 本課程涵蓋大型語言模型實作進階班的內容，包括 LangChain 課程、微調大型語言模型、實作進階班等。\n",
        "thanks for asking!\n",
        "\n",
        "MultiQuery_retriever_from_llm_2 ANS : By generating these alternative questions, we can increase the chances of retrieving relevant documents from the vector database that may not have been retrieved by the original question alone.\n",
        "Here is a summary of the content of the Large Language Model Implementation Advanced Course (LLM-B):\\n\\n**Course Overview**\\n\\n* The course is designed for those who want to learn how to implement large language models in their work.\\n* The course covers the basics of large language models, including their applications and limitations.\\n* The course also covers the implementation of large language models using Python and PyTorch.\\n\\n**Course Outline**\\n\\n* Week 1: Introduction to Large Language Models\\n* Week 2: Implementation of Large Language Models using Python and PyTorch\\n* Week 3: Applications of Large Language Models\\n* Week 4: Advanced Topics in Large Language Models\\n\\n**Course Objectives**\\n\\n* To understand the basics of large language models\\n* To learn how to implement large language models using Python and PyTorch\\n* To understand the applications and limitations of large language models\\n* To learn how to use large language models in real-world applications\\n\\n**Course P"
      ],
      "metadata": {
        "id": "lrNJkmhVVtuR"
      },
      "id": "lrNJkmhVVtuR"
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"] #查看來源檔案"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxQU_JjGycfT",
        "outputId": "8116af25-92ca-4a85-861b-4b7a488dc23a"
      },
      "id": "rxQU_JjGycfT",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='are few-shot learnersTraining language models to follow instructions with human feedbackLLaMA: Open and Efficient Foundation Language ModelsLlama 2: Open Foundation and Fine-Tuned Chat', metadata={'class_name': '大型語言模型實作進階班 (LLM-B) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw1/'}),\n",
              " Document(page_content='few-shotlearnersTraining language models tofollow instructions with human feedbackLLaMA: Open and Efficient Foundation Language ModelsLlama 2: Open Foundation andFine-Tuned Chat', metadata={'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}),\n",
              " Document(page_content='(3 小時)LLM 簡介 (3 小時)：專門領域教授上機習作 (14 小時)文字資料 (4 小時)：助教/AIA 工程師微調大型語言模型 (7 小時)：助教/AIA 工程師問答機器人 (3 小時)：助教/AIA 工程師部署大型語言模型(1 小時)：助教/AIA 工程師專題實作 (4 週，時數 5 小時)專題實作引導 (4 小時)：助教/AIA 工程師專題成果分享 (1 小時)：助教/AIA 工程師專題演講 (8', metadata={'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}),\n",
              " Document(page_content='ModelsLlama 2: Open Foundation andFine-Tuned Chat Models課程有專題實作與呈現，建議準備網頁或PDF問答資料(網頁示例)用於微調大型語言模型。請學員自備筆電，以便課程學習與小組專題實作。上課環境使用 Google Colab修業日期2024 年 3 月 9 日 ( 六 ) ， 3 月 16 日 ( 六 ) ， 3 月 23 日 ( 六 ) ， 3 月 30 日 ( 六 )共 4 週。上課方式實體課程，上課時間為 9:00-17:30 (', metadata={'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'}),\n",
              " Document(page_content='2024/02/07-02/14停課、02/17停課、02/28二二八停課、04/05-04/06清明連假停課、05/01勞動節停課。※實際放假日期依課表為主。日期時程表2024 / 01  / 04報名截止日2024 / 01  / 20課程開始2024 / 05  / 24課程結束退費辦法：退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2023/12/22 之前 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者(', metadata={'class_name': '技術領袖培訓全域班第四期招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-tech-all4-tw/'}),\n",
              " Document(page_content='RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 日， 8 月 17 日 ， 8 月 24 日 每週六，共 4 週。上課方式實體課程，上課時間為 9:00 - 17:30 ( 提供午餐 ) ，4週共 30小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain', metadata={'class_name': '大型語言模型實作進階班 (第四期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw/'}),\n",
              " Document(page_content='(六) 清明連假、6/8 (六) 端午節連假，各停課一次。實際放假日期依課表為主。日期時程表2024 / 03  / 04報名截止日2024 / 03  / 16課程開始2024 / 06  / 29課程結束退費辦法退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2024/02/15 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2024/02/16～2024/02/29 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前', metadata={'class_name': '台北總校第十九期經理人週末研修班招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-manager-tp/'}),\n",
              " Document(page_content='2024/09/27-09/28 AIA年會停課。※實際放假日期依課表為主。日期時程表2024 / 08  / 14報名截止日2024 / 08  / 31課程開始2024 / 12  / 14課程結束退費辦法：退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( ～ 2024/08/02 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2024/08/03～2024/08/15 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前', metadata={'class_name': '技術領袖培訓全域班第五期招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-tech-all-tw/'}),\n",
              " Document(page_content='language models tofollow instructions with human feedbackLLaMA: Open and Efficient Foundation Language ModelsLlama 2: Open Foundation andFine-Tuned Chat Models課程有專題實作與呈現，建議準備網頁或PDF問答資料(網頁示例)用於微調大型語言模型。請學員自備筆電，以便課程學習與小組專題實作。( 記憶體至少16 GB 以上 )上課環境使用', metadata={'class_name': '大型語言模型實作進階班 (第四期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw/'}),\n",
              " Document(page_content='等。以下為參考閱讀文獻：Attention Is All You NeedImproving Language Understanding by Generative Pre-TrainingLanguage Models are Unsupervised Multitask LearnersLanguage models are few-shotlearnersTraining language models tofollow instructions with human', metadata={'class_name': '大型語言模型實作進階班 (第四期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw/'}),\n",
              " Document(page_content='GPT, fine-tuning, Hallucinations 等。以下為參考閱讀文獻：Attention Is All You NeedImproving Language Understanding by Generative Pre-TrainingLanguage Models are Unsupervised Multitask LearnersLanguage models are few-shot learnersTraining language models to', metadata={'class_name': '大型語言模型實作進階班 (LLM-B) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-tw1/'}),\n",
              " Document(page_content='GPT, fine-tuning, Hallucinations 等。以下為參考閱讀文獻：Attention Is All You NeedImproving Language Understanding by Generative Pre-TrainingLanguage Models are Unsupervised Multitask LearnersLanguage models are few-shotlearnersTraining language models tofollow', metadata={'class_name': '大型語言模型實作進階班 (第二期) 招生簡章', 'source': '簡章', 'url': 'https://aiacademy.tw/admission-llmb-2024-tw2/'})]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 其他待測試"
      ],
      "metadata": {
        "id": "tnGqEhkPy6d9"
      },
      "id": "tnGqEhkPy6d9"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 假设您有一个可以转换为检索器的数据库对象\n",
        "# try:\n",
        "#     # 使用配置好的 llm 创建 QA 链\n",
        "#     qa_chain = RetrievalQA.from_chain_type(\n",
        "#         llm=llm,\n",
        "#         retriever=db.as_retriever(),\n",
        "#         return_source_documents=True,\n",
        "#         chain_type=\"stuff\",\n",
        "#         chain_type_kwargs={\"prompt\": \"请根据您的需求定制提示\"}\n",
        "#     )\n",
        "\n",
        "#     question = \"摘要技術領袖培訓全域班課程大綱\"\n",
        "#     result = qa_chain({\"query\": question})  # 把question丢入RetrievalQA\n",
        "#     print(result[\"result\"])  # 查看结果\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(f\"执行过程中发生错误: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pI-iOhtjOs9",
        "outputId": "c87a9d7d-4a6f-4b4d-df56-81407f040ef3"
      },
      "id": "4pI-iOhtjOs9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "执行过程中发生错误: name 'RetrievalQA' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if \"search_quality_reflection\" in result:\n",
        "#     print(result[\"search_quality_reflection\"])\n",
        "# else:\n",
        "#     print(\"Search quality reflection is not available for this query.\")\n",
        "\n",
        "#通过print(result[\"search_quality_reflection\"])输出并查看这个分数。\n",
        "#分数范围是0到1之间的浮点数,越接近1表示检索质量越好,能更好地回答查询。如果分数较低,你可以考虑采取其他措施,比如获取更多相关文档、提示用户重新表达查询等。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rm-wcYcN7RK_",
        "outputId": "2079ab0c-98b9-457f-8812-3929ad87e045"
      },
      "id": "rm-wcYcN7RK_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-ee6ee0ed39cd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m\"search_quality_reflection\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"search_quality_reflection\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Search quality reflection is not available for this query.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step8 : 建立本機evaluation"
      ],
      "metadata": {
        "id": "v0tEYKGXyf8Z"
      },
      "id": "v0tEYKGXyf8Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM-Generated examples"
      ],
      "metadata": {
        "id": "6rHT8571y_J8"
      },
      "id": "6rHT8571y_J8"
    },
    {
      "cell_type": "code",
      "source": [
        "#利用 LLM 自動化生成 (自動從每個文檔建立一個 Q, A pair\n",
        "from langchain.evaluation.qa import QAGenerateChain"
      ],
      "metadata": {
        "id": "PJBovab1ygVf"
      },
      "id": "PJBovab1ygVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = db.get()['documents'] # 取原始文本 chunks\n",
        "print(type(data))\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOzXwmPpzmoQ",
        "outputId": "aaa599f4-7352-4f8c-a3bf-42fa1742bbfc"
      },
      "id": "iOzXwmPpzmoQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['常見問題: 我的學員證不見了，要申請，要怎麼給你們錢?\\n回答: 您好，請發信至hi@aiacademy.tw 申請，以便我們作業紀錄登記；若您確定申請補發學員證，我們將製作好之後，會現場給您學員證+發票，屆時會與您收500元。', '常見問題: 詢問師資 （醫療專班）\\n回答: 台灣人工智慧學校提供專業的師資與課程，也安排醫界的先進前來授課，分享智慧醫療應用與案例的分享。\\n希望能透過五週的課程，讓工作繁忙的醫師及護理相關人員，能快速、系統化掌握人工智慧技術的最新趨勢與發展應用能力，同時進行醫療實作案例分享。\\n學校將邀請中央研究院等學研單位及產業界，擁有豐富經驗與理論背景的講師，進行機器學習、深度學習、智慧生醫等重要的人工智慧核心技術與應用課程講授。\\n預計將培養上千位醫療產業從業人員，擁有定義問題、解決及場域導入方式等關鍵能力，並能實際應用在醫療工作上為全台醫療產業注入維持競爭力的能量。\\n本次北部醫療專班的師資\\n陳弘軒        國立中央大學 資工系副教授        機器學習\\n蔡炎龍        國立政治大學應用數學系副教授        深度學習\\n莊永裕        台大資工系 教授        電腦視覺\\n蔣榮先         成大資工系教授暨醫院健康數據中心執行長        智慧醫療應用', '18,000 元，團報達 10 人以上每人新台幣 16,000 元。大量團報請另洽專員：02-85123731 #12上課地點：桃園龜山文化一路 15號 (林口長庚醫院 研究大樓一樓綜合會議廳)報名方式：本招生採網路報名，請於報名截止日 2023/07/10前（含 07 月 10', '500 元，其餘費用全數退還；活動已開始，部分取消則依取消天數比例退還。注意事項因課程需要，請學員必須自備筆電來參加本營隊。錄取學員如經發現報名資格不符規定，或所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，取消資格，並應負法律責任，且不發給任何有關營隊之證書，如係在營期後始發覺者，將撤銷其營隊證書。主辦單位保有所有相關規定最終解釋權及活動修改、變更之權利，若有相關異動將會公告於網站，', 'Google 前董事總經理 Appier & ikala 董事1991畢業於台大資工所博士班1993年加入中研院資訊所，曾任研究員與兼任副所長2002與台大資管系合聘教授2006年加入 Google，擔任董事總經理2020年從 Google 退休，退休後持續參與台灣新創國際化的發展，包括擔任 Appier/iKala 等 AI 新創董事從零開始的 ChatGPT蔡政霖台灣人工智慧學校 AI工程師台灣人工智慧學校台北總校 AI工程師陽明交通大學生醫資訊所博士候選人研究領域為醫學影像分割最近新增', '所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。日期時程表2024', '常見問題: 開學後申請轉班\\n回答: 1.除非特殊情況，依學員手冊規定，不許轉班\\n2.特殊情況的話(像是個人不可抗拒之因素)，需要學員提出證明，學校方得受理\\n3.課程進行兩周之後，也不許轉班', '296 號 基中大樓 2F報名方式採網路報名，請於報名截止日 2023 年 06 月 28 日前 上網填寫報名資料。結業證書學校將於課程結束後一週內以電子郵件寄發圖靈數位證書。退費辦法已完成繳費之學員如欲取消報名，退費時將酌收 10% 手續費，活動前十天內 (不含活動日) 不予退費。注意事項課程需要自備筆電參加。學校保有修改、變更簡章及相關規定之權利。 恕不另行通知。會在開課當週寄發通知提醒，報名資料請務必填寫正確。', 'AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程目標學習 4', '常見問題: 醫療專班跟技術班還有經理人班的差別是？\\n回答: 醫療專班：\\n智慧醫療專班是台灣人工智慧學校為台灣醫療產業從業人員所設計的密集課程，期待透過智慧醫療專班，讓醫療產業從業人員能夠快速、系統化掌握人工智慧技術的最新趨勢，並徹底瞭解人工智慧如何運作，以及它的能力、侷限及未來發展，並能實際應用在醫療工作的每個場景。\\n智慧金融專班:\\n給予專班學員金融業全面性應用到的人工智慧知識，再透過實務議題、案例分享與場域實地參訪的印證，即時掌握智慧金融應用的趨勢。同時安排學員們進行深入的專題討論，將課堂傳授的知識運用於專題及實作，領略這些技術的實際應用方式及限制，以及進行學員間深入的交流學習。\\n經理人班：', '141 號 14 樓 )報名方式：本招生採網路報名，請於報名截止日 2023 年 05 月 01 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。報名及註冊登記繳費流程：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '14 小時上課方式實體課程上課地點中研院人文館 第二會議室 ( R2 ) | 台北市南港區研究院路2段128號適合對象對辦公室自動化及大型語言模型應用有興趣者 (無程式背景可)課程目標了解大型語言模型的原理和功能熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程內容理論知識 (3 小時)大型語言模型(LLM) 概論 (1.5 小時)：助教/AIA 工程師大型語言模型(LLM)', ')應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2023/04/27~2023/05/11 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/05/12～2023/05/19 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2023/05/20～2023/05/26', '7 日內提出退費申請者( 2023/12/09～2023/12/15 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期二分之一以上提出退費申請者( 2023/12/16 ~ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期二分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程資訊課程名稱大型語言模型實作進階班 (LLM-B)課程時數4週共 28 小時上課方式實體課程上課地點中研院人文館 第二會議室 (  R2 ) |', '28 小時上課方式實體課程上課地點中研院人文館 第二會議室 (  R2 ) | 台北市南港區研究院路2段128號適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)入學條件本校 技術領袖班 / 專題實作班 結業之校友 (需於報名時上傳結業證書以供查核)通過本班的入學考試以上兩項滿足一項即可入學課程目標學習 4', '常見問題: 結業相關問題 我當天結業無法出席怎麼辦？\\n回答: 開學典禮及結業典禮皆為課程時間，出缺席將計入缺席時數。若學員因故有請假需求，請填妥請假表單進行申請：https://reurl.cc/xZNOAL，並上傳證明文件，行政處核可後，系統將會直接寄送請假核可通知至您的信箱中。', '/ 05  / 12課程開始2023 / 07  / 08課程結束課程目標：課程涵蓋 AI 在製造業的各層面，從科普理論擴展到實務議題，讓學員快速進入製造業應用場景，以產業深化案例與校友經驗分享引導、手把手體驗，移地學習，啟發中高階經理人能 lead AI project。課程簡介：2022 年AIA 全面推展「產業 AI 專班」，繼製造業董總專班、台中分校智慧製造專班之後，台北總校特別針對北部 EMS', '| 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象對辦公室自動化及大型語言模型應用有興趣者 ( 無程式背景可 )課程目標了解大型語言模型的原理和功能熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程內容ChatGPT基礎及延伸應用 (5小時)ChatGPT 高效問答術 (2 小時)：助教/AIA 工程師ChatGPT 實用擴充元件 (1.5小時)：助教/AIA', '+ 進階班 (LLM-B) ，並錄取通過，則二班課程享原價 八 折( 新台幣 44,000 元 )。校友優惠專享每人新台幣 13,500 元。本校各班別結業之校友，於報名時附上學員編號，經查核後得享有校友優惠。團報優惠專享 (5人)每人新台幣 12,000 元。團體報名專屬優惠：報名人數達 5 位以上，每人優惠價為 $12,000。請所有參加者透過線上報名系統完成報名，報名完成後再由報名窗口發送郵件至 hi@aiacademy.tw 聯絡林小姐確認審核。報名方式本招生採網路報名，請於報名截止日', '， 3 月 30 日 ( 六 )共 4 週。上課方式實體課程，上課時間為 9:00-17:30 ( 提供午餐 ) ，課程時數 30 小時。上課地點新北市板橋區民族路168號 ( 中華電信學院實驗大樓7樓 ) 招生人數96 名 (得不足額錄取)招生對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)。入學條件本校 技術領袖班 / 專題實作班 結業之校友 (需於報名時上傳結業證書以供查核)通過本班的入學考試以上兩項滿足一項即可入學學費標準每人新台幣 40,000', '8 日起，且未達全期三分之一期間內提出退費申請者( 2024/03/24 ~ 2024/04/20 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2024/04/21～ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', 'AIA 台北總校 (板橋)報名方式：本招生採網路報名，請於報名截止日 2024 年 03 月 04 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。報名及註冊登記繳費流程：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至', '造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。退費辦法本課程退費時將酌收', '週。每週六上課，時間皆為早上 9 時至下午 5 時 (共 105 個小時)。招生人數：150 名 (得不足額錄取)招生對象：在職人士且任管理職位者優先錄取，全域招生不限台北。學費標準：每人新台幣 52,000 元，團報達 10 人以上每人新台幣 50,000 元。大量團報請另洽專員：02-85123731 #17 （上班時間：週二~六）上課方式：週六全天進行實體課程。台中(含)以南的學員，全程皆以線上模式進行(使用ZOOM)，惟手把手實作課程( 2024/04/27 )和結業典禮(', '數位創新中心經理現任職於台中市鉅鋼機械-數位創新中心經理。主要負責企業數位轉型、敏捷文化、AI與智慧製造相關專案，並於2022年榮獲哈佛商業評論舉辦之數位轉型鼎革獎-楷模獎之殊榮。熱愛研究與分享IT新領域之技術，在AI、雲端架構、區塊鏈、工業物聯網等領域均有研究。大型語言模型 (LLM) 概論蔡政霖台灣人工智慧學校 AI 工程師台灣人工智慧學校台北總校 AI工程師陽明交通大學生醫資訊所博士候選人研究領域為醫學影像分割最近新增 Prompt Engineering 技能AI', '開課日期: 2023/07/01\\n報名截止日: 2023/06/28\\n課程名稱: AIGC實戰工作坊：ChatGPTX智慧工作新世紀\\n上課地點: 台中分校', '子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。手把手課程須自備筆電，以利課程進行。學員出席率達四分之三上課時數並參與', '開課日期: 2023/12/09\\n報名截止日: 2023/11/16\\n課程名稱: 大型語言模型實作進階班(LLM-B)招生簡章\\n上課地點: 全域班別', '(具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain 和 Huggingface 等工具包。學員需具備 Python 語言能力和機器學習基礎知識，無須參加入學考試。請先行評估個人程度再行報名。課程目標學習 4 大課程主題與方法：理解大型語言模型實作大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程內容理論知識 (3 小時)LLM 簡介 (3 小時)：專門領域教授上機習作 (14', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學', '元團報每人新台幣 46,000 元 (10 人以上)大量團報請另洽專員：02-85123731 #17（辦公時間：週二~六）上課方式：週六全天於台北總校進行實體課程（學員因疫情考量亦可申請線上上課）。台中(含)以南的學員，全程皆以線上模式進行，惟手把手實作課程(8/12)和結業典禮(10/28)二日課程建議實體上課效果較佳，學校將提供台中(含)以南欲實體出席此二日課程之學員交通費用補助 (憑公共交通票證申請)。實體上課地點：中央研究院 或 台北總校報名方式：本招生採網路報名，請於報名截止日', 'lead AI project。課程簡介：2022 年，AIA 以真實案例應用為主軸，全面推展「產業 AI 專班」，台中分校針對中部精密機械製造業聚落，聚焦在加工組裝製程，再度推出智慧製造專班，為期八週的課程，於週五、週六以全天形式進行，授予學員製造業全面應用人工智慧與淨零碳排、綠色製造等相關知識。除了課程，再透過實務議題、案例分享與場域實地參訪印證，另外特別加上一週的台灣人工智慧年會學習活動，在兩整天的年會中可以第一手獲得國內外重要 AI', '常見問題: 請問您們專題實作班上課幾周? 總時數為?\\n回答: 專題實作班上課五周，為每周星期四和星期五晚間19:00到21:00，星期六時間為早上 09:00到下午17:00，總計上課時數約 46.5小時。您也可以參閱官網 https://aiacademy.tw/的招生訊息內的資訊。', '(六) 清明連假、6/8 (六) 端午節連假，各停課一次。實際放假日期依課表為主。日期時程表2024 / 03  / 04報名截止日2024 / 03  / 16課程開始2024 / 06  / 29課程結束退費辦法退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2024/02/15 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2024/02/16～2024/02/29 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前', '文字生成魔法AI 圖像生成魔法綜合應用與發表08:30 ~ 09:00報到報到報到09:00 ~ 09:50【營隊開場】營隊介紹 互相認識、分組活動【專題演講】AIGC時代的學習方案：硬實力、軟素養、與未來發展路徑預估【實作課程】圖片活起來: 從圖片到影片的技巧09:50 ~10:00休息休息休息10:00 ~ 10:50【概念複習實作】從零開始的 ChatGPT【實作課程】AI 繪圖概述 與 Prompt【實作課程】AIGC 百寶箱: 更多道具介紹10:50', '2023/12/09 )和結業典禮( 2024/03/09 )二日課程建議實體上課效果較佳，學校將提供台中(含)以南欲實體出席此二日課程之學員交通費用補助 (憑公共交通票證申請)。實體上課地點 (以下為暫定，將視招生人數與場地狀況以行前通知為準)：中央研究院 (南港) / 新光傑仕堡有氧園區 (板橋) / AIA 台北總校 (板橋)報名方式：本招生採網路報名，請於報名截止日 2023 年 10 月 26', '，每人新台幣 25,000 元。(校友報名皆需附上學員編號以供查核)上課地點：中央研究院生技園區 或 台北總校 (新北市板橋區中山路一段 141 號 14 樓 )報名方式：本招生採網路報名，請於報名截止日 2023 年 05 月 01', '開課日期: 2024/08/03\\n報名截止日: 2024/07/22\\n課程名稱: 大型語言模型實作進階班(第四期)招生簡章\\n上課地點: 全域班別', '500 元，其餘費用全數退還；活動已開始，部分取消則依取消天數比例退還。注意事項因課程需要，請學員必須自備筆電來參加本營隊。錄取學員如經發現報名資格不符規定，或所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，取消資格，並應負法律責任，且不發給任何有關營隊之證書，如係在營期後始發覺者，將撤銷其營隊證書。主辦單位保有所有相關規定最終解釋權及活動修改、變更之權利，若有相關異動將會公告於網站，', '常見問題: 我要如何申請退費?\\n回答: 很遺憾您無法與我們一起為接下來的課程努力。\\n請您發信至hi@aiacademy.tw 提供您的班別跟姓名。 退費的標準，我們會依照學員手冊退費辦法辦理，後續也請提供你您帳號(含分行)資訊(存摺影本)，以利我們後續匯款。謝謝', ')應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2024/06/21 ~2024/07/05 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2024/07/06 ~ 2024/07/13 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2024/07/14 ~ 2024/08/08', '7 日內提出退費申請者( 2024/04/10 - 2024/04/16 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課日(含)以後提出退費申請者( 2024/04/17 以後 )所收取之當期開班約定繳納費用得全數不予退還。備註：本表所稱「開課日」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程資訊課程名稱大型語言模型實作初階班 (LLM-A)課程時數2週共 14 小時上課方式實體課程上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號', '8 日起，且未達全期三分之一期間內提出退費申請者( 2023/07/23～2023/08/12 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2023/08/13～ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '2023/07/10前（含 07 月 10 日當日）上網填寫報名資料。請完整填寫報名表，以利完成審核程序。錄取通知及註冊繳費：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '2 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流 (轉帳)。若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消資格，事後不得以任何理由要求補註冊。講師陣容手機螢幕建議使用水平橫式瀏覽課程名稱姓名職稱講師簡介線上預習從0到1的Prompt之旅：開啟AI的無限可能簡光正鉅鋼機械股份有限公司', 'AIA 台北總校 (板橋)報名方式：本招生採網路報名，請於報名截止日 2023 年 10 月 26 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。報名及註冊登記繳費流程：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至', '開課日期: 2024/03/09\\n報名截止日: 2024/02/14\\n課程名稱: 大型語言模型實作進階班(第二期)招生簡章\\n上課地點: 全域班別', '開課日期: 2024/07/06\\n報名截止日: 2024/06/24\\n課程名稱: 台北總校第二十期經理人週末研修班招生簡章\\n上課地點: 全域班別', '常見問題: 請問您們智慧醫療專班上課幾周? 總時數為?\\n回答: 智慧醫療專班上課五周，為每星期六，時間為早上 09:30到下午18:00，總計上課時數為 37.5小時。您也可以參考官網 https://aiacademy.tw/的招生訊息內的資訊。', 'AI-Generated Content) 相關工具如：ChatGPT、 Midjourney 等來生成文字與圖像，並能應用在日常生活與學習的情境之中。主辦單位財團法人台灣人工智慧學校基金會、零時小學校協辦單位島島阿學、台灣開放教育推動團隊活動時間活動時間:2023 年 7 月 26 日 (三) 至 7 月 28 日 (五)，每日上午 9:00 至下午 16:50 (共 3 天)活動地點(交通自理)7/26-27 課程：台灣人工智慧學校台北總校  ( 新北市板橋區中山路一段 141 號 14', '常見問題: 如果遇到颱風天，你們課程會順延嗎？\\n回答: 如遇颱風天，本校活動、上課是否照常進行，將依行政院人事行政局公布之臺北市停班停課標準為主，相關消息將另行公告於官網、官方臉書。', '週。每週六上課，時間皆為早上 9 時至下午 5 時(共 105 個小時)。招生人數：150 名 (得不足額錄取)招生對象：在職人士且任管理職位者優先錄取，全域招生不限台北。學費標準：每人新台幣 52,000 元，團報達 10 人以上每人新台幣 50,000 元。大量團報請另洽專員：02-85123731 #12 （上班時間：週二~六）上課方式：週六全天進行實體課程。台中(含)以南的學員，全程皆以線上模式進行(使用ZOOM)，惟手把手實作課程( 2024/08/10 )和結業典禮(', '8 日起，且未達全期三分之一期間內提出退費申請者( 2023/05/20～2023/05/26 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2023/05/27~ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '處理文件、產生報告等。辦公室流程自動化可以幫助您減少錯誤、節省時間、降低成本、提升生產力。「大型語言模型」是一種利用深度學習方法訓練的人工智慧系統，能夠理解和生成我們日常使用的語言，並能處理各種與語言相關的任務，如翻譯、撰寫摘要、進行對話和創作等。這種模型可以提升您的語言技能、創新能力、溝通效果和競爭優勢。辦公室流程自動化和大語言模型兩種技術融合在一起，能讓您的辦公室工作更輕鬆、更高效。您可以應用大語言模型來設計和優化您的辦公室流程，讓軟體機器人能夠更準確地執行您想要的任務。您也可以使用軟體機器', '2024/02/07-02/14停課、02/17停課、02/28二二八停課、04/05-04/06清明連假停課、05/01勞動節停課。※實際放假日期依課表為主。日期時程表2024 / 01  / 04報名截止日2024 / 01  / 20課程開始2024 / 05  / 24課程結束退費辦法：退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2023/12/22 之前 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者(', '常見問題: 請問你們有學費補助嗎？因為我看我們醫院有補助計畫，那如果你們這一期沒有，我是否可以轉下一期？\\n回答: 我們學校沒有提供學費補助，應該是貴醫院單位的補助計畫，可能需要您與貴單位做內部確認，是否能申請院內補助，我本校無權涉入。', '常見問題: 詢問師資 （經理人班）\\n回答: 台灣人工智慧學校提供專業的師資與課程，也安排有深厚實務經驗的先進前來授課，分享人工智慧的應用與案例的分享。希望能透過14週的課程，從基礎核心、實作學習到產業應用，讓來參與課程的學員，充份吸收並掌握人工智慧技術的最新趨勢與發展應用能力。   學校將邀請學研單位及產業界，擁有豐富經驗與理論背景的講師，進行機器學習、深度學習、電腦視覺、資料探勘等重要的人工智慧核心技術與應用課程講授。 本次經理人班的師資 吳漢銘 國立政治大學統計學系副教授 資料科學與大數據分析 陳弘軒 國立中央大學 資工系副教授 機器學習與演算法概論 蔡炎龍 國立政治大學應用數學系副教授 深度學習 莊永裕 國立臺灣大學資訊工程學教授 電腦視覺 陳宜欣 國立清華大學資訊工程學系教授 資料探勘 （學校保有修改、變更課程內容之權利）\\n以及業界先進產業案例的分享及應用。\\n官網只會放上課程大綱，待開課前會寄出學員手冊，登入學員專區裡面的課程表，會有當期課程講義及授課講師。', 'ChatGPT 提問技巧外，您還將透過自動化平台工具串接 ChatGPT 與其他生產力工具，提升職場工作效率。課程也帶您運用其他開源大型語言模型，結合自己的文件資料，建立特定情境下的問答機器人，透過專題實作為您的職涯加分!課程目標熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程效益能善用ChatGPT、Copilot', '通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。手把手課程須自備筆電，以利課程進行。本課程放假日期：4/6', '(信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw', 'AIGC 實戰夏令營：高中生的第一個生成式 AI 營隊🚀虛實混成學習 • 動手實作• 競賽發表🤝 ～體驗生成式 AI 的魔法魅力！立即報名活動簡介為了協助高中職生了解生成式 AI 的最新趨勢，台灣人工智慧學校特別於今年暑假設計了 AIGC 實戰夏令營，以疫後時代的混成教學為主軸，混合了課前的線上學習與三天的的營隊實作，希望學員透過講師的影片與工程師的帶領實作讓高中職生能學會使用AIGC (AIGC, AI-Generated Content) 相關工具如：ChatGPT、 Midjourney', '296 號 基中大樓 2F報名方式：本招生採網路報名，請於報名截止日2023 年 07 月 03 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。報名及註冊登記繳費流程：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利本課程須全程自備筆電。本班上課方式為「實體結合線上課程」，不提供補課或延期。本課程放假日期：※', '( 六 ) ， 12 月 16 日 ( 六 ) ， 12 月 23 日 ( 六 ) ， 12 月 29 日 ( 五 ) 共 4 週。上課方式實體課程，上課時間為 9:00-17:00 ( 提供午餐 ) ，課程時數 28 小時。上課地點中研院人文館 第二會議室 ( R2 ) | 台北市南港區研究院路2段128號招生人數105名 (得不足額錄取)招生對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)。入學條件本校 技術領袖班 / 專題實作班 結業之校友', 'GPT, fine-tuning, Hallucinations 等。以下為參考閱讀文獻：Attention Is All You NeedImproving Language Understanding by Generative Pre-TrainingLanguage Models are Unsupervised Multitask LearnersLanguage models are few-shotlearnersTraining language models tofollow', '(0.5 小時)：助教/AIA 工程師特定情境問答機器人部署實作 (2 小時)：助教/AIA 工程師分組專題成果發表(1.5小時)：助教/AIA 工程師課程大綱立即報名', '如何核實校友身分?: 要如何查詢我的學號?\\n具備台灣人工智慧學校結業證書者。: 請至官網，點選校友資源內的學號查詢即可。', '大揭密: 通往 AI 繪畫大師的方法【創意發想】分組競賽 ( 一組分享10分鐘 )13:50 ~14:00休息休息14:00 ~ 14:50【實作課程】擴展ChatGPT：探索外掛插件的無限可能性【實作課程】Midjourney 進階魔法: 成為 AI 繪圖魔法師14:50 ~ 15:00休息休息休息15:00 ~ 15:50【專題時間】小組討論與實作【專題時間】小組討論與實作【結業式】15:50 ~ 16:00休息休息16:00 ~ 16:50【成品分享時間】【成品分享時間】※', '所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。退費辦法退費時間學費退還金額於當期課程開課日前', '常見問題: 如果我退學了，我還可以登入專區進去看影片等教學相關素材嗎？\\n回答: 這邊和您說聲抱歉。退學或是終止學員，將無法進入專區觀看相關影片，以維護其他學員的就學權益。', '本次經理人班也加入AIGC實戰應用，學會使用相關工具如：ChatGPT、 Midjourney 等來生成文字與圖像，結合情境應用，有效減輕工作負擔，瞬間提升工作效率。', '2024 年 07 月 31 日 週三 17:00 後寄發錄取通知第二梯次考試於 2024 年 08 月 21 日 週三 17:00 後寄發錄取通知※  放榜後，考生應主動查詢，獲知錄取後如期辦理註冊，避免因系統擋信或漏信而影響註冊。逾期未註冊者，不得以未接獲通知為由要求補救措施。錄取通知及註冊繳費：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3', '提供匯款單或匯款帳號後五碼，匯款手續費請自行負擔，以利我們對帳後更新你的註冊狀態，請務必在繳費期限內完成匯款繳費，繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學', '常見問題: 請問您們經理人周末研修班上課幾周? 總時數為?\\n回答: 經理人周末研修班上課十四周，為每周星期六，時間為早上 09:00到下午17:30，總計上課時數約 105小時。經理人週末研修班學員缺席達四分之一上課時數者，不予發給結業證書；您也可以參閱官網 https://aiacademy.tw/的招生訊息內的資訊。', 'ChatGPT 提問技巧外，您還將透過自動化平台工具串接 ChatGPT 與其他生產力工具，提升職場工作效率。課程也帶您運用其他開源大型語言模型，結合自己的文件資料，建立特定情境下的問答機器人，透過專題實作為您的職涯加分! 課程目標熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程效益能善用ChatGPT、Bing、Claude', 'GPT, fine-tuning, Hallucinations 等。以下為參考閱讀文獻：Attention Is All You NeedImproving Language Understanding by Generative Pre-TrainingLanguage Models are Unsupervised Multitask LearnersLanguage models are few-shot learnersTraining language models to', '(Artificial Intelligence Generated Content, AIGC) 相關工具如：ChatGPT、 Midjourney 等來生成文字與圖像，並能應用在日常生活與學習的情境之中。主辦單位財團法人台灣人工智慧學校基金會活動時間與報名網址2024 年 1 月 30 日 (二) 至 2 月 1 日 (四)，每日上午 9:00 至下午 16:50 (共 3 天)報名網址：https://neti.cc/8v8OARk活動地點(交通自理)台灣人工智慧學校台中分校  (', '開課日期: 2023/07/26\\n報名截止日: 2023/07/10\\n課程名稱: AIGC實戰夏令營：高中生的第一個生成式AI營隊\\n上課地點: 台北總校', '10% 手續費，課程前十天內 (不含開課日) 不予退費。第四期開課班別退費時間 週三班2024年06月23日（含）之前可退費。 週六班2024年06月26日（含）之前可退費。請注意，由於課程前十天內不予退費，以上日期均不包括開課日。課程大綱立即報名', '2024/09/27-09/28 AIA年會停課。※實際放假日期依課表為主。日期時程表2024 / 08  / 14報名截止日2024 / 08  / 31課程開始2024 / 12  / 14課程結束退費辦法：退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( ～ 2024/08/02 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2024/08/03～2024/08/15 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前', '常見問題: 學員要通過那些門檻才會有結業證書？是否有課綱介紹？\\n回答: 結業門檻等相關行政細節資訊列於學員手冊上，待開學當周會寄發給各位學員。課綱可以先參考官網 https://aiacademy.tw/', '(五)、09/16 (六)  - 停課09/29(五)、09/30(六) : 中秋連假日期時程表2023 / 06  / 29報名截止日2023 / 07  / 15課程開始2022 / 10  / 28課程結束退費辦法：退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2023/06/16 之前 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/06/17～2023/06/29', '開課日期: 2023/11/11\\n報名截止日: 2023/10/26\\n課程名稱: 台北總校第十八期經理人研修班招生簡章\\n上課地點: 全域班別', ')應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2024/08/16～2024/08/30 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2024/08/31～2024/09/07 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2024/09/08～2024/10/05', '和大語言模型兩種技術融合在一起，能讓您的辦公室工作更輕鬆、更高效。您可以應用大語言模型來設計和優化您的辦公室流程，讓軟體機器人能夠更準確地執行您想要的任務。您也可以使用軟體機器人來呼叫和使用大語言模型，讓您能夠更快速地完成您需要的語言相關工作。台灣人工智慧學校特別針對大型語言模型開設課程，適合無技術背景，想運用大型語言模型實現自動化流程的所有人。除了認識大型語言模型的運作原理，學習', '元 )。團報優惠專享 (5人)每人新台幣 32,000 元。團體報名專屬優惠：報名人數達 5 位以上，每人優惠價為 $32,000。請所有參加者透過線上報名系統完成報名，報名完成後再由報名窗口發送郵件至 hi@aiacademy.tw 聯絡林小姐確認審核。報名方式本招生採網路報名，請於報名截止日 2024 年 02 月 14 日前 (含 02/14 當日) 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。入學考試：考試時間：2024 年 02 月 16 日 週五 19:00 -', '3 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至 :玉山銀行 南港分行 金融機構代碼：808 1182戶名：財團法人台灣人工智慧學校基金會帳號：1182-940-016585※ 注意：選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw提供匯款單或匯款帳號後五碼', '元。本校各班別結業之校友，於報名時附上學員編號，經查核後得享有校友優惠。團報優惠專享 ( 3人 )每人新台幣 13,500 元。團體報名專屬優惠：報名人數達 3 位以上，每人優惠價為 $13,500。請所有參加者透過線上報名系統完成報名，報名完成後再由報名窗口發送郵件至 hi@aiacademy.tw 聯絡林小姐確認審核。報名方式本招生採網路報名，請於報名截止日 2024 年 4 月 8 日前', '(2 小時)：助教/AIA 工程師ChatGPT 實用擴充元件 (1.5小時)：助教/AIA 工程師ChatGPT 應用程式(1.5小時)：助教/AIA 工程師ChatGPT工作流程自動化實作(5小時)自動化原理與相關工具介紹(1.5小時)：助教/AIA 工程師ChatGPT 流程自動化(2小時)：助教/AIA 工程師小組專題討論與實作(1.5小時)開源大型語言模型應用實作 (4小時)認識開源大型語言模型 (0.5 小時)：助教/AIA 工程師特定情境問答機器人部署實作 (2', '~10:00休息休息休息10:00 ~ 10:50【概念複習實作】從零開始的 ChatGPT【實作課程】AI 繪圖概述 與 Prompt 【實作課程】AIGC 百寶箱: 更多道具介紹10:50 ~11:00休息休息休息11:00 ~11:50【實作課程】ChatGPT 指南【實作課程】Midjourney : AI繪圖的第一步【專題時間】小組討論與實作11:50 ~ 13:00午餐午餐午餐13:00 ~ 13:50【實作課程】角色扮演: 透過模板指令掌握工作技巧【實作課程】Midjourney', ')、清寒家庭免費( 學校將借用筆電 )報名規定本活動招生採網路報名，請於截止日 2023 年 7 月 10 日前上網填寫報名資料，並上傳家長同意書 (下載：AIGC 實戰夏令營 家長／監護人同意書)，請列印後填妥資料並簽名，掃描成 PDF、圖片格式等電子檔)上傳或繳交資料不齊或不符規定者，視同未完成報名。欲參加者請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符而影', 'Prompt Engineering 技能AI 繪圖概論吳承澔台灣人工智慧學校 AI工程師逢甲大學資訊工程學系碩士逢甲大學人工智慧中心研究生過去研究主題：醫療病例實體間的時序關係預測曾參與相關專案：使用者興趣分析、駕駛油耗預測、圖像異常檢測、醫療實體時序預測相關工具的使用與延伸實體實作迎接真正“電腦”時代！簡立峰台灣 Google 前董事總經理 Appier & ikala', '課程：台灣人工智慧學校台北總校  ( 新北市板橋區中山路一段 141 號 14 樓 )7/28 課程與結業：中央研究院人文館國際會議廳 ( 台北市南港區研究院路二段128號 )收費標準( 含證書及學習歷程、午餐、保險；不含住宿與交通 )營隊費用 -  NT$ 12,000早鳥優惠價 - NT$ 10,000 ( 06/15 截止 )三人團報價 - NT$ 10,000  ( 三人以上， 限開同一張發票 )校友家長價 - NT$ 10,000 ( 需附校友學號', '台北總校第十九期經理人週末研修班招生簡章🚀 AIA 經典【經理人週末研修班】課程，全明星級的講師陣容，與時俱進的課程內容，不受地域限制彈性上課，利用14週的週六時間，將各產業人脈與寶貴 AI 知識一網打盡。💪👍🤝課程大綱立即報名修業期間：自 2024 年 03 月 16 日起，至 06 月 29 日止，共 14 週。每週六上課，時間皆為早上 9 時至下午 5 時 (共 105 個小時)。招生人數：150 名', '2 樓招生人數：100 名 (得不足額錄取)招生對象：想要學習 AI 的技術研發人員與技術主管。需要參加入學考試。學費標準：每人新台幣 52,000 元，團報達 10 人以上每人新台幣50,000 元。大量團報請另洽專員：02-85123731 #11 （上班時間：週二~六）報名方式：本招生採網路報名，請於報名截止日 2024 年 08 月 14 日前 (含 08/14 當日) 上網填寫報名資料，請完整填寫報名表，以利完成審核程序。入學考試：時間分兩梯次：第一梯次：2024 年 07 月 27', '北部智慧醫療專班第六期招生簡章課程大綱立即報名修課期間： 7/22(六)、7/29(六)、8/05(六)、8/20(日)、8/27(日)上課時間皆為上午九時半至下午六時，共五週（共 37.5 個小時）。主辦單位：財團法人台灣人工智慧學校基金會、林口長庚醫院招生對象：歡迎各界人士報名，錄取審查以醫護人員、生醫產業從業人員、產官學研界從事智慧醫療相關工作之人員優先。招生人數：150 名 (得不足額錄取)學費標準：每人新台幣 18,000 元，團報達 10 人以上每人新台幣 16,000', '2023 年 11 月 20 日前 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。錄取通知及註冊繳費報名後會收到一封報名登記確認信，待通過入學考試後，會再寄一封電子郵件到報名時所留的信箱通知錄取，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '2024/08/10 )和結業典禮( 2024/10/12 )二日課程建議實體上課效果較佳，學校將提供台中(含)以南欲實體出席此二日課程之學員交通費用補助 （憑高鐵票證申請）。結業標準：同時達成以下兩項條件方可獲得數位結業證書：1.上課出席率達課程總時數四分之三2.參與 AI 產業化創新競賽上課地點 (以下為暫定，將視招生人數與場地狀況以行前通知為準)：：中央研究院 (南港) / AIA 台北總校 (板橋)報名方式：本招生採網路報名，請於報名截止日 2024 年 06 月 24', '3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '16 至 29 日提出退費申請者( 2023/06/23～2023/07/06 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2023/07/07~2023/07/21 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/07/22 ~ 2023/07/29 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者(', '2 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '平台大型語言模型實作進階班優秀專題成果於課中分享課程效益能創建企業聊天機器人：設計和開發能夠理解並回應企業內部查詢的聊天機器人。實現機器人與公司資料庫的集成，以提供即時的查詢回應。進行機器人效能測試並根據反饋進行優化。能可微調開源大型語言模型：選擇適合的開源大型語言模型並進行微調，以符合公司特定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關資料集。評估微調後的大型語言模型效能並進行必要的調整。能部署地端大型語言模型程式：架設和配置必要的部署架構，以在地端環境中運行大型語言模型', '台北總校第十八期經理人研修班招生簡章🚀 AIA 經典【經理人週末研修班】課程，全明星級的講師陣容，與時俱進的課程內容，不受地域限制彈性上課，利用14週的週六時間，將各產業人脈與寶貴 AI 知識一網打盡。💪👍🤝課程大綱立即報名主辦單位：台灣人工智慧學校修業期間：自 2023 年 11 月 11 日起，至 2024 年 03 月 09 日止，共 14 週。每週六上課，時間皆為早上 9 時至下午 5 時 30 分(共 105 個小時)。招生人數：150 名', '和大語言模型兩種技術融合在一起，能讓您的辦公室工作更輕鬆、更高效。您可以應用大語言模型來設計和優化您的辦公室流程，讓軟體機器人能夠更準確地執行您想要的任務。您也可以使用軟體機器人來呼叫和使用大語言模型，讓您能夠更快速地完成您需要的語言相關工作。台灣人工智慧學校特別針對大型語言模型開設課程，適合無技術背景，想運用大型語言模型實現自動化流程的所有人。除了認識大型語言模型的運作原理，學習', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學', '年 11 月 18 日 週六 14:00~15:10考試範圍為程式設計，透過線上考試確認應試者的基本能力。程式設計以 Python 作為答題的程式語言，線上考試的形式包括選擇題 (語法相關約10題) 與程式撰寫 (演算法相關約3題)。放榜放榜日期於 11 月 22 日 週三 17:00', '( 台中市北屯區經貿路一段296號 基中大樓2樓 )收費標準( 含證書及學習歷程、午餐、保險；不含住宿與交通 )營隊費用 -  NT$ 12,000早鳥優惠價 - NT$ 10,000 ( 12/18 截止 )三人團報價 - NT$ 10,000 ( 三人以上， 限開同一張發票 )校友家長價 - NT$ 10,000 ( 需附校友學號 )教職員子女優惠單位- NT$ 10,000 -12/30截止 (中國醫藥大學、亞洲大學、逢甲大學、東海大學、中興大學、靜宜大學)', '(4 小時)認識開源大型語言模型 (0.5 小時)：助教/AIA 工程師特定情境問答機器人部署實作 (2 小時)：助教/AIA 工程師分組專題成果發表(1.5小時)：助教/AIA 工程師課程效益能善用 ChatGPT、Claude 、Gemini 等聊天機器人協作日常任務打造結合大型語言模型的辦公室工作流程自動化專案- AI 客服管理工具能運用自帶資料輔助大型語言模型，打造符合個人需求或公司特定應用情境的 AI', '常見問題: 何時會寄發技術領袖全域班入學考試連結?\\n回答: 技術領袖全域班考試連結會於考試前一天17:00前寄發連結並加發簡訊給應考者，線上入學考的連結於考試開始方可登入。', 'ModelsLlama 2: Open Foundation andFine-Tuned Chat Models課程有專題實作與呈現，建議準備網頁或PDF問答資料(網頁示例)用於微調大型語言模型。請學員自備筆電，以便課程學習與小組專題實作。上課環境使用 Google Colab修業日期2024 年 3 月 9 日 ( 六 ) ， 3 月 16 日 ( 六 ) ， 3 月 23 日 ( 六 ) ， 3 月 30 日 ( 六 )共 4 週。上課方式實體課程，上課時間為 9:00-17:30 (', '(具備 Python 程式能力)。入學條件本校 技術領袖班 / 專題實作班 結業之校友 (需於報名時上傳結業證書以供查核)通過本班的入學考試以上兩項滿足一項即可入學學費標準每人新台幣 40,000 元。校友優惠專享每人新台幣 36,000 元。本校各班別結業之校友，於報名時附上學員編號，經查核後得享有校友優惠。團報優惠專享 (5人)每人新台幣 32,000 元。套餐優惠專享同時報名大型語言模型實作初階班 (LLM-A) + 大型語言模型實作進階班 (LLM-B)每人新台幣 44,000', '7 日內提出退費申請者( 2024/02/17 - 2024/02/23 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課日(含)以後提出退費申請者( 2024/02/24 以後 )所收取之當期開班約定繳納費用得全數不予退還。備註：本表所稱「開課日」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程資訊課程名稱大型語言模型實作初階班 (LLM-A)課程時數2週共 14 小時上課方式實體課程上課地點新北市板橋區民族路168號 ( 中華電信學院實驗大樓7樓', '與程式撰寫 (演算法相關約3題)。放榜放榜日期於 11 月 22 日 週三 17:00 後寄發錄取通知公布方式：以電子郵件與簡訊寄發錄取通知。放榜後，考生應主動查詢，獲知錄取後如期辦理註冊，避免因系統擋信或漏信而影響註冊。逾期未註冊者，不得以未接獲通知為由要求補救措施。錄取通知及註冊繳費報名後會收到一封報名登記確認信，待通過入學考試後，會再寄一封電子郵件到報名時所留的信箱通知錄取，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 2 天內', '常見問題: 想報考技術領袖全域班，請問一下 有考古題嗎?\\n回答: 我們沒有考古題。入學考目前focus在基礎的Python, 所以不管是坊間的參考書，\\n或是學校官方網站的建議內容，應該都可以讓學員有能力通過入學考。謝謝', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致影響錄取入學。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造', '所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。退費辦法退費時間學費退還金額於當期課程開課日前', 'AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程成果圖：學員專題成果，地端檢索增強生成 (Retrieval-Augmented Generation, RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10', '30 小時上課方式實體課程上課地點新北市板橋區民族路168號 ( 中華電信學院實驗大樓7樓 ) 適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)入學條件本校 技術領袖班 / 專題實作班 結業之校友 (需於報名時上傳結業證書以供查核)通過本班的入學考試以上兩項滿足一項即可入學課程目標學習 4 大課程主題與方法：理解大型語言模型實作大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程內容理論知識', '2: Open Foundation and Fine-Tuned Chat Models課程有專題實作與呈現，建議準備網頁或PDF問答資料(網頁示例)用於微調大型語言模型。專題實作為分組進行，每組會配置含有 GPU 伺服器。請學員自備筆電，以便課程學習與小組專題實作。請先註冊 kaggle (https://www.kaggle.com/) 並通過手機認證修業日期2023 年 12 月 9 日 ( 六 ) ， 12 月 16 日 ( 六 ) ， 12 月 23 日 ( 六 ) ， 12 月', '14 日 週三 17:00 後寄發錄取通知第二梯次考試於 2023 年 07 月 05 日 週三 17:00 後寄發錄取通知放榜後，考生應主動查詢，獲知錄取後如期辦理註冊，避免因系統擋信或漏信而影響註冊。逾期未註冊者，不得以未接獲通知為由要求補救措施。錄取通知及註冊繳費：報名後會先收到一封【報名登記確認信】，待通過入學考並經學校審核完成，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3', '自動化串接成果示例。課程資訊修業日期週三班：2024 年 07 月 03 日及 07 月 10 日，共 2 日。週六班：2024 年 07 月 06 日及 07 月 13 日，共 2 日。請注意，LLM初階班（週三班、週六班）因為包含分組專題活動，一旦選定上課日期後無法更改。請於選課前謹慎考慮，確認自己的行程是否符合上述日期。備註: 若每班不足30人得延期或併班。校方保留調整班級安排之權利。上課方式實體課程，上課時間為 9:00 - 17:00 ( 提供午餐 ) ，2週共', 'AI 產業化創新競賽者，始發予數位結業證書。本班上課方式為「實體課程」，不提供補課或延期。日期時程表2023 / 07  / 10 報名截止日2023 / 07  / 22 課程開始2023 / 08  / 27 課程結束退費辦\\x08法退費時間學費退還金額於當期課程開課日前 30 日 (含) 以前提出退費申請者( 2023/06/22 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/06/23～2023/07/06', 'hi@aiacademy.tw 聯絡林小姐確認審核。報名方式本招生採網路報名，請於報名截止日 2024 年 2 月 14 日前 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。錄取通知及註冊繳費報名後會收到一封報名登記確認信，待通過入學考試後，會再寄一封電子郵件到報名時所留的信箱通知錄取，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '常見問題: 我已完成報名繳費，何時可以收到發票?\\n回答: 個人用電子發票會於開學後第二週上課日由學務通知領取。\\n公司報帳用電子發票會於開學後第二週由學務 mail 至學員報名時的電子信箱。\\n若需提早或延後開立發票，請發信至hi@aiacademy.tw詢問。', '小時)大型語言模型(LLM) 概論 (1.5 小時)：助教/AIA 工程師大型語言模型(LLM) 運作技術原理(1.5 小時)：助教/AIA 工程師ChatGPT基礎及延伸應用 (3小時)ChatGPT 高效問答術 (1.5 小時)：助教/AIA 工程師ChatGPT 應用程式介面(1.5小時)：助教/AIA 工程師ChatGPT工作流程自動化實作(4小時)自動化原理與相關工具介紹(1.5小時)：助教/AIA 工程師ChatGPT 流程自動化(1.5小時)：助教/AIA', '開課日期: 2023/07/21\\n報名截止日: 2023/07/03\\n課程名稱: ✨⚙️台中分校第十二期產業AI專班（智慧製造）招生簡章⚙️✨\\n上課地點: 台中分校', '或 台北總校報名方式：本招生採網路報名，請於報名截止日 2023 年 06 月 29 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。報名及註冊登記繳費流程：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '常見問題: 結業門檻為何？\\n回答: 智慧醫療專班學員需參與醫療專班創新競賽且缺席時數不超過15小時(含)即可取得結業證書。\\n產業專班及經理人周末研修班學員需參與 AI 產業創新競賽且缺席時數不超過27小時(含)。', '大型語言模型實作初階班 (LLM-A) 招生簡章🚀辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效💪👍🤝課程大綱立即報名-A班A+B 班一起報名課程簡介(因場地限制，目前 A', '提供匯款單或匯款帳號後五碼，匯款手續費請自行負擔，以利我們對帳後更新你的註冊狀態。請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致影響錄取入學。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄', '16 至 29 日提出退費申請者( 2023/06/17～2023/06/29 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2023/06/30～2023/07/14 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/07/15～2023/07/22 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者(', 'Instructions用多個提示讓 ChatGPT 做更深的推理Few shot promptingChain of Thought prompt(思維鏈推理)Chaining Prompts(多個提示鏈)Tree-of Thought辦公室流程自動化ChatGPT輔助辦公室工作流程辦公室流程自動化實作雲端、本機端LLM模型應用開源 LLM 模型介紹雲端聊天機器人體驗地端LLM模型應用專題討論專題討論第二週RPA應用程式介面RPA概念介紹RPA工具- Make', '7 日內提出退費申請者( 2023/07/21～2023/07/27 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2023/07/28～2023/08/03 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2023/08/04～', 'are few-shot learnersTraining language models to follow instructions with human feedbackLLaMA: Open and Efficient Foundation Language ModelsLlama 2: Open Foundation and Fine-Tuned Chat', '(無程式背景可)學費標準每人新台幣15,000元校友優惠專享每人新台幣 13,500 元。本校各班別結業之校友，於報名時附上學員編號，經查核後得享有校友優惠。團報優惠專享 (5人)每人新台幣 12,000 元。套餐優惠專享大型語言模型實作初階班 (LLM-A) + 大型語言模型實作進階班 (LLM-B)每人新台幣 44,000 元。初階班+進階班 線上報名：https://neti.cc/ba1D2ZY有關初階班+進階班課程退費辦法：於當期課程開課日前 7 日內提出退費申請者(', '開課日期: 2023/07/22\\n報名截止日: 2023/07/10\\n課程名稱: 北部智慧醫療專班第六期招生簡章\\n上課地點: 台北總校', '等。以下為參考閱讀文獻：Attention Is All You NeedImproving Language Understanding by Generative Pre-TrainingLanguage Models are Unsupervised Multitask LearnersLanguage models are few-shotlearnersTraining language models tofollow instructions with human', '大型語言模型實作初階班 (第四期) 招生簡章🚀透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。💪👍🤝課程大綱立即報名課程簡介您是否曾經為了重複性的辦公室工作而感到煩悶？您是否想要利用最新的人工智慧技術來提升您的工作品質和效率？如果您的答案是肯定的，您一定要了解「辦公室流程自動化」和「大型語言模型」協作的優勢。辦公室流程自動化(RPA)- 使用軟體機器人執行重複性任務- 包括填寫表單、發送電子郵件、處理文件等-', '即戰力！💪👍🤝課程大綱立即報名修業期間：自 2023 年 7 月 15 日起，至 10 月 28 日止，每週週三、週五、週六三天全天上課。上課方式：實體課程結合線上課程。週三以線上課程進行，週五週六為實體課程。每天上課時間為早上 9:30 到下午 5:00。※ 9/15、9/16 停課，09/29、09/30 中秋連假，9/23 補班日為上課日。實體課程可選擇之地點：台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓 台灣人工智慧學校台中分校 |', '48,000 元，報名回訓八天課程(含年會)：08/12、08/18、08/19、08/25、08/26、09/01、09/15、09/16，每人新台幣 27,000 元。 (校友報名皆需附上學員編號以供查核)。上課地點：台中市北屯區經貿路一段 296 號 基中大樓 2F報名方式：本招生採網路報名，請於報名截止日2023 年 07 月 03', '大型語言模型實作進階班 (第二期) 招生簡章🚀透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。💪👍🤝課程大綱立即報名課程簡介基於上百家企業需求想要用大型語言模型建置企業內部的「企業大腦」，因各企業的資料有機敏性與獨特性，無法使用公開的大型語言模型。此外微調及部署大型語言模型服務有一定的門檻在，不論是在設備上、資料處理上、技術上等。台灣人工智慧學校深知大型語言模型在當今 AI', '需 M1晶片以上)AnythingLLM請學員自備筆電，以便課程學習與小組專題實作。(Mac 建議 M1晶片以上, Nvidia 顯卡, 記憶體16GB 以上)前幾期小組成果發表主題年節賀卡圖片生成推播專案績效 AI 評分管理系統旅遊行程規劃推播法人金融報告流程自動化課程滿意度問卷流程自動化房屋建案資訊推播與問答語音檔轉會議紀錄自動化早安詩小話家郵件內容條列整理推播長輩圖新聞 Provider可愛喵喵天氣推播LINE 工作群請假/外出系統快速依據圖片建立文案AI', '2023/06/16 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/06/17～2023/06/30 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2023/06/30～2023/07/14 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/07/15～2023/07/21 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8', '林小姐確認審核。報名方式本招生採網路報名，請於報名截止日 2024 年 6 月 24 日前 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。註冊繳費報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', ')應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2024/01/28～2024/02/24 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2024/02/25～ )所收取之當期開班約定繳納費用得全數不予退還。※ 備註：本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '小時)：助教/AIA 工程師微調大型語言模型 (6 小時)：助教/AIA 工程師問答機器人 (2 小時)：助教/AIA 工程師部署大型語言模型(2 小時)：助教/AIA 工程師專題實作 (4 週，時數 8 小時)專題實作引導 (4 小時)：助教/AIA 工程師專題成果分享 (4 小時)：助教/AIA 工程師專題演講專題演講：3場專門領域教授、業界實務經驗專家技術班全域班第三期 LLM 優秀專題成果於課中分享課程大綱立即報名-B班A+B 班一起報名', '常見問題: 開學前申請轉班\\n回答: 技術班轉經理人班，我們需要檢視您的職級職位作審核。\\n經理人班轉技術班，我們會看您的背景及程式能立，方能決定是否安排入學考試。', '2024 年 07 月 22 日前 (含 07/22 當日) 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。註冊繳費報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。手把手課程須自備筆電，以利課程進行。本課程放假日期：9/28', '常見問題: 請問要結業的其中一項是繳交競賽的報告，若團隊中有人幾乎0互動，\\n在現在幾乎是線上上課也只能線上互動的，好像完全沒有約束力\\n回答: 請組長分配給所有組員該負責的任務，若有組員拒不合作，再請組長私訊告知，我們再去與該學員私下勸說。我們又會有組員互評機制。謝謝', '技術領袖培訓全域班第三期招生簡章🚀AIA 經典課程強勢回歸，為企業培育上千名 AI 技術人才的技術領袖培訓班！上課不受地域限制，可以選擇北中南任一分校上課，並且採線上與實體混合課程，課程進行更為彈性。完整的理論課程，搭配題材豐富的練習以及手把手教學，最後進行專題實作，解決業界學界的真實問題，讓您在四個月的課程後，有最紮實的 AI 基本功以及 AI 即戰力！💪👍🤝課程大綱立即報名修業期間：自 2023 年 7 月 15 日起，至 10 月 28', '聯絡林小姐確認審核。報名方式本招生採網路報名，請於報名截止日 2024 年 4 月 8 日前 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。錄取通知及註冊繳費報名後會收到一封報名登記確認信，待通過入學考試後，會再寄一封電子郵件到報名時所留的信箱通知錄取，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', '(匯款手續費請自行負擔)，以利我們對帳後更新你的註冊狀態，請務必在繳費期限內完成匯款繳費，繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者', '恕不另行通知。請先註冊ChatGPT(https://chat.openai.com/auth/login) 及事先購買Midjourney (https://www.midjourney.com/)▲上課需事先購買Midjourney訂閱方案 (最低月費為10美金)線上預習課程 ( 預計 7/15 會寄通知信到報名者信箱 )為保障您的權益及確保處理效率，如有任何疑問，敬請直接來電 06-2794380，或寄信至 camp@aiacademy.tw，將有專人為您服務，謝謝您。', '9 時至下午 5 時 30 分( 共105個小時)。招生人數：150 名 (得不足額錄取)招生對象：在職人士且任管理職位者優先錄取，全域招生不限台北。學費標準：每人新台幣 48,000 元團報每人新台幣 46,000 元 (10 人以上)大量團報請另洽專員：02-85123731', '常見問題: 請問智慧醫療專班這門課有要求學員會哪一種程式語言嗎?謝謝\\n回答: 智慧醫療專班這門課是為了要讓醫學相關領域的專業人士能更快速的掌握人工智慧的知識及資訊，而非專精於程式語言的學習。\\n因此並無特別需要學會哪一種程式語言。\\n相關的課程訊息也歡迎您參考：https://aiacademy.tw/curriculum-med/\\n若還有其他的疑問也歡迎與我們聯繫。', '日 週六 14:00~15:10 ( 2023/12/15 至 2024/01/04 當天報名者 )考試內容：以程式設計為主，希望確認應試者的程式設計能力，以Python作為作答的程式語言。考試的形式包括選擇題與程式撰寫。更多考試須知請點這裏第一次入學考未通過的考生，我們將主動通知您再參加第二梯次入學考試。錄取通知：(以電子郵件與簡訊寄發)第一梯次考試於 2023 年 12 月 20 日 週三 17:00 後寄發錄取通知第二梯次考試於 2024 年 01 月 10 日 週三 17:00', '年 02 月 24 日及 03 月 02 日，共 2 日。上課方式實體課程，上課時間為 9:00 - 17:00 ( 提供午餐 ) ，課程時數 14 小時。上課地點新北市板橋區民族路168號 ( 中華電信學院實驗大樓7樓 )招生人數96 名 ( 得不足額錄取 )招生對象對辦公室自動化及大型語言模型應用有興趣者 (無程式背景可)學費標準每人新台幣 15,000 元若同時報名初階班 (LLM-A) + 進階班 (LLM-B) ，並錄取通過，則二班課程享原價 八 折( 新台幣 44,000 元', '如何核實校友身分?: 數位結業證書申請補發?\\n具備台灣人工智慧學校結業證書者。: 申請證書，需收取500元申請費用，將開立發票，請提供發票寄件地址。', '台北總校第十六期經理人研修班招生簡章🚀 AIA 經典【經理人週末研修班】課程，全明星級的講師陣容，與時俱進的課程內容，不受地域限制彈性上課，利用14週的週六時間，將各產業人脈與寶貴 AI 知識一網打盡。💪👍🤝課程大綱立即報名主辦單位：台灣人工智慧學校修業期間：自 2023 年 07 月 15 日起，至 10 月 28 日止，共 14 週。每週六上課，時間皆為早上 9 時至下午 5 時 30 分( 共105個小時)。招生人數：150 名', '何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。退費辦法退費時間學費退還金額於當期課程開課日前15日', '常見問題: 請問你們所有課程都有提供午餐嗎？\\n回答: 因為我們的班別有經理人周末研修班、技術領袖全域班、智慧醫療專班和產業專班，目前只有經理人周末研修班/智慧醫療專班和產業專班有提供午餐。', '響錄取。報名登錄資料之通訊地址、電話號碼及電子郵件地址應正確，若無法通知而延誤繳費期限，其後果需自行負責。逾期繳費者，視為放棄錄取資格，該名額由備取依序遞補。報名及註冊登記繳費流程報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流', 'AI 平台架設生成式 AI 平台LangChain 概述LangChain 介紹及應用基本 LangChain 套件使用第二週資料處理及連接Data ConnectionLangChain 使用及應用AgentMemoryCallback企業案例應用 + 題目及解析LangChain 實例解析使用 LangChain 實作相關企業案例LangChain 與 RAG檢索增強 (Retrieval Augmented Generation, RAG) 介紹使用 Langchain 實現', 'AI 繪圖概述吳承澔台灣人工智慧學校 AI 工程師逢甲大學資訊工程學系碩士逢甲大學人工智慧中心研究生過去研究主題：醫療病例實體間的時序關係預測曾參與相關專案：使用者興趣分析、駕駛油耗預測、圖像異常檢測、醫療實體時序預測圖片活起來：從圖片到影片的技巧※ 學校保有修改、變更課程內容之權利。實作課程表手機螢幕建議使用水平橫式瀏覽時間1/30 (二)1/31 (三)2/1 (四)地點台灣人工智慧學校台中分校台灣人工智慧學校台中分校台灣人工智慧學校台中分校主題AI 文字生成魔法AI', '常見問題: 如何補刷\\n回答: 可使用報到處的平板補刷或是發信至hi@aiacademy.tw /私訊台灣人工智慧學校學務，並提供你的學號/姓名及補刷時間，即可。以上資訊供您參考，若您還有其他疑問也歡迎再與我們聯繫。', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍', '3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至 :玉山銀行 南港分行 金融機構代碼：808 1182戶名：財團法人台灣人工智慧學校基金會帳號：1182-940-016585※ 注意：選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw', '常見問題: 申請退費\\n回答: 親愛的學員你好，很遺憾你無法與我們一起為接下來的課程努力。\\n退費的標準，我們會依照學員手冊退費辦法辦理。\\n此外，請將學員證與發票退回至行政人員，也請告知匯款帳戶，以利我們作業。', '定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關數據集。評估微調後的大型語言模型效能並進行必要的調整。能部署地端大型語言模型程式：架設和配置必要的部署架構，以在地端環境中運行大型語言模型。確保模型部署的安全性和效能，包括資料保護和效能優化。進行系統測試並解決任何出現的技術問題。課前準備建議課前請有先備知識例如：Transformer,', '大型語言模型實作進階班 (LLM-B) 招生簡章🚀辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效💪👍🤝課程大綱立即報名-B班A+B 班一起報名課程簡介基於上百家企業需求想要用大型語言模型建置企業內部的「企業大腦」，因各企業的資料有機敏性與獨特性，無法使用公開的大型語言模型。此外微調及部署大型語言模型服務有一定的門檻在，不論是在設備上、資料處理上、技術上等。台灣人工智慧學校深知大型語言模型在當今 AI', '提供匯款單或匯款帳號後五碼，以利我們對帳後更新你的註冊狀態。請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致影響錄取入學。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽', '以前提出退費申請者( 2023/10/13 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/10/14～2023/10/26 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2023/10/27～2023/11/10 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/11/11～2023/11/18', '址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。手把手課程須自備筆電學員出席率達四分之三上課時數並參與', '常見問題: 如何繳費?\\n回答: 您好，請發信至 hi@aiacademy.tw 並提供您的姓名及報名時填寫的電子郵件信箱。我們會於系統更新你的審核狀態並重新寄發{報名及註冊的登記已可進行下一步報名作業}至您的電子信箱。若您報名的是經理人週末研修班或技術領袖全域班獲錄取者，請於收到錄取通知後 3 天內完成註冊繳費。繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。\\n若選擇臨櫃匯款者，請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。\\n注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw 提供匯款單或匯款帳號後五碼，以利我們對帳後更新你的註冊狀態。', '| 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓 台灣人工智慧學校台中分校 | 中國醫藥大學校本部基中大樓地址：台中市北屯區經貿路一段296號 2 樓 台灣人工智慧學校南部分校 | 沙崙科學城 資安暨智慧科技研發大樓地址：台南市歸仁區歸仁十三路一段6號 6 樓招生人數：100 名 (得不足額錄取)招生對象：想要學習 AI 的技術研發人員與技術主管。需要參加入學考試。學費標準：每人新台幣 48,000 元。 團報達十人每人新台幣 46,000', '等聊天機器人協作日常任務打造結合ChatGPT的辦公室工作流程自動化專案- AI 客服管理工具能運用自帶資料輔助大型語言模型，打造配適個人需求或公司應用情境的AI助理能了解如何將問答機器人部署為應用程式介面透過小組專題實作與成果分享，增進專題實作能力課前準備建議課前先使用gmail信箱註冊以下平台OpenAIMake請學員自備筆電，以便課程學習與小組專題實作修業日期 2024 年 04 月 17 日及 04 月 24 日，共 2 日。上課方式實體課程，上課時間為 9:00 - 17:00 (', '(0.5 小時)：助教/AIA 工程師特定情境問答機器人部署實作 (2 小時)：助教/AIA 工程師分組專題成果發表(1.5小時)：助教/AIA 工程師課程大綱立即報名', '大課程主題與方法：理解大型語言模型微調大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程效益能創建企業聊天機器人：設計和開發能夠理解並回應企業內部查詢的聊天機器人。實現機器人與公司數據庫的集成，以提供實時的查詢回應。進行機器人效能測試並根據反饋進行優化。能可微調開源大型語言模型：選擇適合的開源大型語言模型並進行微調，以符合公司特定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關數據集。評估微調後的大型語言模型效', '年 07 月 27 日 週六 14:00~15:10 ( 含 07/24 當日 ) 以前的報名者第二梯次：2024 年 08 月 17 日 週六 14:00~15:10 ( 07/25 至 08/14 當天報名者 )考試內容：以程式設計為主，希望確認應試者的程式設計能力，以Python作為作答的程式語言。考試的形式包括選擇題與程式撰寫。更多考試須知請點這裏第一次入學考未通過的考生，我們將主動通知您再參加第二梯次入學考試。錄取通知：(以電子郵件與簡訊寄發)第一梯次考試於 2024 年 07 月', '✨⚙️台中分校第十二期產業 AI 專班（智慧製造）招生簡章 ⚙️ ✨🚀 全明星級的講師陣容，與時俱進的課程內容，創新多樣化的授課形式，時間濃縮精彩加倍，利用每週兩天、一共 8 週 16 天的學習時間，將人脈網絡與寶貴知識一網打盡，畢其功於一役。💪👍🤝課程大綱立即報名主辦單位：台灣人工智慧學校修業期間：自 2023 年 07 月 21 日起，至 09 月 16 日止，共 8 週。每週五、週六上課，時間皆為早上 9 時至下午 5 時 30 分 ( 共120個小時)。招生人數：150 名', '7 日內提出退費申請者( 2023/11/11～2023/11/18 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2023/11/19～2023/12/08 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2023/12/09～', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致影響錄取入學。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造', '技術領袖培訓全域班第四期招生簡章🚀AIA 經典課程強勢回歸，為企業培育上千名 AI 技術人才的技術領袖培訓班！上課不受地域限制，可以選擇北部中部任一分校上課，並且採線上與實體混合課程，課程進行更為彈性。完整的理論課程，搭配題材豐富的練習以及手把手教學，最後進行專題實作，解決業界學界的真實問題，讓您在四個月的課程後，有最紮實的 AI 基本功以及 AI 即戰力！💪👍🤝課程大綱立即報名修業期間：自 2024 年 01 月 20 日起，至 2024 年 05 月 24', '址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。手把手課程須自備筆電學員出席率達四分之三上課時數並參與', '2023/11/26～2023/12/01 )，應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者 ( 2023/12/02以後 )，所收取之當期開班約定繳納費用得全數不予退還。報名方式本招生採網路報名，請於報名截止日 2023 年 11 月 16 日前 (含 11/16 當日) 上網填寫報名資料。請完整填寫報名表，以利完成審核程序。入學考試考試時間分：2023 年 11 月 18 日 週六', '常見問題: 我已過繳費期限?\\n回答: 因原先繳費期限已過期，請發信至 hi@aiacademy.tw 並提供您的姓名及報名時填寫的電子郵件信箱。我們將會重新寄發{報名及註冊的登記已可進行下一步報名作業}信件至您的電子信箱。', '開課日期: 2023/07/15\\n報名截止日: 2023/06/29\\n課程名稱: 技術領袖培訓全域班第三期招生簡章\\n上課地點: 全域班別', '2023/08/04～ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '常見問題: 結業證書寄送問題\\n回答: 學校將於結業典禮後㇐週內以電子郵件寄發圖靈數位證書至您提供的電子信箱', '9:00 - 17:00 ( 提供午餐 ) ，2週共 14小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象對辦公室自動化及大型語言模型應用有興趣者 ( 無程式背景可 )課程目標了解大型語言模型的原理和功能熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程內容ChatGPT基礎及延伸應用 (5 小時)ChatGPT 高效問答術', '常見問題: 為何我未錄取經理人周末研修班?\\n回答: 謝謝您的來信。由於報名實在太熱烈及踴躍、報考者都十分優秀，我們能錄取的考生非常有限，不免會有遺珠之憾，對於經理人週末研修班，校方希望提供給在職人士進修與推動產業轉型AI機會， 台灣人工智慧學校經理人班審查標準有二： 1. 從事AI相關工作經理人 2. 具備決策權與預算權的經理人 3. 若以上兩者符合，根據職稱高低以及公司產業別排序 非常的可惜未能錄取所有優秀的報考者，我們期待您未來的參與。建議報考者能就近多利用其他分校，希望及歡迎您報名其他分校或再次報考下一梯次的經理人週末研修班。', '智慧製造實務案例分享及應用，目前講師還在安排調整，官網只會放上課程大綱，待開課前會寄出學員手冊，裡面的課程表會有當期課程講義及授課講師，屆時再提供您參考', 'AI 領域的重要性，因此特別開設此課程。本課程旨在讓學員不只理解大型語言模型的基本原理，更透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。我們期望，透過這樣的完整培訓，能為未來的 AI 領域孕育更多的專業人才，共同推進這一革命性技術的進步。課程目標學習 4', '開課日期: 2024/03/16\\n報名截止日: 2024/03/04\\n課程名稱: 台北總校第十九期經理人週末研修班招生簡章\\n上課地點: 全域班別', '日提出取消，退回報名費八成。營隊開始前 2 日至 20 日提出取消，退回報名費七成。營隊開始前 1 日提出取消，退回報名費五成。營隊活動當日及開始後，恕無法退費。如遇天災及不可抗力因素，人事行政局宣布停班停課，導致營隊取消時，若活動尚未開始，將扣除行政手續費 500', '常見問題: 常見問題\\n回答: 回答', '學校保有修改、變更課程內容之權利。修業期間自 2023 年 07 月 01 日（週六）上課，上午 9 時至下午 5 時。招生人數60 名 (得不足額錄取)招生對象社會在職人士與任何對 ChatGPT 有興趣者皆可參加學費標準每人新台幣 3,500 元 ，衝擊工作坊優惠價$3,000 (有參加過春季或夏季場工作坊者)上課地點台中市北屯區經貿路一段 296 號 基中大樓 2F報名方式採網路報名，請於報名截止日 2023 年 06 月 28 日前', '活動或任務，以達成特定的業務目標。這些活動或任務包括填寫表單、發送電子郵件、處理文件、產生報告等。辦公室流程自動化可以幫助您減少錯誤、節省時間、降低成本、提升生產力。「大型語言模型」是一種利用深度學習方法訓練的人工智慧系統，能夠理解和生成我們日常使用的語言，並能處理各種與語言相關的任務，如翻譯、撰寫摘要、進行對話和創作等。這種模型可以提升您的語言技能、創新能力、溝通效果和競爭優勢。辦公室流程自動化和大語言模型兩種技術融合在一起，能讓您的辦公室工作更輕鬆、更高效。您可以應用大語言模型來設計和優化您', '(六) AIA年會(暫定)，停課一次。實際放假日期依課表為主。日期時程表2024 / 06  / 24報名截止日2024 / 07  / 06課程開始2024 / 10  / 12課程結束議程表退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2024/06/06 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2024/06/07～2024/06/20 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15', ')應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2024/03/01 ~2024/03/15 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2024/03/16 ~ 2024/03/23 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2024/03/24 ~ 2024/04/20', '模型開發客服機器人RAG實作專題實作討論與成果發表分組專題實作討論小組實作成果分享注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律', '10,000 -12/30截止 (中國醫藥大學、亞洲大學、逢甲大學、東海大學、中興大學、靜宜大學) 需出示相關證明文件檔案在報名時上傳提供審核。清寒生免費：為鼓勵清寒、中低／低收入戶、特殊境遇家庭學生報名，主辦單位將予以補助免收該學生參加本次研修之費用。請學生將戶籍所在地之縣、市政府社會局發給之清寒、中低／低收入、特殊境遇家庭相關證明文件檔案在報名時上傳提供審核(名額有限)。錄取人數70 名 (得不足額錄取)招生對象高中職在學或國高中應屆畢業生( 需自備筆電 )、清寒家庭免費( 學校將借用筆電', '產業應用智慧對話全面性的資訊服務相關實例分享成果發表注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程', '常見問題: 如何請假?\\n回答: 若學員因故有請假需求，請填妥請假表單進行申請 https://reurl.cc/xZNOAL校務行政處核可後，系統將會直接寄送請假核可通知至您的信箱中。請假申請審核過後，仍計入缺席時數。本課程無補課機制。', 'AIA 台北總校 (板橋)報名方式：本招生採網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。報名及註冊登記繳費流程：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至', '( 三人以上， 限開同一張發票 )校友家長價 - NT$ 10,000 ( 需附校友學號 )清寒生免費：為鼓勵清寒、中低／低收入戶、特殊境遇家庭學生報名，主辦單位將予以補助免收該學生參加本次研修之費用。請學生將戶籍所在地之縣、市政府社會局發給之清寒、中低／低收入、特殊境遇家庭相關證明文件檔案在報名時上傳提供審核。錄取人數60 名 (得不足額錄取)招生對象高中職在學或國高中應屆畢業生( 需自備筆電 )、清寒家庭免費( 學校將借用筆電 )報名規定本活動招生採網路報名，請於截止日 2023 年 7', 'RAG) 串接資料庫進行資料檢索。課程資訊修業日期2024 年 8 月 03 日 ， 8 月 10 日， 8 月 17 日 ， 8 月 24 日 每週六，共 4 週。上課方式實體課程，上課時間為 9:00 - 17:30 ( 提供午餐 ) ，4週共 30小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓適合對象具有 AI 基本知識的技術研發人員與主管 (具備 Python 程式能力)本課程涵蓋程式實作及模型微調，授課將運用 LangChain', '開課日期: 2024/08/24\\n報名截止日: 2024/08/07\\n課程名稱: 技術領袖培訓全域班第五期招生簡章\\n上課地點: 全域班別', '招生簡章🚀辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效💪👍🤝課程大綱立即報名課程簡介辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效您是否曾經為了重複性的辦公室工作而感到煩悶？您是否想要利用最新的人工智慧技術來提升您的工作品質和效率？如果您的答案是肯定的，請一定要了解「辦公室流程自動化」和「大型語言模型」協作的優勢。「辦公室流程自動化」是指使用軟體機器人來執行一系列相互關聯的活動或任務，以達成特定的業務目標。這些活動或任務包括填寫表單、發送電子郵件、處理文件、產生報告等。辦', '2024 年 01 月 04 日前 (含 01/04 當日) 上網填寫報名資料，請完整填寫報名表，以利完成審核程序。入學考試：時間分兩梯次：第一梯次：2023 年 12 月 16 日 週六 14:00~15:10 ( 含 12/14 當日 ) 以前的報名者第二梯次：2024 年 01 月 06 日 週六 14:00~15:10 ( 2023/12/15 至 2024/01/04 當天報名者', '日及 04 月 24 日，共 2 日。上課方式實體課程，上課時間為 9:00 - 17:00 ( 提供午餐 ) ，課程時數 14 小時。上課地點台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓招生人數55 名 ( 得不足額錄取 )招生對象對辦公室自動化及大型語言模型應用有興趣者 (無程式背景可)學費標準每人新台幣 15,000 元校友優惠專享每人新台幣 13,500 元。本校各班別結業之校友，於報名時附上學員編號，經查核後得享有校友優惠。團報優惠專享 (', 'Provider可愛喵喵天氣推播LINE 工作群請假/外出系統快速依據圖片建立文案AI 命理大師在職進修課程推薦系統課程照片課程大綱週別課程主題內容大綱第一週ChatGPT 高效問答術 (Prompt engineering)了解 LLM 的基本概念學習 LLM 的使用時機和方法讓 ChatGPT 角色扮演，得到更高品質的回應用模板和例子指導 ChatGPT，讓它執行你的任務Custom Instructions用多個提示讓 ChatGPT 做更深的推理Few shot', ')應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8 日起，且未達全期三分之一期間內提出退費申請者( 2023/07/22～2023/08/12 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2023/08/13～ )所收取之當期開班約定繳納費用得全數不予退還。', '大型語言模型實作初階班 (第三期)', 'AI 課蔡宗翰中研院 GIS 中心研究員中央大學資工系教授中研院人社中心研究員、中央大學資工系教授、人工智慧學會副理事長、數位人文學會理事長、教育部大專校院人工智慧競賽（AI CUP）計畫主持人。如何與AI和平共處？侯宜秀財團法人台灣人工智慧學校基金會 秘書長律師，專注科技創新及智慧財產法律。目前擔任台灣人工智慧學校基金會秘書長、立法院開放國會委員會委員。2019 年起擔任 g0v 揪松團輪值主席，並發起零時小學校。活用 ChatGPT', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍', '總校長長期專注在國際教育、語言教育、與科技教育與創新領域。目前擔任葳格國際學校的總校長與1111生成式AI創新學院的執行長，致力推廣AIGC相關應用。他擁有全民英檢和TOEIC的全數滿分，並且是台灣僅有的五位多益官方講師之一。從零開始的 ChatGPT黃冠華台灣人工智慧學校 AI 工程師台灣人工智慧學校台中分校 AI工程師東海大學資工所，研究領域強化學習，電腦視覺圖片魔法: AI 繪圖概述吳承澔台灣人工智慧學校 AI', '年 11 月 25 日及 12 月 2 日，共 2 日。上課方式實體課程，上課時間為 9:00-17:00 ( 提供午餐 ) ，課程時數 14 小時。上課地點中研院人文館 第二會議室 ( R2 ) | 台北市南港區研究院路2段128號招生人數105 名 (得不足額錄取)※ 此課程有場地及人數的限制， 11/4 以後報名者暫列為候補，預計將於11/22下午五點後，以電子郵件及簡訊通知您，若有名額將通知您完成繳費。招生對象對辦公室自動化及大型語言模型應用有興趣者', '~ 16:00休息休息16:00 ~ 16:50【成品分享時間】【成品分享時間】※ 學校保有修改、變更課程內容之權利。營隊證書與學習歷程請確認活動期間可以全程參與，全程參與者可領取營隊證書及學習歷程各一份。因故離營須填寫請假單，病假請檢附就醫證明，請假時數：事假累計達4 小時僅發給學習歷程，不發給營隊證書；6 小時以上營隊證書及學習歷程均不發給。病假累計達7 小時僅發給學習歷程，不發給營隊證書；9 小時以上營隊證書及學習歷程均不發給。合作飯店優惠住宿聯絡資訊智選假日酒店 (', '2024 年 08 月 31 日起，至 2024 年 12 月 14 日止，每週週三、週五、週六三天全天上課。上課方式：實體課程結合線上課程。週三以線上課程進行，週五週六為實體課程。每天上課時間為早上 9:30 到下午 5:00。實體課程可選擇之地點：台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓台灣人工智慧學校台中分校 | 中國醫藥大學校本部基中大樓地址：台中市北屯區經貿路一段296號 2 樓招生人數：100 名 (得不足額錄取)招生對象：想要學習', '7 日內提出退費申請者( 2024/03/09～2024/03/15 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期二分之一以上提出退費申請者( 2024/03/16 ~ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期二分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程資訊課程名稱大型語言模型實作進階班 (LLM-B)課程時數4週共 30 小時上課方式實體課程上課地點新北市板橋區民族路168號 ( 中華電信學院實驗大樓7樓', '~ 13:50【實作課程】角色扮演: 透過模板指令掌握工作技巧【實作課程】Midjourney 大揭密 : 通往AI繪畫大師的方法【創意發想】分組競賽 ( 一組分享10分鐘 )13:50 ~14:00休息休息14:00 ~ 14:50【實作課程】高效能工作大腦【實作課程】Midjourney 進階魔法 : 成為魔法師14:50 ~ 15:00休息休息休息15:00 ~ 15:50【專題時間】小組討論與實作【專題時間】小組討論與實作【結業式】15:50 ~ 16:00休息休息16:00 ~', '大語言模型來設計和優化您的辦公室流程，讓軟體機器人能夠更準確地執行您想要的任務。您也可以使用軟體機器人來呼叫和使用大語言模型，讓您能夠更快速地完成您需要的語言相關工作。台灣人工智慧學校特別針對大型語言模型開設課程，適合無技術背景，想運用大型語言模型實現自動化流程的所有人。除了認識大型語言模型的運作原理，學習', '02 月 17 日 週六 17:00 後寄發錄取 / 未錄取通知公布方式：以電子郵件與簡訊寄發錄取通知。放榜後，考生應主動查詢，獲知錄取後如期辦理註冊，避免因系統擋信或漏信而影響註冊。逾期未註冊者，不得以未接獲通知為由要求補救措施。錄取通知及註冊繳費報名後會收到一封報名登記確認信，待通過入學考試後，會再寄一封電子郵件到報名時所留的信箱通知錄取，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3 天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流', '9 時至下午 5 時 30 分 ( 共120個小時)。招生人數：150 名 (得不足額錄取)招生對象：製造業在職人士且任管理職位者優先錄取。適合企業中高階專業經理人能一同帶領2位以上工程師共同參與。學費標準：每人新台幣 50,000 元，團報達 10 人以上每人新台幣 48,000 元。大量團報請另洽專員：04-2298-6620校友回訓優惠：校友報名全部課程享有優惠價每人新台幣 48,000', 'ChatGPT 提問技巧外，您還將透過自動化平台工具串接 ChatGPT 與其他生產力工具，提升職場工作效率。課程也帶您運用其他開源大型語言模型，結合自己的文件資料，建立特定情境下的問答機器人，透過專題實作為您的職涯加分! 課程目標了解大型語言模型的原理和功能熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程效益能善用ChatGPT、Bing、Claude', '2023/12/09～ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '活動或任務，以達成特定的業務目標。這些活動或任務包括填寫表單、發送電子郵件、處理文件、產生報告等。辦公室流程自動化可以幫助您減少錯誤、節省時間、降低成本、提升生產力。「大型語言模型」是一種利用深度學習方法訓練的人工智慧系統，能夠理解和生成我們日常使用的語言，並能處理各種與語言相關的任務，如翻譯、撰寫摘要、進行對話和創作等。這種模型可以提升您的語言技能、創新能力、溝通效果和競爭優勢。辦公室流程自動化和大語言模型兩種技術融合在一起，能讓您的辦公室工作更輕鬆、更高效。您可以應用大語言模型來設計和優化您', 'AI 講者的演說與案例發表，即時掌握智慧製造應用趨勢。同時安排學員進行深入的專題討論，將課堂的知識運用於專題及實作，領略這些技術的實際應用方式及限制，並讓學員間有深入的交流分享。課程效益：瞭解與轉譯實務議題與 AI 技術之間的關聯性，掌握可用的技術／工具。企業中高階專業經理人、同業之間相互標竿學習，縮短學習曲線，減少重複犯錯的成本。全新的案例導向聚焦，實地參訪交流，給產業一個獨一無二的學習體驗！退費辦法退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者(', '天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流 (轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。課前準備建議課前請有先備知識例如：Transformer, GPT, fine-tuning, Hallucinations 等。以下為參考閱讀文獻：Attention Is All You NeedImproving', 'AI 技術之間的關聯性，掌握可用的技術／工具。企業中高階專業經理人、同業之間相互標竿學習，縮短學習曲線，減少重複犯錯的成本。全新的案例導向聚焦，實地參訪交流，給產業一個獨一無二的學習體驗！退費辦\\x08法退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2023/04/12 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/04/13～2023/04/26 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15', 'AI 產業化創新競賽者，始發予數位結業證書。本課程放假日期：09/08～09/09停課。實際放假日期依課表為主。日期時程表2023 / 07  / 03報名截止日2023 / 07  / 21課程開始2023 / 09  / 16課程結束課程目標：課程涵蓋 AI 在製造業的各層面，從科普理論擴展到實務議題，讓學員快速進入製造業應用場景，以產業深化案例與校友經驗分享引導、手把手體驗，移地學習，啟發中高階經理人能 lead AI project。課程簡介：2022 年，AIA', '的定義和應用範圍ChatGPT 如何提高工作效率什麼是 Prompt使用 Prompt 對 ChatGPT 作用10：00 ~ 10：50ChatGPT 指南如何使用 ChatGPT 平台如何將文本輸入到 ChatGPT 中11：00 ~ 11：50工作情境在不同的工作情境中使用 ChatGPTChatGPT 如何提供智能建議和解決方案，例如展覽、企劃、說故事13：00 ~ 13：50角色扮演: 透過模板指令掌握工作技巧如何使用模板指令來定制 ChatGPT', 'AIGC 實戰工作坊：ChatGPT X 智慧工作新世紀AIGC 實戰工作坊首波主題是 ChatGPT，由 AIA 工程師帶領從零開始的 ChatGPT 指南，讓身為辦公室上班族的您結合情境應用，瞬間化身不同角色，從了解 ChatGPT 的 Prompt 模板，到學會駕馭您的 AI 個人助理，有效減輕工作負擔，瞬間提升工作效率 50% up!立即報名課程簡介本課程將教你如何使用 ChatGPT 平台，從文本輸入到工作情境的應用，讓你在不同的工作場景中熟練使用 ChatGPT', '開課日期: 2024/07/03\\n報名截止日: 2024/06/24\\n課程名稱: 大型語言模型實作初階班(第四期)招生簡章\\n上課地點: 全域班別', 'PDF、圖片格式等電子檔)上傳或繳交資料不齊或不符規定者，視同未完成報名。欲參加者請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符而影響錄取。報名登錄資料之通訊地址、電話號碼及電子郵件地址應正確，若無法通知而延誤繳費期限，其後果需自行負責。逾期繳費者，視為放棄錄取資格，該名額由備取依序遞補。報名及註冊登記繳費流程報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者', '(含) 以前提出退費申請者( 2023/06/22 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/06/23～2023/07/06 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2023/07/07～2023/07/20 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/07/21～2023/07/27', '常見問題: 為何我未通過技術領袖全域班入學考試?\\n回答: 謝謝您的來信。很遺憾您未通過技術領袖全域班入學考試。\\n試題中，選擇題與程式題各佔50分，總分為100分，本期考生的程度都相當好，在參酌其他考生的成績後，我們會擇優錄取。', '| 中國醫藥大學校本部基中大樓地址：台中市北屯區經貿路一段296號 2 樓招生人數：100 名 (得不足額錄取)招生對象：想要學習 AI 的技術研發人員與技術主管。需要參加入學考試。學費標準：每人新台幣 52,000 元，團報達 10 人以上每人新台幣50,000 元。大量團報請另洽專員：02-85123731 #11 （上班時間：週二~六）報名方式：本招生採網路報名，請於報名截止日 2024 年 01 月 04 日前 (含 01/04 當日)', 'Prompt Engineering 技能AI 繪圖概論吳承澔台灣人工智慧學校 AI 工程師逢甲大學資訊工程學系碩士逢甲大學人工智慧中心研究生過去研究主題：醫療病例實體間的時序關係預測曾參與相關專案：使用者興趣分析、駕駛油耗預測、圖像異常檢測、醫療實體時序預測相關工具的使用與延伸實體實作AIGC時代的學習方案：硬實力、軟素養、與未來發展路徑預估李海碩葳格國際學校', '常見問題: 經理人周末研修班需要考試或審核嗎？怎麼審核？審核標準是什麼?\\n回答: 參加經理人周末研修班是不需要經過考試。但需要經過審核，審核的標準為 \\n1. 從事AI相關工作經理人2. 具備決策權與預算權的經理人3. 若以上兩者符合，根據職稱高低排序。', '/ 02 / 16入學考試2024 / 02 / 17入學考放榜2024 / 02 / 20錄取生註冊繳費截止日2024 / 03 / 09課程開始2024 / 03 / 30課程結束退費辦法退費時間學費退還金額於當期課程開課日前 7 日內提出退費申請者( 2024/03/02 以前 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2024/03/09～2024/03/15', '址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。學員出席率達四分之三上課時數並參與', '7 日內提出退費申請者( 2023/11/18 以前)，應退還當期開班約定繳納費用總額百分之九十。於當期課程開課日後且未達全期三分之一期間內提出退費申請者( 2023/11/26～2023/12/01 )，應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者 ( 2023/12/02以後 )，所收取之當期開班約定繳納費用得全數不予退還。報名方式本招生採網路報名，請於報名截止日 2023 年 11 月 20 日前', '定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關數據集。評估微調後的大型語言模型效能並進行必要的調整。能部署地端大型語言模型程式：架設和配置必要的部署架構，以在地端環境中運行大型語言模型。確保模型部署的安全性和效能，包括資料保護和效能優化。進行系統測試並解決任何出現的技術問題。課前準備建議課前請有先備知識例如：Transformer,', '開課日期: 2023/05/12\\n報名截止日: 2023/05/01\\n課程名稱: ✨⚙️台北總校第十七期產業AI專班(智慧製造)招生簡章⚙️✨\\n上課地點: 台北總校', '常見問題: 我的報名已過期?\\n回答: 因原先報名連結已過期，請發信至 hi@aiacademy.tw 並提供您的姓名及報名時填寫的電子郵件信箱。我們將會重新寄發{報名及註冊的登記已可進行下一步報名作業}信件至您的電子信箱。', '(含) 以前提出退費申請者( ~ 2024/07/20)全額退還已繳費用。於當期課程開課日前 14 至當期課程開課當日開始前提出退費申請者( 2024/07/21 ~ 2024/08/02 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日起，且未達全期三分之一期間內提出退費申請者( 2024/08/03 ~ 2024/08/09 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達(含)全期三分之一以上提出退費申請者( 2024/08/10 ~', '常見問題: 請問每人需參與 AI 產業創新競賽？\\n回答: 參加AI創新競賽是結業的其中一個門檻。', '常見問題: 我是文科的人，我可以報名你們的課程嗎？\\n回答: 我們非常歡迎不同產業的人進來，希望可以推動不同產業專業的人，能認識AI這些知識。', 'EMS 電子製造代工服務業聚落，以加工/組裝型製程為主，精心打造推出「智慧製造專班」，以為期七週的時間，於週五、週六的全天班形式進行，給予學員製造業全面應用人工智慧的知識，再加上熱門的淨零碳排與綠色製造等議題。除了課程，再透過實務議題、案例分享與場域實地參訪印證，即時掌握智慧製造應用趨勢。同時安排學員進行深入的專題討論，將課堂的知識運用於專題及實作，領略這些技術的實際應用方式及限制，並讓學員間深入的交流分享學習。課程效益：瞭解與轉譯實務議題與 AI', 'AI 產業化創新競賽者，始發予數位結業證書。本課程放假日期：09/16 (六)台灣人工智慧年會、 09/30 (六) 中秋節，各停課一次。實際放假日期依課表為主。日期時程表2023 / 06  / 29報名截止日2023 / 07  / 15課程開始2023 / 10  / 28課程結束退費辦\\x08法退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2023/06/16 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者(', '常見問題: 學員發票什麼時候拿\\n回答: 個人用電子發票會於開學後第二週上課日由學務通知領取。\\r\\n公司報帳用電子發票會於開學後第二週由學務 mail 至學員報名時的電子信箱。\\r\\n若需提早或延後開立發票，請發信至hi@aiacademy.tw詢問。\\n發票部分，若有疑慮，請於五日內向校方反應。\\n電子發票會於今晚上傳財政部申報後，寄發至你的電子信箱中。', 'AI 產業化創新競賽者，始發予數位結業證書。手把手課程須自備筆電本課程停課日期：06/16 (五) ~ 06/17 (六) 彈性補班 及 06/23 (五) ~ 06/24 (六) 端午連假。實際放假日期依課表為主。日期時程表2023 / 05  / 01報名截止日2023 / 05  / 12課程開始2023 / 07  / 08課程結束課程目標：課程涵蓋 AI', '年 07 月 01 日 週六 14:00~15:10 ( 06/09 至 06/29 當天報名者 )考試內容以程式設計為主，希望確認應試者的程式設計能力。會以Python作為作答的程式語言。而考試的形式包括選擇題與程式撰寫。更多考試須知請點這裏未能通過第一次入學考的考生，可以再參加第二梯次的入學考試測驗，通過後一樣有入學資格。錄取通知：以電子郵件與簡訊寄發第一梯次考試於 2023 年 06 月 14 日 週三 17:00 後寄發錄取通知第二梯次考試於 2023 年 07 月 05 日 週三', '~ 13：50角色扮演: 透過模板指令掌握工作技巧如何使用模板指令來定制 ChatGPT 創建的文本如何設置模板指令以達到更好的效果14：00 ~ 14：50高效能工作大腦如何將 ChatGPT 整合到現有的工作流程中如何使用 ChatGPT 提高工作效率15：00 ~ 15：50小組討論與實作分組討論如何應用 ChatGPT 在不同的工作場景中16：00 ~ 17：00成品分享每組分享其討論的結果※ 學校保有修改、變更課程內容之權利。修業期間自 2023 年 07 月 01', '常見問題: 課程是否需要帶電腦?\\n回答: 課程當中並沒有需要使用到電腦的部(除了工程技術類課程外)，您可以依據自身上課需要攜帶筆電。', '(3 小時)LLM 簡介 (3 小時)：專門領域教授上機習作 (14 小時)文字資料 (3 小時)：助教/AIA 工程師微調大型語言模型 (7 小時)：助教/AIA 工程師架設生成式 AI 平台 (1 小時)：助教/AIA 工程師問答機器人 (3 小時)：助教/AIA 工程師專題實作 (4 週，時數 5 小時)專題實作引導 (4 小時)：助教/AIA 工程師專題成果分享 (1 小時)：助教/AIA 工程師專題演講 (8 小時)專題演講：2場專門領域教授、業界實務經驗專家生成式 AI', 'AIGC 實戰冬令營：高中生的第一個生成式 AI 營隊🚀虛實混成學習 • 動手實作• 競賽發表🤝 ～體驗生成式 AI 的魔法魅力！立即報名活動簡介為了協助高中職生了解生成式 AI 的最新趨勢，台灣人工智慧學校特別於2024年寒假規劃了 AIGC 實戰冬令營，以疫後時代的混成教學為主軸，混合了課前的線上學習與三天的的營隊實作，希望透過講師的影片與工程師的帶領實作，讓高中職生能學會使用 AIGC (Artificial Intelligence Generated Content, AIGC)', '週三 17:00 後寄發錄取通知第二梯次考試於 2024 年 01 月 10 日 週三 17:00 後寄發錄取通知※ 放榜後，考生應主動查詢，獲知錄取後如期辦理註冊，避免因系統擋信或漏信而影響註冊。逾期未註冊者，不得以未接獲通知為由要求補救措施。錄取通知及註冊繳費：報名後會先收到一封【報名登記確認信】，待通過學校審核，系統會再寄發【報名及註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後 3', '現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。本課程須全程自備筆電本班上課方式為「實體結合線上課程」，不提供補課或延期。本課程放假日期：09/15', '工程師ChatGPT 流程自動化(1.5小時)：助教/AIA 工程師小組專題討論與實作(1小時)開源大型語言模型應用實作 (4小時)認識、微調開源大型語言模型 (1.5 小時)：助教/AIA 工程師特定情境問答機器人部署實作 (1.5 小時)：助教/AIA 工程師分組專題成果發表(1小時)：助教/AIA 工程師課程大綱立即報名-A班A+B 班一起報名', '9 時至下午 5 時 30 分(共 105 個小時)。招生人數：150 名 (得不足額錄取)招生對象：在職人士且任管理職位者優先錄取，全域招生不限台北。學費標準：每人新台幣 52,000 元，團報達 10 人以上每人新台幣 50,000 元。大量團報請另洽專員：02-85123731 #12 （上班時間：週二~六）上課方式：週六全天進行實體課程（學員因疫情考量亦可申請線上上課）。台中(含)以南的學員，全程皆以線上模式進行(使用ZOOM)，惟手把手實作課程( 2023/12/09 )和結業典禮(', '高效問答術 (2 小時)：助教/AIA 工程師ChatGPT 實用擴充元件 (1.5小時)：助教/AIA 工程師ChatGPT 應用程式(1.5小時)：助教/AIA 工程師ChatGPT工作流程自動化實作(5小時)自動化原理與相關工具介紹(1.5小時)：助教/AIA 工程師ChatGPT 流程自動化(2小時)：助教/AIA 工程師小組專題討論與實作(1.5小時)開源大型語言模型應用實作 (4小時)認識開源大型語言模型 (0.5 小時)：助教/AIA 工程師特定情境問答機器人部署實作 (2', '8 日起，且未達全期三分之一期間內提出退費申請者( 2024/09/08～2024/10/05 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2024/10/06～ )所收取之當期開班約定繳納費用得全數不予退還。※ 備註：本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '常見問題: 明天開學典禮我無法參加，需要請假嗎？\\n回答: 開學典禮及結業典禮皆為課程時間，出缺席將計入缺席時數。若學員因故有請假需求，請填妥請假表單進行申請：https://reurl.cc/xZNOAL，並上傳證明文件，行政處核可後，系統將會直接寄送請假核可通知至您的信箱中。提醒您於下次上課時，攜帶有照片的證件，來領取學員證。', '日提出取消，退回報名費八成。營隊開始前 2 日至 20 日提出取消，退回報名費七成。營隊開始前 1 日提出取消，退回報名費五成。營隊活動當日及開始後，恕無法退費。如遇天災及不可抗力因素，人事行政局宣布停班停課，導致營隊取消時，若活動尚未開始，將扣除行政手續費 500', '現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。手把手課程須自備筆電學員出席率達四分之三上課時數並參與', '8 日起，且未達全期三分之一期間內提出退費申請者( 2024/07/14 ~ 2024/08/08 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2024/08/09～ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '常見問題: 為何我未錄取產業專班?\\n回答: 謝謝您的來信。由於報名實在太熱烈及踴躍、報考者都十分優秀，我們能錄取的考生非常有限，不免會有遺珠之憾，對於產業專班，校方希望提供給在職人士進修與推動產業轉型AI機會， 台灣人工智慧學校經理人班審查標準有二： 1. 從事AI相關工作經理人 2. 具備決策權與預算權的經理人 3. 若以上兩者符合，根據職稱高低以及公司產業別排序 非常的可惜未能錄取所有優秀的報考者，我們期待您未來的參與。建議報考者能就近多利用其他分校，希望及歡迎您報名其他分校或再次報考下一梯次的產業專班。', '之前 )全額退還已繳費用。於當期課程開課日前 16 至 29 日提出退費申請者( 2023/12/23～2024/01/04 )應退還當期開班約定繳納費用總額百分之九十五。於當期課程開課日前 15 日內提出退費申請者( 2024/01/05～2024/01/19 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2024/01/20～2024/01/27 )應退還當期開班約定繳納費用總額百分之八十。於當期課程開課日後第 8', 'AI 產業化創新競賽者，逕發予數位結業證書。本課程放假日期：12/30 (六) 元旦連假、 01/13 (六) 選舉、 02/10 (六) 農曆春節、 02/17 (六) 補上班，各停課一次。實際放假日期依課表為主。日期時程表2023 / 10  / 26報名截止日2023 / 11  / 11課程開始2024 / 03  / 09課程結束退費辦法退費時間學費退還金額於當期課程開課日前30日 (含) 以前提出退費申請者( 2023/10/13 )全額退還已繳費用。於當期課程開課日前 16 至', '者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。本課程須全程自備筆電及耳機。本班上課方式為「實體結合線上課程」，不提供補課或延期。本課程放假日期：※', '註冊的登記已可進行下一步報名作業】信件通知，請點選信件中的連結網址以完成報名及註冊繳費程序。獲錄取者需於收到錄取通知後', '台北總校第二十期經理人週末研修班招生簡章🚀 AIA 經典【經理人週末研修班】課程，全明星級的講師陣容，與時俱進的課程內容，不受地域限制彈性上課，利用14週的週六時間，將各產業人脈與寶貴 AI 知識一網打盡。💪👍🤝課程大綱立即報名修業期間：自 2024 年 07 月 06 日起，至 10 月 12 日止，共 14 週。每週六上課，時間皆為早上 9 時至下午 5 時(共 105 個小時)。招生人數：150 名', '48,000 元。 團報達十人每人新台幣 46,000 元。報名方式：本招生採網路報名，請於報名截止日 2023 年 6 月 29 日前 (含 6/29 當日)  上網填寫報名資料。請完整填寫報名表，以利完成審核程序。入學考試：時間分兩梯次：第一梯次：2023 年 06 月 10 日 週六 14:00~15:10 ( 含 06/08 當日 ) 以前的報名者第二梯次：2023 年 07 月 01 日 週六 14:00~15:10 ( 06/09 至 06/29 當天報名者', '2024 年 01 月 20 日起，至 2024 年 05 月 24 日止，每週週三、週五、週六三天全天上課，時數共計 270 小時 (一天6小時) 。上課方式：實體課程結合線上課程。週三以線上課程進行，週五週六為實體課程。每天上課時間為早上 9:30 到下午 5:00。實體課程可選擇之地點：台灣人工智慧學校台北總校 | 新板金融大樓地址：新北市板橋區中山路一段141號 14 樓台灣人工智慧學校台中分校 | 中國醫藥大學校本部基中大樓地址：台中市北屯區經貿路一段296號 2 樓招生人數：100', 'few-shotlearnersTraining language models tofollow instructions with human feedbackLLaMA: Open and Efficient Foundation Language ModelsLlama 2: Open Foundation andFine-Tuned Chat', '(LLM-A) + 大型語言模型實作進階班 (LLM-B)每人新台幣 44,000 元。初階班+進階班 線上報名：https://neti.cc/ba1D2ZY有關初階班+進階班課程退費辦法：於當期課程開課日前 7 日內提出退費申請者( 2023/11/18 以前)，應退還當期開班約定繳納費用總額百分之九十。於當期課程開課日後且未達全期三分之一期間內提出退費申請者( 2023/11/26～2023/12/01', '大型語言模型實作進階班 (第四期) 招生簡章🚀透過上機實作教學和專題實作導引，熟練地將這些技術應用於實際問題中，開發出具有價值的 AI 應用。💪👍🤝課程大綱立即報名課程簡介基於上百家企業需求想要用大型語言模型建置企業內部的「企業大腦」，因各企業的資料有機敏性與獨特性，無法使用公開的大型語言模型。此外微調及部署大型語言模型服務有一定的門檻在，不論是在設備上、資料處理上、技術上等。台灣人工智慧學校深知大型語言模型在當今 AI', 'ChatGPT 平台，從文本輸入到工作情境的應用，讓你在不同的工作場景中熟練使用 ChatGPT ，並提供智能建議和解決方案，例如展覽、企劃和說故事等。除此之外，你還將學習如何使用模板指令來影響 ChatGPT 創建的文本，以及如何設置模板指令以達到更好的效果。本課程還將強調高效能工作大腦的使用，讓你能夠將 ChatGPT 整合到現有的工作流程中，並在日常工作中提高效率。最後，你將參與小組討論和實作，分組探討如何應用 ChatGPT 在不同的工作場景中，並分享自己的成果，讓你真正理解', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍', '(4 小時)：助教/AIA 工程師專題成果分享 (1 小時)：助教/AIA 工程師專題演講 (8 小時)專題演講：2場專門領域教授、業界實務經驗專家生成式AI平台第一期大型語言模型實作進階班優秀專題成果於課中分享課程大綱立即報名', '提供匯款單或匯款帳號後五碼，匯款手續費請自行負擔，以利我們對帳後更新你的註冊狀態。請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致影響錄取入學。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄', '開課日期: 2024/01/20\\n報名截止日: 2024/01/04\\n課程名稱: 技術領袖培訓全域班第四期招生簡章\\n上課地點: 全域班別', '班報名皆為候補名額)辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效您是否曾經為了重複性的辦公室工作而感到煩悶？您是否想要利用最新的人工智慧技術來提升您的工作品質和效率？如果您的答案是肯定的，請一定要了解「辦公室流程自動化」和「大型語言模型」協作的優勢。「辦公室流程自動化」是指使用軟體機器人來執行一系列相互關聯的活動或任務，以達成特定的業務目標。這些活動或任務包括填寫表單、發送電子郵件、處理文件、產生報告等。辦公室流程自動化可以幫助您減少錯誤、節省時間、降低成本、提升生產力。「大型語言', '(3 小時)LLM 簡介 (3 小時)：專門領域教授上機習作 (14 小時)文字資料 (4 小時)：助教/AIA 工程師微調大型語言模型 (7 小時)：助教/AIA 工程師問答機器人 (3 小時)：助教/AIA 工程師部署大型語言模型(1 小時)：助教/AIA 工程師專題實作 (4 週，時數 5 小時)專題實作引導 (4 小時)：助教/AIA 工程師專題成果分享 (1 小時)：助教/AIA 工程師專題演講 (8', '常見問題: 詢問師資 （智慧製造班）\\n回答: 台灣人工智慧學校提供專業的師資與課程，也安排了在製造業有深厚實務經驗的先進前來授課，分享智慧製造應用與案例的分享。\\n希望能透過二天共七週的課程，讓來參與智慧製造課程的各位，能充份吸收並掌握人工智慧技術的最新趨勢與發展應用能力。\\n學校將邀請中央研究院等學研單位及產業界，擁有豐富經驗與理論背景的講師，進行機器學習、深度學習、智慧製造等重要的人工智慧核心技術與應用課程講授。\\n本次產業專班的師資\\n吳漢銘        國立政治大學統計學系副教授      資料科學與大數據分析\\n陳弘軒       國立中央大學 資工系副教授        機器學習與演算法概論\\n許懷中       逢甲大學資訊工程學系副教授     深度學習 \\n莊永裕       台大資工系 教授                          電腦視覺 \\n李家岩       國立臺灣大學資訊管理學系教授  智慧製造與生產線上的資料科學', '(信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw', '恕不另行通知。請先註冊ChatGPT(https://chat.openai.com/auth/login) 及事先購買Midjourney (https://www.midjourney.com/)▲上課需事先購買Midjourney訂閱方案 (最低月費為10美金)為保障您的權益及確保處理效率，如有任何疑問，敬請直接來電 04-2298-6620，或寄信至 camp@aiacademy.tw，將有專人為您服務，謝謝您。', '8 日起，且未達全期三分之一期間內提出退費申請者( 2023/07/30～2023/08/11 )應退還當期開班約定繳納費用總額百分之五十。於當期課程開課期間已達全期三分之一以上提出退費申請者( 2023/08/12～ )所收取之當期開班約定繳納費用得全數不予退還。備註:本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '使用軟體機器人執行重複性任務- 包括填寫表單、發送電子郵件、處理文件等- 可減少錯誤、節省時間、降低成本、提升生產力大型語言模型(LLM)- 利用深度學習理解和生成自然語言- 能處理翻譯、摘要撰寫、對話、創作等任務- 提升語言技能、創新能力、溝通效果和競爭優勢RPA 與 LLM 融合的優勢- 使用 LLM 設計和優化辦公室流程- 讓機器人更準確執行指定任務- 使用機器人呼叫 LLM 加速語言相關工作課程成果圖：Make 自動化串接成果示例。課程資訊修業日期週三班：2024 年 07 月 03', '招生簡章🚀辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效💪👍🤝課程大綱立即報名課程簡介辦公室流程自動化結合大語言模型，讓您的工作更輕鬆、更高效您是否曾經為了重複性的辦公室工作而感到煩悶？您是否想要利用最新的人工智慧技術來提升您的工作品質和效率？如果您的答案是肯定的，請一定要了解「辦公室流程自動化」和「大型語言模型」協作的優勢。「辦公室流程自動化」是指使用軟體機器人來執行一系列相互關聯的活動或任務，以達成特定的業務目標。這些活動或任務包括填寫表單、發送電子郵件、處理文件、產生報告等。辦', '所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。日期時程表2023', '40,000 元。若同時報名初階班 (LLM-A) + 進階班 (LLM-B) ，並錄取通過，則二班課程享原價 八 折( 新台幣 44,000 元 )。校友優惠專享每人新台幣 36,000 元。本校各班別結業之校友，於報名時附上學員編號，經查核後得享有校友優惠。若同時報名初階班 (LLM-A) + 進階班 (LLM-B) ，並錄取通過，則二班課程享原價 八 折( 新台幣 44,000 元 )。團報優惠專享 (5人)每人新台幣 32,000 元。團體報名專屬優惠：報名人數達 5', '技術領袖培訓全域班第五期招生簡章🚀AIA 經典課程強勢回歸，為企業培育上千名 AI 技術人才的技術領袖培訓班！上課不受地域限制，可以選擇台北或中部任一校區上課，並且採線上與實體混合課程，課程進行更為彈性。完整的理論課程，搭配題材豐富的練習以及手把手教學，最後進行專題實作，解決業界學界的真實問題，讓您在四個月的課程後，有最紮實的 AI 基本功以及 AI 即戰力！💪👍🤝課程大綱立即報名修業期間：自 2024 年 08 月 31 日起，至 2024 年 12 月 14', '小時以上營隊證書及學習歷程均不發給。合作飯店優惠住宿聯絡資訊智選假日酒店 ( 407台中市西屯區福星北三街33巷28號 )飯店電話：04-2708-6313請告知或出示參加台灣人工智慧學校高中冬令營相關證明，即享有優惠價格。取消及退費辦法營隊開始前 31 日前提出取消，退回報名費九成。營隊開始前 21 日至 30 日提出取消，退回報名費八成。營隊開始前 2 日至 20 日提出取消，退回報名費七成。營隊開始前 1', '~ 16:00休息休息16:00 ~ 16:50【成品分享時間】【成品分享時間】※ 學校保有修改、變更課程內容之權利。營隊證書與學習歷程請確認活動期間可以全程參與，全程參與者可領取營隊證書及學習歷程各一份。因故離營須填寫請假單，病假請檢附就醫證明，請假時數：事假累計達4 小時僅發給學習歷程，不發給營隊證書；6 小時以上營隊證書及學習歷程均不發給。病假累計達7 小時僅發給學習歷程，不發給營隊證書；9 小時以上營隊證書及學習歷程均不發給。合作飯店優惠住宿聯絡資訊傑仕堡有氧酒店 (', 'Augmented Generation, RAG) 介紹使用 Langchain 實現 RAG第三週LLM 開源模型微調方式介紹開源 LLM 模型微調開源 LLM 模型訓練效能框架與應用PEFT (LoRA, QLoRA, PEFT) 參數微調方法LLM 應用 (RAG & multimodal)第四週生成式 AI', 'ChatGPT 在不同的工作場景中，並分享自己的成果，讓你真正理解 ChatGPT 的優勢和應用。課程效益提升文書工作效率50% 以上，有效減輕工作負擔了解 ChatGPT 的 prompt 模板，學會與 AI 溝通結合情境應用，瞬間化身不同角色討論與分享更多應用，擴展自己的想像空間手機螢幕建議使用水平橫式瀏覽時間課程主題課程大綱09：00 ~ 09：50從零開始的 ChatGPTChatGPT 的定義和應用範圍ChatGPT 如何提高工作效率什麼是 Prompt使用 Prompt 對', '(需於報名時上傳結業證書以供查核)通過本班的入學考試以上兩項滿足一項即可入學課程目標學習 4 大課程主題與方法：理解大型語言模型實作大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程內容環境介紹、帳號設定 (1 小時)理論知識 (3 小時)LLM 簡介 (3 小時)：專門領域教授上機習作 (12 小時)文字資料 (2 小時)：助教/AIA 工程師微調大型語言模型 (6 小時)：助教/AIA 工程師問答機器人 (2', '需自備筆電 )、清寒家庭免費( 學校將借用筆電 )報名規定本活動招生採網路報名，請於截止日 請於截止日 2024 年 1 月 15 日上網填寫報名資料，並上傳家長同意書 (下載：AIGC 實戰冬令營 家長／監護人同意書)，請列印後填妥資料並簽名，掃描成', 'Make 操作應用專題實作1-ChatGPT + Make + Line 流程自動化RPA應用程式介面專題實作2-ChatGPT + Make + Line 流程自動化運用 LLM 互動式介面工具雲端使用 LLM', '開課日期: 2023/11/25\\n報名截止日: 2023/11/17\\n課程名稱: 大型語言模型實作初階班(LLM-A)招生簡章\\n上課地點: 全域班別', '大課程主題與方法：理解大型語言模型微調大型語言模型實作問答機器人大型語言模型部署上機實作熟悉大語言模型的技術能力。主題性的專題實作，培養專案實作的能力。課程效益能創建企業聊天機器人：設計和開發能夠理解並回應企業內部查詢的聊天機器人。實現機器人與公司數據庫的集成，以提供實時的查詢回應。進行機器人效能測試並根據反饋進行優化。能可微調開源大型語言模型：選擇適合的開源大型語言模型並進行微調，以符合公司特定的需求和應用場景。收集和整理適用於微調開源大型語言模型的業務相關數據集。評估微調後的大型語言模型效', '(5 小時)ChatGPT 高效問答術 (2 小時)：助教/AIA 工程師ChatGPT 實用擴充元件(1.5小時)：助教/AIA 工程師ChatGPT 應用程式(1.5小時)：助教/AIA 工程師ChatGPT工作流程自動化實作 (5 小時)自動化原理與相關工具介紹(1.5小時)：助教/AIA 工程師ChatGPT 流程自動化(2小時)：助教/AIA 工程師小組專題討論與實作(1.5小時)開源大型語言模型應用實作 (4 小時)認識開源大型語言模型 (0.5 小時)：助教/AIA', '小時以上營隊證書及學習歷程均不發給。合作飯店優惠住宿聯絡資訊傑仕堡有氧酒店 ( 新北市板橋區縣民大道二段275號 )飯店聯絡人：02-77273000 #54098   涂茂羣 Martin Tu請告知參加台灣人工智慧學校高中夏令營即享有優惠價格取消及退費辦法營隊開始前 31 日前提出取消，退回報名費九成。營隊開始前 21 日至 30 日提出取消，退回報名費八成。營隊開始前 2 日至 20 日提出取消，退回報名費七成。營隊開始前 1', 'AI 客服管理工具能選用、微調開源大型語言模型，打造配適個人需求或公司應用情境的AI助理將AI助理與您的個人網站結合，打造互動式個人網頁能了解如何將微調後的問答機器人部署為應用程式介面透過小組專題實作與成果分享，增進專題實作能力課前準備建議課前先使用gmail信箱註冊以下平台OpenAIMake請學員自備筆電，以便課程學習與小組專題實作課程有專題實作與呈現，建議準備網頁或PDF問答資料用於微調大型語言模型。修業日期2023 年 11 月 25 日及 12 月 2 日，共 2', '✨⚙️ 台北總校第十七期產業 AI 專班 (智慧製造) 招生簡章 ⚙️ ✨🚀 全明星級的講師陣容，與時俱進的課程內容，創新多樣化的授課形式，時間濃縮精彩加倍，利用每週兩天、一共七週 14 天的學習時間，將人脈網絡與寶貴知識一網打盡，畢其功於一役。💪👍🤝課程大綱立即報名主辦單位：台灣人工智慧學校修業期間：自 2023 年 05 月 12 日起，至 07 月 08 日止，共 7 週。每週五、週六上課，時間皆為早上 9 時至下午 5 時 30 分( 共 105 個小時)。招生人數：100 名', '天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流 (轉帳)。若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消資格，事後不得以任何理由要求補註冊。講師陣容手機螢幕建議使用水平橫式瀏覽課程名稱姓名職稱講師簡介線上預習給高中生的第一堂 AI 課蔡宗翰中研院 GIS', '9 時至下午 5 時 30 分( 共 105 個小時)。招生人數：100 名 (得不足額錄取)招生對象：製造業在職人士且任管理職位者優先錄取。學費標準：每人新台幣 48,000 元，團報達 10 人以上每人新台幣 46,000 元。大量團報請另洽專員：02-85123731校友回訓優惠：校友報名全部課程享有優惠價每人新台幣 46,000 元，報名回訓六天課程：06/03、06/09、06/10、06/30、07/01、07/07 ，每人新台幣 25,000', '/ 11 / 18入學考試2023 / 11 / 22入學考放榜2023 / 11 / 27錄取生註冊繳費截止日2023 / 12 / 09課程開始2023 / 12 / 29課程結束退費辦法退費時間學費退還金額於當期課程開課日前 7 日內提出退費申請者( 2023/12/02以前 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課當日至開課日後 7 日內提出退費申請者( 2023/12/09～2023/12/15', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍', '7 日內提出退費申請者( 2023/11/18 以前 )應退還當期開班約定繳納費用總額百分之九十。於當期課程開課日(含)以後提出退費申請者( 2023/11/25 以後 )所收取之當期開班約定繳納費用得全數不予退還。備註：本表所稱「開課日」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程資訊課程名稱大型語言模型實作初階班 (LLM-A)課程時數2週共 14 小時上課方式實體課程上課地點中研院人文館 第二會議室 ( R2 ) |', '2024/08/10 ~ )所收取之當期開班約定繳納費用得全數不予退還。備註：本表所稱「開課日」、「全期三分之一」等日期，皆以本校當期課程行事曆規定之日期為判斷依據。課程大綱立即報名', '14 小時上課方式實體課程上課地點新北市板橋區民族路168號 ( 中華電信學院實驗大樓7樓 )適合對象對辦公室自動化及大型語言模型應用有興趣者 ( 無程式背景可 )課程目標了解大型語言模型的原理和功能熟悉 ChatGPT 的提問技巧和延伸應用學會用 ChatGPT 結合其他工具自動化工作流程探索開源大型語言模型的特色和應用建立適用特定場景的聊天機器人課程內容ChatGPT基礎及延伸應用 (5小時)ChatGPT 高效問答術 (2 小時)：助教/AIA 工程師ChatGPT 實用擴充元件', '開課日期: 2024/04/17\\n報名截止日: 2024/04/08\\n課程名稱: 大型語言模型實作初階班(第三期)招生簡章\\n上課地點: 全域班別', '開課日期: 2024/02/24\\n報名截止日: 2024/02/14\\n課程名稱: 大型語言模型實作初階班(第二期)招生簡章\\n上課地點: 全域班別', '年起擔任 g0v 揪松團輪值主席，並發起零時小學校。活用 ChatGPT 自學寫程式實戰教學許武龍(哈爸)LASS開源環境感測網路創辦人LASS 創辦人，總統盃黑客松卓越團隊，擔任幾個社群管理者、企業顧問、公部門審查委員。大型語言模型(LLM) 概論蔡政霖台灣人工智慧學校 AI工程師台灣人工智慧學校台北總校 AI工程師陽明交通大學生醫資訊所博士候選人研究領域為醫學影像分割最近新增 Prompt Engineering 技能AI 繪圖概論吳承澔台灣人工智慧學校', '繪圖概述 與 Prompt【實作課程】AIGC 百寶箱: 更多道具介紹10:50 ~11:00休息休息休息11:00 ~11:50【實作課程】ChatGPT和Bing：全面指南和實用技巧【實作課程】Midjourney : AI 繪圖的第一步【專題時間】小組討論與實作11:50 ~ 13:00午餐午餐午餐13:00 ~ 13:50【實作課程】模板指令：ChatGPT助你掌握生活技巧【實作課程】Midjourney 大揭密: 通往 AI 繪畫大師的方法【創意發想】分組競賽 ( 一組分享10分鐘', '進行必要的調整。能部署地端大型語言模型程式：架設和配置必要的部署架構，以在地端環境中運行大型語言模型。確保模型部署的安全性和效能，包括資料保護和效能優化。進行系統測試並解決任何出現的技術問題。學費標準一般報名費用:', '及其他醫界先進們，目前講師還在安排調整，官網只會放上課程大綱，待開課前會寄出學員手冊，裡面的課程表會有當期課程及講師，屆時再提供您參考', '常見問題: 請問您們產業專班上課幾周? 總時數為?\\n回答: 產業專班上課七周，為每周星期五和星期六，時間為早上 09:00-到下午17:30，總計上課時數為 105小時。您也可以參考官網 https://aiacademy.tw/的招生訊息內的資訊。', 'AI工程師陽明交通大學生醫資訊所博士候選人研究領域為醫學影像分割最近新增 Prompt Engineering 技能圖片魔法: AI 繪圖概述吳承澔台灣人工智慧學校 AI工程師逢甲大學資訊工程學系碩士逢甲大學人工智慧中心研究生過去研究主題：醫療病例實體間的時序關係預測曾參與相關專案：使用者興趣分析、駕駛油耗預測、圖像異常檢測、醫療實體時序預測圖片活起來：從圖片到影片的技巧※ 學校保有修改、變更課程內容之權利。實作課程表手機螢幕建議使用水平橫式瀏覽時間7/26 (三)7/27 (四)', '大型語言模型實作初階班 (第二期)', '常見問題: 請問您們技術領袖全域班上課幾周? 總時數為?\\n回答: 技術領袖全域班上課約十五周，為每周星期三、星期五和星期六，時間為早上 09:30到下午17:00，總計上課時數約 270小時。技術領袖全域班學員缺席達十分之一上課時數者，不予發給結業證書；您也可以參閱官網 https://aiacademy.tw/的招生訊息內的資訊。', '如何核實校友身分?: 未收到數位結業證書?\\n具備台灣人工智慧學校結業證書者。: 請至證書入口網站https://global.turingcerts.com/login (使用者登入)使用自己受訓登記的電子郵件註冊進入，即可看到自己證書。第一次登入需要先註冊，電子郵件以報名時的E-mail信箱。註冊後的登入頁面，雖然要求以手機號碼登入，但實質上是使用受訓登記的電子郵件進行登入~  可詳閱收證方使用手冊 https://taiwan-e-portfolio-alliance.gitbook.io/turing-certs-user-guidebook/', 'AI 客服管理工具能運用自帶資料輔助大型語言模型，打造符合個人需求或公司特定應用情境的 AI 助理能了解如何將問答機器人部署為應用程式介面透過小組專題實作與成果分享，增進專題實作能力學費標準一般報名費用: 15,000 元優惠方案:校友優惠(13,500元/人)：本校校友，報名時填寫學號。團體優惠(13,500元/人，三人以上)：報名時需一起完成線上報名，並由報名窗口發送郵件至 hi@aiacademy.tw 林小姐確認審核。報名方式本招生採網路報名，請於報名截止日 2024 年 6 月 24', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致被取消報考或影響錄取。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍', '2024/04/27 )和結業典禮( 2024/06/29 )二日課程建議實體上課效果較佳，學校將提供台中(含)以南欲實體出席此二日課程之學員高鐵交通費用補助 （憑高鐵票證申請）。結業標準：同時達成以下兩項條件方可獲得數位結業證書：1.上課出席率達課程總時數四分之三2.參與 AI 產業化創新競賽上課地點 (以下為暫定，將視招生人數與場地狀況以行前通知為準)：：中央研究院 (南港) / AIA 台北總校 (板橋)報名方式：本招生採網路報名，請於報名截止日 2024 年 03 月 04', '等聊天機器人協作日常任務打造結合ChatGPT的辦公室工作流程自動化專案- AI 客服管理工具能運用、自帶資料輔助大型語言模型，打造配適個人需求或公司應用情境的AI助理將AI助理與您的個人網站結合，打造互動式個人網頁能了解如何將問答機器人部署為應用程式介面透過小組專題實作與成果分享，增進專題實作能力課前準備建議課前先使用gmail信箱註冊以下平台OpenAIMake請學員自備筆電，以便課程學習與小組專題實作修業日期2024 年 02 月 24 日及 03 月 02 日，共 2', '常見問題: 關於【 NLP 專題實作班 】入學考試型式與範圍?\\n回答: 關於入學考試型式與範圍概述如下：\\n1. 選擇題 10-15 題 ： 機器學習 / 深度學習 / NLP / Python / PyTorch 之基礎概念\\n2. 手寫題 3 題 ： Python / PyTorch 不要求全對 /  有寫的要正確即可\\n以上請參考並保持平常心即可！ 祝您能順利通過考試入學！', '所繳資料有偽造、變造、假借、冒用、剽竊、內容不實、塗改等情事，未入學者取消錄取資格，已入學者開除學籍，並應負法律責任，且不發給任何有關學業之證明，如係在本校結業後始發覺者，除勒令撤銷其結業證書外，並公告取消其結業資格。請詳閱課程資訊相關規定，學校保有修改、變更簡章及相關規定之權利。請詳閱並同意保密暨權益歸屬同意書。退費辦法退費時間學費退還金額於當期課程開課日前', '(信用卡) 或臨櫃匯款。選擇臨櫃匯款者請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw', '(轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。注意事項：請務必於報名前詳閱本項招生簡章規定，避免日後因報名資格不符致影響錄取入學。學員註冊繳費後若因各種原因無法繼續課程，得依本校退費辦法進行退費，恕不提供補課與延期。上網登錄報名資料之通訊地址、電話號碼及電子郵件地址應正確，否則無法通知而致延誤考試及其他重要事項，其後果需自行負責。錄取者如發現所繳資料有偽造、變造', '記憶體至少16 GB 以上 )上課環境使用 Google Colab請先安裝  Docker 軟體前幾期小組成果發表主題營養師 AI 助手交通貓貓機器人保險 AI經營資料分析與趨勢預測ISO 27001 問答機器人智慧型農業供應鏈系統標快手!自由雙手智慧探索公司智識庫疾藥綜合系統課程照片課程大綱週次課程大綱教學內容第一週人工智慧到大型語言模型概論人工智慧與 LLM 概論LLM 的道德議題、限制與風險相關實例分享生成式 AI 平台架設生成式 AI 平台LangChain 概述LangChain', '常見問題: 註冊後，我選擇臨櫃匯款，該匯到哪裡?\\n回答: 選擇臨櫃匯款者，請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。\\n注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw 提供您的姓名、報名課別、匯款單或匯款帳號後五碼，以利我們對帳後更新你的註冊狀態。', '年 02 月 16 日 週五 19:00 - 20:10考試範圍為程式設計，透過線上考試確認應試者的基本能力。程式設計以 Python 作為答題的程式語言，線上考試的形式包括選擇題 (語法相關約10題) 與程式撰寫 (演算法相關約3題)。入學考通知信將於考前一天 02/15 ( 四 ) 17:00 後以簡訊通知，並寄發考試連結通知信至您的信箱中。放榜放榜日期將於 02 月 17 日 週六 17:00 後寄發錄取 /', 'language models tofollow instructions with human feedbackLLaMA: Open and Efficient Foundation Language ModelsLlama 2: Open Foundation andFine-Tuned Chat Models課程有專題實作與呈現，建議準備網頁或PDF問答資料(網頁示例)用於微調大型語言模型。請學員自備筆電，以便課程學習與小組專題實作。( 記憶體至少16 GB 以上 )上課環境使用', '天內 完成註冊繳費。請於規定時間內辦理註冊及繳費，繳費方式可選擇線上金流 (刷卡) 或非線上金流 (轉帳)，若選擇非線上金流，系統會產生一組虛擬帳號，請務必在繳費期限內完成匯款繳費。繳費後才算完成報名程序。未依規定辦理或逾期未註冊者，取消入學資格，事後不得以任何理由要求補註冊。課前準備建議課前先使用gmail信箱註冊以下平台OpenAIMake建議課前先安裝軟體LM studio( Mac 需 M1晶片以上)AnythingLLM請學員自備筆電，以便課程學習與小組專題實作。(Mac 建議', '40,000 元優惠方案:校友優惠(32,000元/人)：本校校友，報名時填寫學號。團體優惠(32,000元/人，三人以上)：報名時需一起完成線上報名，並由報名窗口發送郵件至 hi@aiacademy.tw 林小姐確認審核。初階班校友優惠(29,000元)：初階班結業，報名時填寫學號。報名方式本招生採網路報名，請於報名截止日 2024 年 07 月 22 日前 (含 07/22 當日)', '開課日期: 2023/07/15\\n報名截止日: 2023/06/29\\n課程名稱: 台北總校第十六期經理人研修班招生簡章\\n上課地點: 全域班別', '經理人週末研修班是台灣人工智慧學校在技術領袖培訓班之後，第二個專門為台灣目前產業需求所設計的班別。我們預期透過經理人週末研修班，讓各產業的經理人能有一個場域，與不同產業的經理人一同學習及理解人工智慧的技術概觀，對於人工智慧技術能有全面性的大局觀，而且徹底瞭解人工智慧是如何運作的，以及它的能力、侷限及未來發展，才能讓產業欲以人工智慧進行產業升級時，能有清楚的方向感來帶領企業前進。\\n技術班：\\n技術領袖培訓班期為台灣育成具有人工智慧技術思維與實戰經驗的技術領袖人才，讓產業欲以人工智慧進行產業升級時，不再為缺乏人才所束縛。', '(三)7/27 (四)   7/28 (五) 地點台灣人工智慧學校台北總校台灣人工智慧學校台北總校中研院人文館主題AI文字生成魔法AI圖像生成魔法綜合應用與發表08:30 ~ 09:00報到報到報到09:00 ~ 09:50【營隊開場】營隊介紹互相認識、分組活動【專題演講】簡立峰 台灣Google 前董事總經理 Appier & ikala董事【概念複習實作】圖片活起來: 從圖片到影片的技巧09:50 ~10:00休息休息休息10:00 ~ 10:50【概念複習實作】從零開始的', '等聊天機器人協作日常任務打造結合ChatGPT的辦公室工作流程自動化專案- AI', '開課日期: 2024/01/30\\n報名截止日: 2024/01/15\\n課程名稱: AIGC實戰冬令營：高中生的第一個生成式AI營隊\\n上課地點: 台中分校']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#選擇要使用的LLM\n",
        "# llm = llm_primehub_llama3\n",
        "llm = llm_Groq_llama3\n",
        "\n",
        "# 自動從每個文檔的每個 chunks 建立一個 QA pair\n",
        "example_gen_chain = QAGenerateChain.from_llm(llm)\n",
        "\n",
        "# examples = example_gen_chain.apply(\n",
        "#     [{\"doc\": \"請用中文: \" + t} for t in data[:50]] # 先產 50 個看看 (實測僅 OpenAI model 可轉成中文問答生成，llama3-70b-8192 生成的依然是英文)\n",
        "# )\n",
        "\n",
        "examples = example_gen_chain.apply_and_parse(\n",
        "    [{\"doc\": \"請用中文: \" + t} for t in data[:50]] # 先產 50 個看看 (實測僅 OpenAI model 可轉成中文問答生成，llama3-70b-8192 生成的依然是英文)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htpSVKRCzmw-",
        "outputId": "79392353-f112-49ce-cd5a-dfd5d4fa0ecc"
      },
      "id": "htpSVKRCzmw-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:367: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk_KnJz_NPvC",
        "outputId": "3b576e30-06ee-4796-8228-db0d39e08c67"
      },
      "id": "Xk_KnJz_NPvC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'qa_pairs': {'query': 'What is the recommended method for requesting a replacement student ID card if it is lost?',\n",
              "  'answer': 'Sending an email to hi@aiacademy.tw with a request for a replacement student ID card.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(examples[0]))\n",
        "examples[0]['qa_pairs']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q57omAVzm45",
        "outputId": "753eacd6-fba6-4b00-e8c2-d1ef967aa494"
      },
      "id": "0Q57omAVzm45",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is the recommended method for requesting a replacement student ID card if it is lost?',\n",
              " 'answer': 'Sending an email to hi@aiacademy.tw with a request for a replacement student ID card.'}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 因為建立的 examples 會是兩層的 dictionary list, 只組合第二層的 dictionary 作為最後的 qa_examples list\n",
        "qa_examples = []\n",
        "for example in examples:\n",
        "  qa_examples.append(example['qa_pairs'])\n",
        "print(qa_examples)\n",
        "print(len(qa_examples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8E9Abyozm_W",
        "outputId": "fc429cb9-a4da-4a03-c219-c4f637a5601c"
      },
      "id": "Z8E9Abyozm_W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'query': 'What is the recommended method for requesting a replacement student ID card if it is lost?', 'answer': 'Sending an email to hi@aiacademy.tw with a request for a replacement student ID card.'}, {'query': 'Who are the professors invited to teach the core technologies and applications of artificial intelligence in the medical field?', 'answer': 'The professors invited include Chen Hong-xuan, Cai Yan-long, Zhuang Yong-yu, and Jiang Rong-xian.'}, {'query': 'What is the price for each person if there are 10 or more people in a group?', 'answer': 'NT$16,000'}, {'query': 'What will happen to the fees if a participant cancels their registration after the activity has started?', 'answer': 'The fees will be refunded proportionally based on the cancellation date.'}, {'query': 'Who was the director-general of Google?', 'answer': 'Eric Tsai'}, {'query': 'What will happen to students who have submitted false or forged documents, such as fake academic records or certificates?', 'answer': 'Their admission will be cancelled, and if they have already been admitted, they will be expelled from school, and they will also be held legally responsible.'}, {'query': 'What are the circumstances under which a student is allowed to transfer to a different class after the start of the semester?', 'answer': 'According to the document, a student is only allowed to transfer to a different class under special circumstances, such as unforeseen events, and must provide proof to the school, which will then consider the request.'}, {'query': 'How should students register for the course?', 'answer': 'Through the online registration system.'}, {'query': 'What is the main goal of this course in the AI domain?', 'answer': 'To develop professionals who can apply AI technology to real-world problems and contribute to the progress of this revolutionary technology.'}, {'query': 'What is the main purpose of the \"智慧醫療專班\" (Intelligent Healthcare Program)?', 'answer': 'The main purpose of the \"智慧醫療專班\" is to enable medical professionals to quickly and systematically grasp the latest trends in artificial intelligence technology and understand how it works, its capabilities, limitations, and future developments, and apply it to medical work in every scenario.'}, {'query': 'What is the deadline for online registration for the program?', 'answer': '2023年05月01日 (May 1st, 2023)'}, {'query': 'What is the location of the classroom where the course will be held?', 'answer': '中研院人文館 第二會議室 (R2)'}, {'query': 'What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?', 'answer': '95%'}, {'query': 'What percentage of the tuition fee will be refunded to students who submit a withdrawal application within 7 days of the course start date?', 'answer': '50%'}, {'query': 'Where is the physical classroom for the course?', 'answer': 'The physical classroom is located at the Institute of Humanities, Room R2.'}, {'query': 'What happens if a student is unable to attend the graduation ceremony?', 'answer': \"The student's absence will be counted as an absence, and if the student needs to take a leave of absence, they must fill out a leave application form at https://reurl.cc/xZNOAL and upload proof of the reason, and the administration will notify the student via email once the application is approved.\"}, {'query': 'What is the main goal of the AI course in the manufacturing industry?', 'answer': 'To enable middle to high-level managers to lead AI projects.'}, {'query': 'What is the address of the new board financial building mentioned in the document?', 'answer': '新北市板橋區中山路一段141號 14 樓'}, {'query': 'What is the discount for students who register for the LLM-B program and are accepted?', 'answer': '80% off the original price, with a total cost of NT$44,000.'}, {'query': 'What is the duration of the course in hours?', 'answer': '30 hours'}, {'query': 'What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the period from March 24th, 2024 to April 20th, 2024?', 'answer': '50%'}, {'query': 'How should one register for AIA Taipei Campus (Banqiao) according to the registration method?', 'answer': 'Through online registration, which should be completed before the deadline of March 4th, 2024.'}, {'query': 'What will happen to a student who has not been admitted to the school but is found to have committed academic dishonesty, such as plagiarism or falsification of academic records?', 'answer': \"The student's admission will be cancelled, and they will not be allowed to enroll in the school.\"}, {'query': 'What is the duration of the course, and what are the class hours?', 'answer': 'The course is 105 hours long, with classes held from 9:00 AM to 5:00 PM on Saturdays.'}, {'query': 'Who is the current manager of the Digital Innovation Center in Taichung City?', 'answer': \"The current manager of the Digital Innovation Center in Taichung City is the manager of Taichung City's giant steel machinery - Digital Innovation Center.\"}, {'query': 'What is the start date of the course \"AIGC實戰工作坊：ChatGPTX智慧工作新世紀\"?', 'answer': '2023/07/01'}, {'query': 'What will happen to a student who is found to have submitted false or forged information during the application process?', 'answer': \"The student's admission will be cancelled, and if the student has already been enrolled, their student status will be revoked, and they will be held legally responsible.\"}, {'query': 'What is the registration deadline for the \"大型語言模型實作進階班(LLM-B)\" course?', 'answer': '2023/11/16'}, {'query': 'What are the prerequisites for enrolling in this course?', 'answer': 'The prerequisites are having Python programming skills and basic knowledge of machine learning, and no prior exam is required.'}, {'query': 'What will happen if a student fails to complete the payment and registration process within the specified deadline?', 'answer': \"The student's enrollment will be cancelled, and they will not be eligible to take the exam or participate in the program.\"}, {'query': 'What is the minimum number of people required for a group booking for the course?', 'answer': '10 people'}, {'query': 'What is the main focus of the \"產業 AI 專班\" project launched by AIA in 2022?', 'answer': 'The main focus is on applying real-life cases to promote the development of AI in the industry, with a specific focus on the precision machinery manufacturing industry in the central region of Taiwan.'}, {'query': 'How many weeks does the special topic practical class meet?', 'answer': 'The special topic practical class meets for 5 weeks.'}, {'query': 'What is the deadline for students to submit a refund application for the current course before the course starts?', 'answer': '30 days prior to the course opening day (including the day of the course opening day).'}, {'query': 'What is the topic of the special lecture from 09:00 to 09:50 in the document?', 'answer': 'AIGC時代的學習方案：硬實力、軟素養、與未來發展路徑預估'}, {'query': 'Where will the physical classes for the graduation ceremony be held?', 'answer': 'The physical classes will be held at the Central Research Institute (Nangang), New Light Garden (Banqiao), or AIA Taipei Headquarters (Banqiao), with the final location to be determined based on the number of participants and venue conditions.'}, {'query': 'What is the registration fee for the course?', 'answer': 'New Taiwan dollars 25,000.'}, {'query': 'What is the start date of the course \"大型語言模型實作進階班(第四期)\"?', 'answer': '2024/08/03'}, {'query': 'What will happen to the fees if a participant cancels their registration after the activity has started?', 'answer': 'The fees will be refunded proportionally based on the cancellation date.'}, {'query': 'How can I apply for a refund?', 'answer': 'You can send an email to hi@aiacademy.tw, providing your class and name.'}, {'query': 'What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?', 'answer': '95%'}, {'query': 'What percentage of the tuition fee will be refunded to students who submit a refund application within 7 days of the course start date?', 'answer': '90%'}, {'query': 'What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the first one-third period of the course (from July 23rd to August 12th, 2023)?', 'answer': '50%'}, {'query': 'What is the deadline for filling out the registration form online?', 'answer': '2023/07/10'}, {'query': 'What is the deadline for completing the registration and payment process?', 'answer': '2 天內 (within 2 days)'}, {'query': 'How should one register for AIA Taipei Campus (Banqiao) according to the registration method?', 'answer': 'Through online registration, which should be completed before the deadline of October 26th, 2023.'}, {'query': 'What is the start date of the course \"大型語言模型實作進階班(第二期)\"?', 'answer': '2024/03/09'}, {'query': 'What is the start date of the course?', 'answer': '2024/07/06'}, {'query': 'How many weeks does the Intelligent Healthcare program take to complete, and what is the total number of hours?', 'answer': 'The Intelligent Healthcare program takes 5 weeks to complete, with a total of 37.5 hours of instruction time.'}, {'query': 'What is the duration of the activity?', 'answer': '3 days'}]\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM assisted evaluation"
      ],
      "metadata": {
        "id": "3yr7of8vNd3t"
      },
      "id": "3yr7of8vNd3t"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = qa_chain.apply(qa_examples) # 對所有 QA 範例進行預測，以供後續評估"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oATaZiPBNkXz",
        "outputId": "9076ba9c-8bee-4e61-f4e1-7e7be2f9cbff"
      },
      "id": "oATaZiPBNkXz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.apply` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use batch instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions)) # 確認數量"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXF_8jqqT3K0",
        "outputId": "b5beb507-3954-4da7-8860-8e2a40dd90ea"
      },
      "id": "gXF_8jqqT3K0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QAEvalChain"
      ],
      "metadata": {
        "id": "2GxJqEBNT677"
      },
      "id": "2GxJqEBNT677"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.qa import QAEvalChain"
      ],
      "metadata": {
        "id": "p3uOpYjvT_yL"
      },
      "id": "p3uOpYjvT_yL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_chain = QAEvalChain.from_llm(llm)"
      ],
      "metadata": {
        "id": "f8EPARPKUEC1"
      },
      "id": "f8EPARPKUEC1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對所有 QA 範例和預測結果進行比對評估，返回一堆評估分級\n",
        "graded_outputs = eval_chain.evaluate(qa_examples, predictions)\n",
        "len(graded_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqXTE8b5UMvE",
        "outputId": "80b3e3ec-63db-4977-8976-c381686b5266"
      },
      "id": "DqXTE8b5UMvE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRwcPyKPUPsV",
        "outputId": "814b72d0-cea7-4bf1-ac5e-d986609e2af9"
      },
      "id": "NRwcPyKPUPsV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'results': 'GRADE: INCORRECT'}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, eg in enumerate(qa_examples):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(\"Question: \" + predictions[i]['query'])\n",
        "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
        "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
        "    print(\"Predicted \" + graded_outputs[i]['results'])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv4Er6d6UTjM",
        "outputId": "4399adbe-e637-42e4-b58c-d1b1a64e948c"
      },
      "id": "Jv4Er6d6UTjM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 0:\n",
            "Question: What is the recommended method for requesting a replacement student ID card if it is lost?\n",
            "Real Answer: Sending an email to hi@aiacademy.tw with a request for a replacement student ID card.\n",
            "Predicted Answer: 沒有找到相關信息，無法回答這個問題。 thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 1:\n",
            "Question: Who are the professors invited to teach the core technologies and applications of artificial intelligence in the medical field?\n",
            "Real Answer: The professors invited include Chen Hong-xuan, Cai Yan-long, Zhuang Yong-yu, and Jiang Rong-xian.\n",
            "Predicted Answer: 不知道（wǒ bù zhī dào）. Thanks for asking!\n",
            "Predicted QUESTION: Who are the professors invited to teach the core technologies and applications of artificial intelligence in the medical field?\n",
            "STUDENT ANSWER: 不知道（wǒ bù zhī dào）. Thanks for asking!\n",
            "TRUE ANSWER: The professors invited include Chen Hong-xuan, Cai Yan-long, Zhuang Yong-yu, and Jiang Rong-xian.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 2:\n",
            "Question: What is the price for each person if there are 10 or more people in a group?\n",
            "Real Answer: NT$16,000\n",
            "Predicted Answer: 團體報名專屬優惠：報名人數達 5 位以上，每人優惠價為新台幣 32,000。thanks for asking!\n",
            "Predicted QUESTION: What is the price for each person if there are 10 or more people in a group?\n",
            "STUDENT ANSWER: 團體報名專屬優惠：報名人數達 5 位以上，每人優惠價為新台幣 32,000。\n",
            "TRUE ANSWER: NT$16,000\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 3:\n",
            "Question: What will happen to the fees if a participant cancels their registration after the activity has started?\n",
            "Real Answer: The fees will be refunded proportionally based on the cancellation date.\n",
            "Predicted Answer: 未知。thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 4:\n",
            "Question: Who was the director-general of Google?\n",
            "Real Answer: Eric Tsai\n",
            "Predicted Answer: 前董事總經理是1991年台大資工所博士班畢業，1993年加入中研院資訊所，2006年加入 Google，2020年退休。 thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 5:\n",
            "Question: What will happen to students who have submitted false or forged documents, such as fake academic records or certificates?\n",
            "Real Answer: Their admission will be cancelled, and if they have already been admitted, they will be expelled from school, and they will also be held legally responsible.\n",
            "Predicted Answer: 如果學生提交虛假或偽造的文件，例如假的學歷或證書，可能會被取消學籍或不予認證。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 6:\n",
            "Question: What are the circumstances under which a student is allowed to transfer to a different class after the start of the semester?\n",
            "Real Answer: According to the document, a student is only allowed to transfer to a different class under special circumstances, such as unforeseen events, and must provide proof to the school, which will then consider the request.\n",
            "Predicted Answer: 不知道。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What are the circumstances under which a student is allowed to transfer to a different class after the start of the semester?\n",
            "STUDENT ANSWER: 不知道。\n",
            "TRUE ANSWER: According to the document, a student is only allowed to transfer to a different class under special circumstances, such as unforeseen events, and must provide proof to the school, which will then consider the request.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 7:\n",
            "Question: How should students register for the course?\n",
            "Real Answer: Through the online registration system.\n",
            "Predicted Answer: 請先註冊ChatGPT並購買Midjourney訂閱方案。thanks for asking!\n",
            "Predicted QUESTION: How should students register for the course?\n",
            "STUDENT ANSWER: 請先註冊ChatGPT並購買Midjourney訂閱方案。thanks for asking!\n",
            "TRUE ANSWER: Through the online registration system.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 8:\n",
            "Question: What is the main goal of this course in the AI domain?\n",
            "Real Answer: To develop professionals who can apply AI technology to real-world problems and contribute to the progress of this revolutionary technology.\n",
            "Predicted Answer: 本課程的主要目的是介紹 LangChain 的應用和實現，包括資料處理、連接和使用 LangChain 實現 AI 應用。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What is the main goal of this course in the AI domain?\n",
            "STUDENT ANSWER: 本課程的主要目的是介紹 LangChain 的應用和實現，包括資料處理、連接和使用 LangChain 實現 AI 應用。\n",
            "TRUE ANSWER: To develop professionals who can apply AI technology to real-world problems and contribute to the progress of this revolutionary technology.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 9:\n",
            "Question: What is the main purpose of the \"智慧醫療專班\" (Intelligent Healthcare Program)?\n",
            "Real Answer: The main purpose of the \"智慧醫療專班\" is to enable medical professionals to quickly and systematically grasp the latest trends in artificial intelligence technology and understand how it works, its capabilities, limitations, and future developments, and apply it to medical work in every scenario.\n",
            "Predicted Answer: 智慧醫療專班的主要目的是透過人工智慧技術，應用於醫療領域，提高醫療服務質量和效率。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What is the main purpose of the \"智慧醫療專班\" (Intelligent Healthcare Program)?\n",
            "STUDENT ANSWER: 智慧醫療專班的主要目的是透過人工智慧技術，應用於醫療領域，提高醫療服務質量和效率。\n",
            "TRUE ANSWER: The main purpose of the \"智慧醫療專班\" is to enable medical professionals to quickly and systematically grasp the latest trends in artificial intelligence technology and understand how it works, its capabilities, limitations, and future developments, and apply it to medical work in every scenario.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 10:\n",
            "Question: What is the deadline for online registration for the program?\n",
            "Real Answer: 2023年05月01日 (May 1st, 2023)\n",
            "Predicted Answer: 報名截止日是2024/01/15。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 11:\n",
            "Question: What is the location of the classroom where the course will be held?\n",
            "Real Answer: 中研院人文館 第二會議室 (R2)\n",
            "Predicted Answer: 課程地點是台北總校。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What is the location of the classroom where the course will be held?\n",
            "STUDENT ANSWER: 課程地點是台北總校。\n",
            "TRUE ANSWER: 中研院人文館 第二會議室 (R2)\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 12:\n",
            "Question: What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?\n",
            "Real Answer: 95%\n",
            "Predicted Answer: 根據資料，退費申請需要於當期課程開課日前 7 日內提出。這意味著退費申請的截止日期是課程開課前 7 日，而不是 15 日。因此，我不知道答案。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?\n",
            "STUDENT ANSWER: 根據資料，退費申請需要於當期課程開課日前 7 日內提出。這意味著退費申請的截止日期是課程開課前 7 日，而不是 15 日。因此，我不知道答案。\n",
            "TRUE ANSWER: 95%\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 13:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within 7 days of the course start date?\n",
            "Real Answer: 50%\n",
            "Predicted Answer: 80%\n",
            "\n",
            "thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 14:\n",
            "Question: Where is the physical classroom for the course?\n",
            "Real Answer: The physical classroom is located at the Institute of Humanities, Room R2.\n",
            "Predicted Answer: 課程地點在台北總校，地址是新北市板橋區中山路一段141號14樓。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: Where is the physical classroom for the course?\n",
            "STUDENT ANSWER: 課程地點在台北總校，地址是新北市板橋區中山路一段141號14樓。\n",
            "TRUE ANSWER: The physical classroom is located at the Institute of Humanities, Room R2.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 15:\n",
            "Question: What happens if a student is unable to attend the graduation ceremony?\n",
            "Real Answer: The student's absence will be counted as an absence, and if the student needs to take a leave of absence, they must fill out a leave application form at https://reurl.cc/xZNOAL and upload proof of the reason, and the administration will notify the student via email once the application is approved.\n",
            "Predicted Answer: 如果學生無法出席畢業典禮，請發信至hi@aiacademy.tw詢問。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 16:\n",
            "Question: What is the main goal of the AI course in the manufacturing industry?\n",
            "Real Answer: To enable middle to high-level managers to lead AI projects.\n",
            "Predicted Answer: 課程目標是讓學員快速進入製造業應用場景，以產業深化案例與校友經驗分享引導、手把手體驗，啟發中高階經理人能 lead AI project。 Thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 17:\n",
            "Question: What is the address of the new board financial building mentioned in the document?\n",
            "Real Answer: 新北市板橋區中山路一段141號 14 樓\n",
            "Predicted Answer: 新北市板橋區中山路一段141號 14 樓\n",
            "\n",
            "thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 18:\n",
            "Question: What is the discount for students who register for the LLM-B program and are accepted?\n",
            "Real Answer: 80% off the original price, with a total cost of NT$44,000.\n",
            "Predicted Answer: 退費辦法：於當期課程開課日前 7 日內提出退費申請者，應退還當期開班約定繳納費用總額百分之九十。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 19:\n",
            "Question: What is the duration of the course in hours?\n",
            "Real Answer: 30 hours\n",
            "Predicted Answer: 不知道（wǒ bù zhī dào）\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 20:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the period from March 24th, 2024 to April 20th, 2024?\n",
            "Real Answer: 50%\n",
            "Predicted Answer: 退還當期開班約定繳納費用總額百分之九十五。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the period from March 24th, 2024 to April 20th, 2024?\n",
            "STUDENT ANSWER: 退還當期開班約定繳納費用總額百分之九十五。\n",
            "TRUE ANSWER: 50%\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 21:\n",
            "Question: How should one register for AIA Taipei Campus (Banqiao) according to the registration method?\n",
            "Real Answer: Through online registration, which should be completed before the deadline of March 4th, 2024.\n",
            "Predicted Answer: 可以通過網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。thanks for asking!\n",
            "Predicted QUESTION: How should one register for AIA Taipei Campus (Banqiao) according to the registration method?\n",
            "STUDENT ANSWER: 可以通過網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。thanks for asking!\n",
            "TRUE ANSWER: Through online registration, which should be completed before the deadline of March 4th, 2024.\n",
            "GRADE: CORRECT\n",
            "\n",
            "Example 22:\n",
            "Question: What will happen to a student who has not been admitted to the school but is found to have committed academic dishonesty, such as plagiarism or falsification of academic records?\n",
            "Real Answer: The student's admission will be cancelled, and they will not be allowed to enroll in the school.\n",
            "Predicted Answer: 根據台灣人工智慧學校的規定，學生如果未被錄取，但發現有學術不正當行為，例如抄襲或學術記錄偽造，將會被取消學籍。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What will happen to a student who has not been admitted to the school but is found to have committed academic dishonesty, such as plagiarism or falsification of academic records?\n",
            "STUDENT ANSWER: 根據台灣人工智慧學校的規定，學生如果未被錄取，但發現有學術不正當行為，例如抄襲或學術記錄偽造，將會被取消學籍。\n",
            "TRUE ANSWER: The student's admission will be cancelled, and they will not be allowed to enroll in the school.\n",
            "GRADE: CORRECT\n",
            "\n",
            "Example 23:\n",
            "Question: What is the duration of the course, and what are the class hours?\n",
            "Real Answer: The course is 105 hours long, with classes held from 9:00 AM to 5:00 PM on Saturdays.\n",
            "Predicted Answer: 课程的持续时间是从2024/07/03到未知，具体的上课时间和地点请查看招生简章。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 24:\n",
            "Question: Who is the current manager of the Digital Innovation Center in Taichung City?\n",
            "Real Answer: The current manager of the Digital Innovation Center in Taichung City is the manager of Taichung City's giant steel machinery - Digital Innovation Center.\n",
            "Predicted Answer: 不知道。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: Who is the current manager of the Digital Innovation Center in Taichung City?\n",
            "STUDENT ANSWER: 不知道。\n",
            "TRUE ANSWER: The current manager of the Digital Innovation Center in Taichung City is the manager of Taichung City's giant steel machinery - Digital Innovation Center.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 25:\n",
            "Question: What is the start date of the course \"AIGC實戰工作坊：ChatGPTX智慧工作新世紀\"?\n",
            "Real Answer: 2023/07/01\n",
            "Predicted Answer: 2023/07/01\n",
            "\n",
            "thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 26:\n",
            "Question: What will happen to a student who is found to have submitted false or forged information during the application process?\n",
            "Real Answer: The student's admission will be cancelled, and if the student has already been enrolled, their student status will be revoked, and they will be held legally responsible.\n",
            "Predicted Answer: 根據規定，發現學生在申請過程中提交虛假或偽造信息的，將會被取消學籍。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What will happen to a student who is found to have submitted false or forged information during the application process?\n",
            "STUDENT ANSWER: 根據規定，發現學生在申請過程中提交虛假或偽造信息的，將會被取消學籍。\n",
            "TRUE ANSWER: The student's admission will be cancelled, and if the student has already been enrolled, their student status will be revoked, and they will be held legally responsible.\n",
            "GRADE: CORRECT\n",
            "\n",
            "Example 27:\n",
            "Question: What is the registration deadline for the \"大型語言模型實作進階班(LLM-B)\" course?\n",
            "Real Answer: 2023/11/16\n",
            "Predicted Answer: 報名截止日是2023/11/16。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 28:\n",
            "Question: What are the prerequisites for enrolling in this course?\n",
            "Real Answer: The prerequisites are having Python programming skills and basic knowledge of machine learning, and no prior exam is required.\n",
            "Predicted Answer: 本課程的入學條件為：具備台灣人工智慧學校結業證書。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 29:\n",
            "Question: What will happen if a student fails to complete the payment and registration process within the specified deadline?\n",
            "Real Answer: The student's enrollment will be cancelled, and they will not be eligible to take the exam or participate in the program.\n",
            "Predicted Answer: 如果學生未能在指定的截止日期完成付款和登記程序，將會全額退還已繳費用。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 30:\n",
            "Question: What is the minimum number of people required for a group booking for the course?\n",
            "Real Answer: 10 people\n",
            "Predicted Answer: 團報優惠專享 (5人)每人新台幣 32,000 元。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 31:\n",
            "Question: What is the main focus of the \"產業 AI 專班\" project launched by AIA in 2022?\n",
            "Real Answer: The main focus is on applying real-life cases to promote the development of AI in the industry, with a specific focus on the precision machinery manufacturing industry in the central region of Taiwan.\n",
            "Predicted Answer: 本課程的主要焦點是推展「產業 AI 專班」，聚焦在加工組裝製程，為期八週的課程，授予學員製造業全面應用人工智慧與淨零碳排、綠色製造等相關知識。 thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 32:\n",
            "Question: How many weeks does the special topic practical class meet?\n",
            "Real Answer: The special topic practical class meets for 5 weeks.\n",
            "Predicted Answer: 不知道（I don't know）\n",
            "\n",
            "thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 33:\n",
            "Question: What is the deadline for students to submit a refund application for the current course before the course starts?\n",
            "Real Answer: 30 days prior to the course opening day (including the day of the course opening day).\n",
            "Predicted Answer: 報名截止日是2024/01/15，學生需要在這個日期前完成報名和付款。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted QUESTION: What is the deadline for students to submit a refund application for the current course before the course starts?\n",
            "STUDENT ANSWER: 報名截止日是2024/01/15，學生需要在這個日期前完成報名和付款。\n",
            "TRUE ANSWER: 30 days prior to the course opening day (including the day of the course opening day).\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 34:\n",
            "Question: What is the topic of the special lecture from 09:00 to 09:50 in the document?\n",
            "Real Answer: AIGC時代的學習方案：硬實力、軟素養、與未來發展路徑預估\n",
            "Predicted Answer: 沒有找到相關的信息，無法找到特定的講座主題。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: CORRECT\n",
            "\n",
            "Example 35:\n",
            "Question: Where will the physical classes for the graduation ceremony be held?\n",
            "Real Answer: The physical classes will be held at the Central Research Institute (Nangang), New Light Garden (Banqiao), or AIA Taipei Headquarters (Banqiao), with the final location to be determined based on the number of participants and venue conditions.\n",
            "Predicted Answer: 沒有明確的信息表明了畢業典禮的實體課程地點。\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 36:\n",
            "Question: What is the registration fee for the course?\n",
            "Real Answer: New Taiwan dollars 25,000.\n",
            "Predicted Answer: 課程報名費用為新台幣 12,000 元。thanks for asking!\n",
            "Predicted QUESTION: What is the registration fee for the course?\n",
            "STUDENT ANSWER: 課程報名費用為新台幣 12,000 元。thanks for asking!\n",
            "TRUE ANSWER: New Taiwan dollars 25,000.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 37:\n",
            "Question: What is the start date of the course \"大型語言模型實作進階班(第四期)\"?\n",
            "Real Answer: 2024/08/03\n",
            "Predicted Answer: 2024年7月3日。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What is the start date of the course \"大型語言模型實作進階班(第四期)\"?\n",
            "STUDENT ANSWER: 2024年7月3日。\n",
            "TRUE ANSWER: 2024/08/03\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 38:\n",
            "Question: What will happen to the fees if a participant cancels their registration after the activity has started?\n",
            "Real Answer: The fees will be refunded proportionally based on the cancellation date.\n",
            "Predicted Answer: 未知。thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 39:\n",
            "Question: How can I apply for a refund?\n",
            "Real Answer: You can send an email to hi@aiacademy.tw, providing your class and name.\n",
            "Predicted Answer: 沒有明確的退款政策。請聯繫客服電話04-2298-6620或寄信至camp@aiacademy.tw，將有專人為您服務。thanks for asking!\n",
            "Predicted QUESTION: How can I apply for a refund?\n",
            "STUDENT ANSWER: 沒有明確的退款政策。請聯繫客服電話04-2298-6620或寄信至camp@aiacademy.tw，將有專人為您服務。thanks for asking!\n",
            "TRUE ANSWER: You can send an email to hi@aiacademy.tw, providing your class and name.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 40:\n",
            "Question: What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?\n",
            "Real Answer: 95%\n",
            "Predicted Answer: 根據資料，退費申請需要於當期課程開課日前 7 日內提出。這意味著退費申請的截止日期是課程開課前 7 日，而不是 15 日。因此，我不知道答案。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?\n",
            "STUDENT ANSWER: 根據資料，退費申請需要於當期課程開課日前 7 日內提出。這意味著退費申請的截止日期是課程開課前 7 日，而不是 15 日。因此，我不知道答案。\n",
            "TRUE ANSWER: 95%\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 41:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a refund application within 7 days of the course start date?\n",
            "Real Answer: 90%\n",
            "Predicted Answer: 80%\n",
            "\n",
            "thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 42:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the first one-third period of the course (from July 23rd to August 12th, 2023)?\n",
            "Real Answer: 50%\n",
            "Predicted Answer: 不知道。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the first one-third period of the course (from July 23rd to August 12th, 2023)?\n",
            "STUDENT ANSWER: 不知道。\n",
            "TRUE ANSWER: 50%\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 43:\n",
            "Question: What is the deadline for filling out the registration form online?\n",
            "Real Answer: 2023/07/10\n",
            "Predicted Answer: 報名截止日是2023/11/16。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What is the deadline for filling out the registration form online?\n",
            "STUDENT ANSWER: 報名截止日是2023/11/16。\n",
            "TRUE ANSWER: 2023/07/10\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 44:\n",
            "Question: What is the deadline for completing the registration and payment process?\n",
            "Real Answer: 2 天內 (within 2 days)\n",
            "Predicted Answer: 報名截止日為2024年01月20日。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 45:\n",
            "Question: How should one register for AIA Taipei Campus (Banqiao) according to the registration method?\n",
            "Real Answer: Through online registration, which should be completed before the deadline of October 26th, 2023.\n",
            "Predicted Answer: 可以通過網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。thanks for asking!\n",
            "Predicted QUESTION: How should one register for AIA Taipei Campus (Banqiao) according to the registration method?\n",
            "STUDENT ANSWER: 可以通過網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。thanks for asking!\n",
            "TRUE ANSWER: Through online registration, which should be completed before the deadline of October 26th, 2023.\n",
            "GRADE: CORRECT\n",
            "\n",
            "Example 46:\n",
            "Question: What is the start date of the course \"大型語言模型實作進階班(第二期)\"?\n",
            "Real Answer: 2024/03/09\n",
            "Predicted Answer: 2023年12月9日。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: What is the start date of the course \"大型語言模型實作進階班(第二期)\"?\n",
            "STUDENT ANSWER: 2023年12月9日。\n",
            "TRUE ANSWER: 2024/03/09\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 47:\n",
            "Question: What is the start date of the course?\n",
            "Real Answer: 2024/07/06\n",
            "Predicted Answer: 2023年12月9日。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n",
            "Example 48:\n",
            "Question: How many weeks does the Intelligent Healthcare program take to complete, and what is the total number of hours?\n",
            "Real Answer: The Intelligent Healthcare program takes 5 weeks to complete, with a total of 37.5 hours of instruction time.\n",
            "Predicted Answer: 本課程共 8 週，總共 40 小時。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted QUESTION: How many weeks does the Intelligent Healthcare program take to complete, and what is the total number of hours?\n",
            "STUDENT ANSWER: 本課程共 8 週，總共 40 小時。\n",
            "TRUE ANSWER: The Intelligent Healthcare program takes 5 weeks to complete, with a total of 37.5 hours of instruction time.\n",
            "GRADE: INCORRECT\n",
            "\n",
            "Example 49:\n",
            "Question: What is the duration of the activity?\n",
            "Real Answer: 3 days\n",
            "Predicted Answer: 活動的持續時間為7天。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted GRADE: INCORRECT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring Evaluator"
      ],
      "metadata": {
        "id": "E5UvQMpuZ6t5"
      },
      "id": "E5UvQMpuZ6t5"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation import load_evaluator\n",
        "evaluator = load_evaluator(\"labeled_score_string\", llm=llm)"
      ],
      "metadata": {
        "id": "V-qSpvDHZ8lL"
      },
      "id": "V-qSpvDHZ8lL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample test\n",
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=\"You can find them in the dresser's third drawer.\",\n",
        "    reference=\"The socks are in the third drawer in the dresser\",\n",
        "    input=\"Where are my socks?\",\n",
        ")\n",
        "print(eval_result['score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rN1N2fhaBPf",
        "outputId": "a36d8208-4419-4213-805b-7252686a824f"
      },
      "id": "0rN1N2fhaBPf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 對所有 QA 範例和預測結果進行比對評估，返回一堆評估分級\n",
        "# graded_outputs = eval_chain.evaluate(qa_examples, predictions)\n",
        "# len(graded_outputs)\n",
        "\n",
        "for i, eg in enumerate(qa_examples):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(\"Question: \" + predictions[i]['query'])\n",
        "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
        "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
        "    print(\"Predicted Score: \" +\n",
        "          str(\n",
        "              evaluator.evaluate_strings(\n",
        "                  prediction=predictions[i]['result'],\n",
        "                  reference=predictions[i]['answer'],\n",
        "                  input=predictions[i]['query']\n",
        "                  )['score']\n",
        "              )\n",
        "          )\n",
        "    print()\n",
        "\n",
        "# eval_result =\n",
        "# print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9d2y1H1aDyi",
        "outputId": "c964dd8a-e083-424a-e501-18430434ca63"
      },
      "id": "a9d2y1H1aDyi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 0:\n",
            "Question: What is the recommended method for requesting a replacement student ID card if it is lost?\n",
            "Real Answer: Sending an email to hi@aiacademy.tw with a request for a replacement student ID card.\n",
            "Predicted Answer: 沒有找到相關信息，無法回答這個問題。 thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 1:\n",
            "Question: Who are the professors invited to teach the core technologies and applications of artificial intelligence in the medical field?\n",
            "Real Answer: The professors invited include Chen Hong-xuan, Cai Yan-long, Zhuang Yong-yu, and Jiang Rong-xian.\n",
            "Predicted Answer: 不知道（wǒ bù zhī dào）. Thanks for asking!\n",
            "Predicted Score: 1\n",
            "\n",
            "Example 2:\n",
            "Question: What is the price for each person if there are 10 or more people in a group?\n",
            "Real Answer: NT$16,000\n",
            "Predicted Answer: 團體報名專屬優惠：報名人數達 5 位以上，每人優惠價為新台幣 32,000。thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 3:\n",
            "Question: What will happen to the fees if a participant cancels their registration after the activity has started?\n",
            "Real Answer: The fees will be refunded proportionally based on the cancellation date.\n",
            "Predicted Answer: 未知。thanks for asking!\n",
            "Predicted Score: 1\n",
            "\n",
            "Example 4:\n",
            "Question: Who was the director-general of Google?\n",
            "Real Answer: Eric Tsai\n",
            "Predicted Answer: 前董事總經理是1991年台大資工所博士班畢業，1993年加入中研院資訊所，2006年加入 Google，2020年退休。 thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 5:\n",
            "Question: What will happen to students who have submitted false or forged documents, such as fake academic records or certificates?\n",
            "Real Answer: Their admission will be cancelled, and if they have already been admitted, they will be expelled from school, and they will also be held legally responsible.\n",
            "Predicted Answer: 如果學生提交虛假或偽造的文件，例如假的學歷或證書，可能會被取消學籍或不予認證。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 6:\n",
            "Question: What are the circumstances under which a student is allowed to transfer to a different class after the start of the semester?\n",
            "Real Answer: According to the document, a student is only allowed to transfer to a different class under special circumstances, such as unforeseen events, and must provide proof to the school, which will then consider the request.\n",
            "Predicted Answer: 不知道。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 1\n",
            "\n",
            "Example 7:\n",
            "Question: How should students register for the course?\n",
            "Real Answer: Through the online registration system.\n",
            "Predicted Answer: 請先註冊ChatGPT並購買Midjourney訂閱方案。thanks for asking!\n",
            "Predicted Score: 1\n",
            "\n",
            "Example 8:\n",
            "Question: What is the main goal of this course in the AI domain?\n",
            "Real Answer: To develop professionals who can apply AI technology to real-world problems and contribute to the progress of this revolutionary technology.\n",
            "Predicted Answer: 本課程的主要目的是介紹 LangChain 的應用和實現，包括資料處理、連接和使用 LangChain 實現 AI 應用。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 3\n",
            "\n",
            "Example 9:\n",
            "Question: What is the main purpose of the \"智慧醫療專班\" (Intelligent Healthcare Program)?\n",
            "Real Answer: The main purpose of the \"智慧醫療專班\" is to enable medical professionals to quickly and systematically grasp the latest trends in artificial intelligence technology and understand how it works, its capabilities, limitations, and future developments, and apply it to medical work in every scenario.\n",
            "Predicted Answer: 智慧醫療專班的主要目的是透過人工智慧技術，應用於醫療領域，提高醫療服務質量和效率。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 10:\n",
            "Question: What is the deadline for online registration for the program?\n",
            "Real Answer: 2023年05月01日 (May 1st, 2023)\n",
            "Predicted Answer: 報名截止日是2024/01/15。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 11:\n",
            "Question: What is the location of the classroom where the course will be held?\n",
            "Real Answer: 中研院人文館 第二會議室 (R2)\n",
            "Predicted Answer: 課程地點是台北總校。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 7\n",
            "\n",
            "Example 12:\n",
            "Question: What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?\n",
            "Real Answer: 95%\n",
            "Predicted Answer: 根據資料，退費申請需要於當期課程開課日前 7 日內提出。這意味著退費申請的截止日期是課程開課前 7 日，而不是 15 日。因此，我不知道答案。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 13:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within 7 days of the course start date?\n",
            "Real Answer: 50%\n",
            "Predicted Answer: 80%\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 14:\n",
            "Question: Where is the physical classroom for the course?\n",
            "Real Answer: The physical classroom is located at the Institute of Humanities, Room R2.\n",
            "Predicted Answer: 課程地點在台北總校，地址是新北市板橋區中山路一段141號14樓。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 15:\n",
            "Question: What happens if a student is unable to attend the graduation ceremony?\n",
            "Real Answer: The student's absence will be counted as an absence, and if the student needs to take a leave of absence, they must fill out a leave application form at https://reurl.cc/xZNOAL and upload proof of the reason, and the administration will notify the student via email once the application is approved.\n",
            "Predicted Answer: 如果學生無法出席畢業典禮，請發信至hi@aiacademy.tw詢問。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 16:\n",
            "Question: What is the main goal of the AI course in the manufacturing industry?\n",
            "Real Answer: To enable middle to high-level managers to lead AI projects.\n",
            "Predicted Answer: 課程目標是讓學員快速進入製造業應用場景，以產業深化案例與校友經驗分享引導、手把手體驗，啟發中高階經理人能 lead AI project。 Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 17:\n",
            "Question: What is the address of the new board financial building mentioned in the document?\n",
            "Real Answer: 新北市板橋區中山路一段141號 14 樓\n",
            "Predicted Answer: 新北市板橋區中山路一段141號 14 樓\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 9\n",
            "\n",
            "Example 18:\n",
            "Question: What is the discount for students who register for the LLM-B program and are accepted?\n",
            "Real Answer: 80% off the original price, with a total cost of NT$44,000.\n",
            "Predicted Answer: 退費辦法：於當期課程開課日前 7 日內提出退費申請者，應退還當期開班約定繳納費用總額百分之九十。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 19:\n",
            "Question: What is the duration of the course in hours?\n",
            "Real Answer: 30 hours\n",
            "Predicted Answer: 不知道（wǒ bù zhī dào）\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 20:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the period from March 24th, 2024 to April 20th, 2024?\n",
            "Real Answer: 50%\n",
            "Predicted Answer: 退還當期開班約定繳納費用總額百分之九十五。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 21:\n",
            "Question: How should one register for AIA Taipei Campus (Banqiao) according to the registration method?\n",
            "Real Answer: Through online registration, which should be completed before the deadline of March 4th, 2024.\n",
            "Predicted Answer: 可以通過網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 22:\n",
            "Question: What will happen to a student who has not been admitted to the school but is found to have committed academic dishonesty, such as plagiarism or falsification of academic records?\n",
            "Real Answer: The student's admission will be cancelled, and they will not be allowed to enroll in the school.\n",
            "Predicted Answer: 根據台灣人工智慧學校的規定，學生如果未被錄取，但發現有學術不正當行為，例如抄襲或學術記錄偽造，將會被取消學籍。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 23:\n",
            "Question: What is the duration of the course, and what are the class hours?\n",
            "Real Answer: The course is 105 hours long, with classes held from 9:00 AM to 5:00 PM on Saturdays.\n",
            "Predicted Answer: 课程的持续时间是从2024/07/03到未知，具体的上课时间和地点请查看招生简章。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 1\n",
            "\n",
            "Example 24:\n",
            "Question: Who is the current manager of the Digital Innovation Center in Taichung City?\n",
            "Real Answer: The current manager of the Digital Innovation Center in Taichung City is the manager of Taichung City's giant steel machinery - Digital Innovation Center.\n",
            "Predicted Answer: 不知道。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 25:\n",
            "Question: What is the start date of the course \"AIGC實戰工作坊：ChatGPTX智慧工作新世紀\"?\n",
            "Real Answer: 2023/07/01\n",
            "Predicted Answer: 2023/07/01\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 8\n",
            "\n",
            "Example 26:\n",
            "Question: What will happen to a student who is found to have submitted false or forged information during the application process?\n",
            "Real Answer: The student's admission will be cancelled, and if the student has already been enrolled, their student status will be revoked, and they will be held legally responsible.\n",
            "Predicted Answer: 根據規定，發現學生在申請過程中提交虛假或偽造信息的，將會被取消學籍。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 8\n",
            "\n",
            "Example 27:\n",
            "Question: What is the registration deadline for the \"大型語言模型實作進階班(LLM-B)\" course?\n",
            "Real Answer: 2023/11/16\n",
            "Predicted Answer: 報名截止日是2023/11/16。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 28:\n",
            "Question: What are the prerequisites for enrolling in this course?\n",
            "Real Answer: The prerequisites are having Python programming skills and basic knowledge of machine learning, and no prior exam is required.\n",
            "Predicted Answer: 本課程的入學條件為：具備台灣人工智慧學校結業證書。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 29:\n",
            "Question: What will happen if a student fails to complete the payment and registration process within the specified deadline?\n",
            "Real Answer: The student's enrollment will be cancelled, and they will not be eligible to take the exam or participate in the program.\n",
            "Predicted Answer: 如果學生未能在指定的截止日期完成付款和登記程序，將會全額退還已繳費用。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 30:\n",
            "Question: What is the minimum number of people required for a group booking for the course?\n",
            "Real Answer: 10 people\n",
            "Predicted Answer: 團報優惠專享 (5人)每人新台幣 32,000 元。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 31:\n",
            "Question: What is the main focus of the \"產業 AI 專班\" project launched by AIA in 2022?\n",
            "Real Answer: The main focus is on applying real-life cases to promote the development of AI in the industry, with a specific focus on the precision machinery manufacturing industry in the central region of Taiwan.\n",
            "Predicted Answer: 本課程的主要焦點是推展「產業 AI 專班」，聚焦在加工組裝製程，為期八週的課程，授予學員製造業全面應用人工智慧與淨零碳排、綠色製造等相關知識。 thanks for asking!\n",
            "Predicted Score: 3\n",
            "\n",
            "Example 32:\n",
            "Question: How many weeks does the special topic practical class meet?\n",
            "Real Answer: The special topic practical class meets for 5 weeks.\n",
            "Predicted Answer: 不知道（I don't know）\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 33:\n",
            "Question: What is the deadline for students to submit a refund application for the current course before the course starts?\n",
            "Real Answer: 30 days prior to the course opening day (including the day of the course opening day).\n",
            "Predicted Answer: 報名截止日是2024/01/15，學生需要在這個日期前完成報名和付款。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 34:\n",
            "Question: What is the topic of the special lecture from 09:00 to 09:50 in the document?\n",
            "Real Answer: AIGC時代的學習方案：硬實力、軟素養、與未來發展路徑預估\n",
            "Predicted Answer: 沒有找到相關的信息，無法找到特定的講座主題。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 35:\n",
            "Question: Where will the physical classes for the graduation ceremony be held?\n",
            "Real Answer: The physical classes will be held at the Central Research Institute (Nangang), New Light Garden (Banqiao), or AIA Taipei Headquarters (Banqiao), with the final location to be determined based on the number of participants and venue conditions.\n",
            "Predicted Answer: 沒有明確的信息表明了畢業典禮的實體課程地點。\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 36:\n",
            "Question: What is the registration fee for the course?\n",
            "Real Answer: New Taiwan dollars 25,000.\n",
            "Predicted Answer: 課程報名費用為新台幣 12,000 元。thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 37:\n",
            "Question: What is the start date of the course \"大型語言模型實作進階班(第四期)\"?\n",
            "Real Answer: 2024/08/03\n",
            "Predicted Answer: 2024年7月3日。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 8\n",
            "\n",
            "Example 38:\n",
            "Question: What will happen to the fees if a participant cancels their registration after the activity has started?\n",
            "Real Answer: The fees will be refunded proportionally based on the cancellation date.\n",
            "Predicted Answer: 未知。thanks for asking!\n",
            "Predicted Score: 1\n",
            "\n",
            "Example 39:\n",
            "Question: How can I apply for a refund?\n",
            "Real Answer: You can send an email to hi@aiacademy.tw, providing your class and name.\n",
            "Predicted Answer: 沒有明確的退款政策。請聯繫客服電話04-2298-6620或寄信至camp@aiacademy.tw，將有專人為您服務。thanks for asking!\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 40:\n",
            "Question: What percentage of the total tuition fee will be refunded to students who submit a refund application 15 days before the start of the course?\n",
            "Real Answer: 95%\n",
            "Predicted Answer: 根據資料，退費申請需要於當期課程開課日前 7 日內提出。這意味著退費申請的截止日期是課程開課前 7 日，而不是 15 日。因此，我不知道答案。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 6\n",
            "\n",
            "Example 41:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a refund application within 7 days of the course start date?\n",
            "Real Answer: 90%\n",
            "Predicted Answer: 80%\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 42:\n",
            "Question: What percentage of the tuition fee will be refunded to students who submit a withdrawal application within the first one-third period of the course (from July 23rd to August 12th, 2023)?\n",
            "Real Answer: 50%\n",
            "Predicted Answer: 不知道。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 43:\n",
            "Question: What is the deadline for filling out the registration form online?\n",
            "Real Answer: 2023/07/10\n",
            "Predicted Answer: 報名截止日是2023/11/16。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 8\n",
            "\n",
            "Example 44:\n",
            "Question: What is the deadline for completing the registration and payment process?\n",
            "Real Answer: 2 天內 (within 2 days)\n",
            "Predicted Answer: 報名截止日為2024年01月20日。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 8\n",
            "\n",
            "Example 45:\n",
            "Question: How should one register for AIA Taipei Campus (Banqiao) according to the registration method?\n",
            "Real Answer: Through online registration, which should be completed before the deadline of October 26th, 2023.\n",
            "Predicted Answer: 可以通過網路報名，請於報名截止日 2024 年 06 月 24 日前上網填寫報名資料。請完整填寫報名表，以利完成審核程序。thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 46:\n",
            "Question: What is the start date of the course \"大型語言模型實作進階班(第二期)\"?\n",
            "Real Answer: 2024/03/09\n",
            "Predicted Answer: 2023年12月9日。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 8\n",
            "\n",
            "Example 47:\n",
            "Question: What is the start date of the course?\n",
            "Real Answer: 2024/07/06\n",
            "Predicted Answer: 2023年12月9日。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 4\n",
            "\n",
            "Example 48:\n",
            "Question: How many weeks does the Intelligent Healthcare program take to complete, and what is the total number of hours?\n",
            "Real Answer: The Intelligent Healthcare program takes 5 weeks to complete, with a total of 37.5 hours of instruction time.\n",
            "Predicted Answer: 本課程共 8 週，總共 40 小時。\n",
            "\n",
            "thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n",
            "Example 49:\n",
            "Question: What is the duration of the activity?\n",
            "Real Answer: 3 days\n",
            "Predicted Answer: 活動的持續時間為7天。\n",
            "\n",
            "Thanks for asking!\n",
            "Predicted Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step9 : 建立LangSmith evaluation"
      ],
      "metadata": {
        "id": "HICPM0kDaI0Z"
      },
      "id": "HICPM0kDaI0Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "intsall LangSmith"
      ],
      "metadata": {
        "id": "F-4CJDgzfZ91"
      },
      "id": "F-4CJDgzfZ91"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langsmith # evaluation platform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY_o2gLgeurR",
        "outputId": "a705433e-9849-4238-cbff-21a466616a86"
      },
      "id": "qY_o2gLgeurR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.56)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "其他環境設定"
      ],
      "metadata": {
        "id": "BERMEiCVfbFt"
      },
      "id": "BERMEiCVfbFt"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" # 告訴 LangChain 啟用記錄追蹤 (如使用 RunTree API，可以不用設定啟用)\n",
        "# os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\" # 指定記錄到哪個 project (預設記錄在 default project；指定 project 不存在時，會自動協助建立；詳緦可登入 LangSmith 平台查看)\n",
        "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ],
      "metadata": {
        "id": "AKsujSnafd5P"
      },
      "id": "AKsujSnafd5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "f7zrMKIPgEBW"
      },
      "id": "f7zrMKIPgEBW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立 Langsmith 客戶端"
      ],
      "metadata": {
        "id": "X4MNELehflWg"
      },
      "id": "X4MNELehflWg"
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client() # 建立 langsmith 客戶端以與 API 互動\n",
        "\n",
        "# 指定 LangSmith Dataset (如未建立，需執行下段「建立 dataset 及 QA samples」程式)\n",
        "\n",
        "dataset_name = \"AIA Q&A Dataset\" # 完整 AIA Q&A 共 47 筆\n",
        "# dataset_name = \"AIA Q&A Dataset_oneTest\" # 只有一筆 QA"
      ],
      "metadata": {
        "id": "TPEyKU5sfi9r"
      },
      "id": "TPEyKU5sfi9r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立 dataset 及 QA samples(婷方已建立 可略過）\n",
        "在 LangSmith 平台上建立新的資料集和樣本資料\n"
      ],
      "metadata": {
        "id": "qh4fvTbJgVP8"
      },
      "id": "qh4fvTbJgVP8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset:\n",
        "# dataset_aia = client.create_dataset(dataset_name, description=\"## AIA Q&A集: https://aiacademy.tw/AIA_QA/qa_data_12AJAJCIqeck45.php (僅供專題使用)\")"
      ],
      "metadata": {
        "id": "qW2aT2pQgN-N"
      },
      "id": "qW2aT2pQgN-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 建立樣本資料 - AIA Q&A 集\n",
        "# import requests\n",
        "\n",
        "# # 載入 AIA Q&A 集\n",
        "# response = requests.get(\"https://aiacademy.tw/AIA_QA/qa_data_12AJAJCIqeck45.php\")\n",
        "# data = response.json()  # Decode the JSON data\n",
        "# queries = []\n",
        "# answers = []\n",
        "# for i in data:\n",
        "#   if len(i)<2 or i[0]==\"常見問題\": #處理標題/分類 列\n",
        "#     pass\n",
        "#   else:\n",
        "#     query = {\"query\":i[0]}\n",
        "#     answer = {\"answer\":i[1]}\n",
        "#     queries.append(query)\n",
        "#     answers.append(answer)\n",
        "\n",
        "# # 上傳至 LangSmith \"AIA Q&A Dataset\" 資料集\n",
        "# client.create_examples(\n",
        "#     inputs = queries,\n",
        "#     outputs = answers,\n",
        "#     dataset_id = dataset_aia.id\n",
        "# )"
      ],
      "metadata": {
        "id": "A1aVf67tgOBF"
      },
      "id": "A1aVf67tgOBF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立evaluation使用的PromptTemplate"
      ],
      "metadata": {
        "id": "athYcVT2iZtV"
      },
      "id": "athYcVT2iZtV"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langsmith.evaluation import LangChainStringEvaluator\n",
        "\n",
        "_PROMPT_TEMPLATE = \"\"\"You are an expert professor specialized in grading students' answers to questions.\n",
        "You are grading the following question:\n",
        "{query}\n",
        "Here is the real answer:\n",
        "{answer}\n",
        "You are grading the following predicted answer:\n",
        "{result}\n",
        "Respond with CORRECT or INCORRECT:\n",
        "Grade:\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\", \"result\"], template=_PROMPT_TEMPLATE\n",
        ")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": llm, \"prompt\": PROMPT})"
      ],
      "metadata": {
        "id": "DdjDFC2KgOD7"
      },
      "id": "DdjDFC2KgOD7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "評估 llm 回答的長度，確保我們的答案 (如預期的) 簡短明瞭"
      ],
      "metadata": {
        "id": "QFOHqUhIiho3"
      },
      "id": "QFOHqUhIiho3"
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查實際輸出是否小於預期結果長度的 2 倍\n",
        "from langsmith.schemas import Run, Example\n",
        "\n",
        "def evaluate_length(run: Run, example: Example) -> dict:\n",
        "    prediction = run.outputs.get(\"output\") or \"\"\n",
        "    required = example.outputs.get(\"answer\") or \"\"\n",
        "    score = int(len(prediction) < 2 * len(required))\n",
        "    return {\"key\":\"length\", \"score\": score}"
      ],
      "metadata": {
        "id": "j8P9igrugOGa"
      },
      "id": "j8P9igrugOGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 針對question進行Answer的prediction"
      ],
      "metadata": {
        "id": "lDsTlCGsilUt"
      },
      "id": "lDsTlCGsilUt"
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_prediction(question):\n",
        "  result = qa_chain.invoke({\"query\": question})\n",
        "  return result[\"result\"]"
      ],
      "metadata": {
        "id": "cvGXdwwjVkoA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cvGXdwwjVkoA"
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義一個簡單的包裝器，將 (LangSmith) 資料集中的 input key 對應到我們想要呼叫的函數，然後也將函數的輸出對應到我們期望的 output key。\n",
        "def langsmith_app(inputs):\n",
        "    output = llm_prediction(inputs[\"query\"])\n",
        "    return {\"answer\": output}"
      ],
      "metadata": {
        "id": "1D8ZhZM8npHI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1D8ZhZM8npHI"
    },
    {
      "cell_type": "code",
      "source": [
        "#執行後，可至下方介面查看結果\n",
        "# AIA Q&A Dataset:\n",
        "# https://smith.langchain.com/public/6cd4801e-f174-4674-ba06-dda2ab18191d/d\n",
        "# AIA Q&A Dataset_oneTest:\n",
        "# https://smith.langchain.com/public/eb428b1b-b27e-47a4-8111-dfa612ddb8ef/d\n",
        "# from langsmith.evaluation import evaluate\n",
        "\n",
        "experiment_results = evaluate(\n",
        "    langsmith_app, # Your AI system\n",
        "    data=dataset_name, # The data to predict and grade over\n",
        "    evaluators=[evaluate_length, qa_evaluator], # The evaluators to score the results\n",
        "    experiment_prefix=\"131027_Ollama-llama3_DB-xt131028_v1-Nomic-embedding\", # A prefix for your experiment names to easily identify them\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7cb89cf87404376ba7178926a6ac0fc",
            "6c9a16d7cc6b4cd0b0769a0701178a89",
            "092770d619964970bbe26d52a7d5f8bc",
            "32629205012f4a44bccacfd54f276cf9",
            "4cc08b1ed1074678ab3463cfa0d86e84",
            "8d1c30f165804993b5d2fe0c90add9c9",
            "87c05a64fc134ba9af8653964182eb9f",
            "8b324efe46204a2c82ad250eb303976f",
            "ebefe5b597fd4f53afbb31ae5f128586",
            "8e7e1dffddf1446c84e42976c9b4accf",
            "75a3d492844e4de0b489c2664079ab77"
          ]
        },
        "id": "4exApbWyn6CJ",
        "outputId": "e67cf157-4c82-4f92-e730-5527af9ad7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for experiment: '131027_Ollama-llama3_DB-xt131028_v1-Nomic-embedding-651ff6ac' at:\n",
            "https://smith.langchain.com/o/6ee61aca-f04a-5cdf-9665-bb8fceaeb496/datasets/d657a3ef-050f-45a6-ac90-d3cc4877c030/compare?selectedSessions=b260b011-d8e9-4d13-b262-944d95b68265\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7cb89cf87404376ba7178926a6ac0fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.626s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.535s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.232s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.28s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.16s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.875s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.742s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.831s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.71s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.13s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 2s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 293abe80-0f95-483b-98d3-43bab0fbc337: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.998s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.998s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 2e53599d-f55d-42f9-9144-ef2ad8e51c7a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.705s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.705s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 7c1a7da2-27d6-4302-a27a-15d6791414fc: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.883s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.883s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 2ff60e6e-157e-4a2f-b3f8-1f5a98a87182: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.212s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.212s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 4fb4bb62-d45f-4c3d-8682-6e775076ef1f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.846s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.846s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 21a92931-de39-4cb4-9ac5-b5eb985c5355: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.773s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.773s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 8634424e-046b-491b-91b2-06d8c24fe0ed: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.922s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.922s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 44d19149-e899-4997-9ed5-2387691dd774: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.319999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.319999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run ba265189-bf24-4ef0-a678-ec6819a37676: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.947s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.947s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run f20ed0ab-87b1-4276-8c40-9ff032883607: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.845s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.845s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 8099607b-6449-4e39-bc69-2285f500f07d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.671s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.671s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run ff65c588-eade-4c05-85bf-4a1d1eca11d5: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.748s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.748s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 00b4d401-713e-4966-9d68-e52148439039: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.609999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.609999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 65279fe5-f3cd-4690-86aa-c2e84a73575e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.83s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.83s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 339a3f2a-d576-4da0-a4a8-d5ad03aae956: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.838s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.838s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b2ce6ef6-5de2-4458-b7a3-de93629899e4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.92s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.92s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run ac9b0f4c-3408-4228-a45e-0aa37f0f247e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.76s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.76s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 8c3a872d-2357-4dea-82db-4a0e48569436: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.794s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.794s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run a26c374b-96f5-4158-acd8-1f6a798aa90d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.758s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.758s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 25db5f0d-1335-4e45-b2db-d1504f005307: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.702s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.702s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 7e76d14f-84d0-423e-a1e0-0dca9eeb2191: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.743s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.743s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 70f0863b-ed8c-4730-b020-e09b3fc20d69: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.894s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.894s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 9c20a14f-7cb0-4f89-a942-c67e62aa4e31: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.819s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.819s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 0d21737a-af9d-43c2-97b0-0c32cb5b4bfa: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.792s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.792s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 7e56e799-fc4b-487b-b269-0fe25ed31845: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.826s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.826s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 7c664fad-1246-47fe-877f-e7ea8c7159f3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.177s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.177s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 72928bc6-047d-4aa2-ab83-811be686b8ff: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.966s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.966s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 60a86c03-e474-457b-aa98-83520bb9b41f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.692s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.692s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 09be868e-fb0c-49e6-af5c-af2b65fa403c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.655s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.655s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 7c151104-d947-457a-8154-d59309d55419: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.785s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.785s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 8830faa9-7573-45c0-86b2-1dab9022611d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.452999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1215, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 279, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 565, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 560, in wrapper\n",
            "    function_result = run_container[\"context\"].run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 257, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 219, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 179, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 148, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 378, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 163, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 153, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\", line 242, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\", line 178, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1194, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 896, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 972, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 1020, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\", line 987, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01hxghnbqnfmws4ygz7gy1k9aq` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.452999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n"
          ]
        }
      ],
      "id": "4exApbWyn6CJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 附件：AIA FAQ 測試資料"
      ],
      "metadata": {
        "id": "46wvt85OfSLx"
      },
      "id": "46wvt85OfSLx"
    },
    {
      "cell_type": "code",
      "source": [
        "# 註冊繳費\n",
        "question: 我已完成報名繳費,何時可以收到發票?\n",
        "answer: 個人用電子發票會於開學後第二週上課日由學務通知領取。公司報帳用電子發票會於開學後第二週由學務 mail 至學員報名時的電子信箱。若需提早或延後開立發票,請發信至hi@aiacademy.tw詢問。\n",
        "\n",
        "question: 我已過繳費期限?\n",
        "answer: 因原先繳費期限已過期,請發信至 hi@aiacademy.tw 並提供您的姓名及報名時填寫的電子郵件信箱。我們將會重新寄發{報名及註冊的登記已可進行下一步報名作業}信件至您的電子信箱。\n",
        "\n",
        "question: 註冊後,我選擇臨櫃匯款,該匯到哪裡?\n",
        "answer: 選擇臨櫃匯款者,請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw 提供您的姓名、報名課別、匯款單或匯款帳號後五碼,以利我們對帳後更新你的註冊狀態。\n",
        "\n",
        "question: 如何繳費?\n",
        "answer: 您好,請發信至 hi@aiacademy.tw 並提供您的姓名及報名時填寫的電子郵件信箱。我們會於系統更新你的審核狀態並重新寄發{報名及註冊的登記已可進行下一步報名作業}至您的電子信箱。若您報名的是經理人週末研修班或技術領袖全域班獲錄取者,請於收到錄取通知後 3 天內完成註冊繳費。繳費方式可選擇線上金流 (信用卡) 或臨櫃匯款。若選擇臨櫃匯款者,請匯款至 : 玉山銀行 南港分行 金融機構代碼：808 1182 戶名：財團法人台灣人工智慧學校基金會 帳號：1182-940-016585。\\n注意 : 選擇臨櫃匯款繳費的學員請務必於匯款完成後來信至 hi@aiacademy.tw 提供匯款單或匯款帳號後五碼,以利我們對帳後更新你的註冊狀態。\n",
        "\n",
        "# 退費\n",
        "question: 我要如何申請退費?\n",
        "answer: 很遺憾您無法與我們一起為接下來的課程努力。\\請您發信至hi@aiacademy.tw 提供您的班別跟姓名。 退費的標準,我們會依照學員手冊退費辦法辦理,後續也請提供你您帳號(含分行)資訊(存摺影本),以利我們後續匯款。謝謝\n",
        "\n",
        "question: 申請退費\n",
        "answer: 親愛的學員你好,很遺憾你無法與我們一起為接下來的課程努力。退費的標準,我們會依照學員手冊退費辦法辦理。此外,請將學員證與發票退回至行政人員,也請告知匯款帳戶,以利我們作業。\n",
        "\n",
        "# 請假\n",
        "question: 如何請假?\n",
        "answer: 若學員因故有請假需求,請填妥請假表單進行申請 https://reurl.cc/xZNOAL校務行政處核可後,系統將會直接寄送請假核可通知至您的信箱中。請假申請審核過後,仍計入缺席時數。本課程無補課機制。\n",
        "\n",
        "#報名\n",
        "question: 我的報名已過期?\n",
        "answer: 因原先報名連結已過期,請發信至 hi@aiacademy.tw 並提供您的姓名及報名時填寫的電子郵件信箱。我們將會重新寄發{報名及註冊的登記已可進行下一步報名作業}信件至您的電子信箱。\n",
        "\n",
        "question: 我是文科的人,我可以報名你們的課程嗎？\n",
        "answer: 我們非常歡迎不同產業的人進來,希望可以推動不同產業專業的人,能認識AI這些知識。\n",
        "\n",
        "#學費補助\n",
        "question: 請問你們有學費補助嗎？因為我看我們醫院有補助計畫,那如果你們這一期沒有,我是否可以轉下一期？\n",
        "answer: 我們學校沒有提供學費補助,應該是貴醫院單位的補助計畫,可能需要您與貴單位做內部確認,是否能申請院內補助,我本校無權涉入。\n",
        "\n",
        "#電腦\n",
        "question: 課程是否需要帶電腦?\n",
        "answer: 課程當中並沒有需要使用到電腦的部(除了工程技術類課程外),您可以依據自身上課需要攜帶筆電。\n",
        "\n",
        "#午餐\n",
        "question: 請問你們所有課程都有提供午餐嗎？\n",
        "answer: 因為我們的班別有經理人周末研修班、技術領袖全域班、智慧醫療專班和產業專班,目前只有經理人周末研修班/智慧醫療專班和產業專班有提供午餐。\n",
        "\n",
        "#結業\n",
        "question: 學員要通過那些門檻才會有結業證書？是否有課綱介紹？\n",
        "answer: 結業門檻等相關行政細節資訊列於學員手冊上,待開學當周會寄發給各位學員。課綱可以先參考官網 https://aiacademy.tw/\n",
        "\n",
        "#課程差別\n",
        "question: 醫療專班跟技術班還有經理人班的差別是？\n",
        "answer: 醫療專班：智慧醫療專班是台灣人工智慧學校為台灣醫療產業從業人員所設計的密集課程,期待透過智慧醫療專班,讓醫療產業從業人員能夠快速、系統化掌握人工智慧技術的最新趨勢,並徹底瞭解人工智慧如何運作,以及它的能力、侷限及未來發展,並能實際應用在醫療工作的每個場景。\\n智慧金融專班:\\n給予專班學員金融業全面性應用到的人工智慧知識,再透過實務議題、案例分享與場域實地參訪的印證,即時掌握智慧金融應用的趨勢。同時安排學員們進行深入的專題討論,將課堂傳授的知識運用於專題及實作,領略這些技術的實際應用方式及限制,以及進行學員間深入的交流學習。\\n經理人班：\\n經理人週末研修班是台灣人工智慧學校在技術領袖培訓班之後,第二個專門為台灣目前產業需求所設計的班別。我們預期透過經理人週末研修班,讓各產業的經理人能有一個場域,與不同產業的經理人一同學習及理解人工智慧的技術概觀,對於人工智慧技術能有全面性的大局觀,而且徹底瞭解人工智慧是如何運作的,以及它的能力、侷限及未來發展,才能讓產業欲以人工智慧進行產業升級時,能有清楚的方向感來帶領企業前進。\\n技術班：\\n技術領袖培訓班期為台灣育成具有人工智慧技術思維與實戰經驗的技術領袖人才,讓產業欲以人工智慧進行產業升級時,不再為缺乏人才所束縛。\n",
        "\n",
        "#師資\n",
        "question: 詢問智慧醫療專班師資\n",
        "answer: 台灣人工智慧學校提供專業的師資與課程,也安排醫界的先進前來授課,分享智慧醫療應用與案例的分享。希望能透過五週的課程,讓工作繁忙的醫師及護理相關人員,能快速、系統化掌握人工智慧技術的最新趨勢與發展應用能力,同時進行醫療實作案例分享。\\n學校將邀請中央研究院等學研單位及產業界,擁有豐富經驗與理論背景的講師,進行機器學習、深度學習、智慧生醫等重要的人工智慧核心技術與應用課程講授。\\n預計將培養上千位醫療產業從業人員,擁有定義問題、解決及場域導入方式等關鍵能力,並能實際應用在醫療工作上為全台醫療產業注入維持競爭力的能量。\\n本次北部醫療專班的師資\\n陳弘軒        國立中央大學 資工系副教授        機器學習\\n蔡炎龍        國立政治大學應用數學系副教授        深度學習\\n莊永裕        台大資工系 教授        電腦視覺\\n蔣榮先         成大資工系教授暨醫院健康數據中心執行長        智慧醫療應用\\n及其他醫界先進們,目前講師還在安排調整,官網只會放上課程大綱,待開課前會寄出學員手冊,裡面的課程表會有當期課程及講師,屆時再提供您參考\\n\n",
        "\n",
        "question: 詢問智慧製造專班師資\n",
        "answer: 台灣人工智慧學校提供專業的師資與課程,也安排了在製造業有深厚實務經驗的先進前來授課,分享智慧製造應用與案例的分享。希望能透過二天共七週的課程,讓來參與智慧製造課程的各位,能充份吸收並掌握人工智慧技術的最新趨勢與發展應用能力。\\n學校將邀請中央研究院等學研單位及產業界,擁有豐富經驗與理論背景的講師,進行機器學習、深度學習、智慧製造等重要的人工智慧核心技術與應用課程講授。\\n本次產業專班的師資\\n吳漢銘        國立政治大學統計學系副教授      資料科學與大數據分析\\n陳弘軒       國立中央大學 資工系副教授        機器學習與演算法概論\\n許懷中       逢甲大學資訊工程學系副教授     深度學習 \\n莊永裕       台大資工系 教授                          電腦視覺 \\n李家岩       國立臺灣大學資訊管理學系教授  智慧製造與生產線上的資料科學\\n智慧製造實務案例分享及應用,目前講師還在安排調整,官網只會放上課程大綱,待開課前會寄出學員手冊,裡面的課程表會有當期課程講義及授課講師,屆時再提供您參考\n",
        "\n",
        "question: 詢問經理人班師資\n",
        "answer: 台灣人工智慧學校提供專業的師資與課程,也安排有深厚實務經驗的先進前來授課,分享人工智慧的應用與案例的分享。希望能透過14週的課程,從基礎核心、實作學習到產業應用,讓來參與課程的學員,充份吸收並掌握人工智慧技術的最新趨勢與發展應用能力。   學校將邀請學研單位及產業界,擁有豐富經驗與理論背景的講師,進行機器學習、深度學習、電腦視覺、資料探勘等重要的人工智慧核心技術與應用課程講授。 本次經理人班的師資 吳漢銘 國立政治大學統計學系副教授 資料科學與大數據分析 陳弘軒 國立中央大學 資工系副教授 機器學習與演算法概論 蔡炎龍 國立政治大學應用數學系副教授 深度學習 莊永裕 國立臺灣大學資訊工程學教授 電腦視覺 陳宜欣 國立清華大學資訊工程學系教授 資料探勘 （學校保有修改、變更課程內容之權利）\\n以及業界先進產業案例的分享及應用。\\n官網只會放上課程大綱,待開課前會寄出學員手冊,登入學員專區裡面的課程表,會有當期課程講義及授課講師。\\n本次經理人班也加入AIGC實戰應用,學會使用相關工具如：ChatGPT、 Midjourney 等來生成文字與圖像,結合情境應用,有效減輕工作負擔,瞬間提升工作效率。\n",
        "\n",
        "#發票\n",
        "question: 學員發票什麼時候拿\n",
        "answer: 個人用電子發票會於開學後第二週上課日由學務通知領取。\\r公司報帳用電子發票會於開學後第二週由學務 mail 至學員報名時的電子信箱。\\r若需提早或延後開立發票,請發信至hi@aiacademy.tw詢問。發票部分,若有疑慮,請於五日內向校方反應。\\n電子發票會於今晚上傳財政部申報後,寄發至你的電子信箱中。\n",
        "\n",
        "#開學典禮\n",
        "question: 明天開學典禮我無法參加,需要請假嗎？\n",
        "answer: 開學典禮及結業典禮皆為課程時間,出缺席將計入缺席時數。若學員因故有請假需求,請填妥請假表單進行申請：https://reurl.cc/xZNOAL,並上傳證明文件,行政處核可後,系統將會直接寄送請假核可通知至您的信箱中。提醒您於下次上課時,攜帶有照片的證件,來領取學員證。\n",
        "\n",
        "question: 結業相關問題 我當天結業無法出席怎麼辦？\n",
        "answer: 開學典禮及結業典禮皆為課程時間,出缺席將計入缺席時數。若學員因故有請假需求,請填妥請假表單進行申請：https://reurl.cc/xZNOAL,並上傳證明文件,行政處核可後,系統將會直接寄送請假核可通知至您的信箱中。\n",
        "\n",
        "#退學\n",
        "question: 如果我退學了,我還可以登入專區進去看影片等教學相關素材嗎？\n",
        "answer: 這邊和您說聲抱歉。退學或是終止學員,將無法進入專區觀看相關影片,以維護其他學員的就學權益。\n",
        "\n",
        "#轉班\n",
        "question: 開學前申請轉班\n",
        "answer: 技術班轉經理人班,我們需要檢視您的職級職位作審核。經理人班轉技術班,我們會看您的背景及程式能立,方能決定是否安排入學考試。\n",
        "\n",
        "question: 開學後申請轉班\n",
        "answer: 1.除非特殊情況,依學員手冊規定,不許轉班\\n2.特殊情況的話(像是個人不可抗拒之因素),需要學員提出證明,學校方得受理 3.課程進行兩周之後,也不許轉班\n",
        "\n",
        "#補刷\n",
        "question: 如何補刷\n",
        "answer: 可使用報到處的平板補刷或是發信至hi@aiacademy.tw /私訊台灣人工智慧學校學務,並提供你的學號/姓名及補刷時間,即可。以上資訊供您參考,若您還有其他疑問也歡迎再與我們聯繫。\n",
        "\n",
        "#競賽\n",
        "question: 請問要結業的其中一項是繳交競賽的報告,若團隊中有人幾乎0互動,在現在幾乎是線上上課也只能線上互動的,好像完全沒有約束力\n",
        "answer: 請組長分配給所有組員該負責的任務,若有組員拒不合作,再請組長私訊告知,我們再去與該學員私下勸說。我們又會有組員互評機制。謝謝\n",
        "\n",
        "question: 請問每人需參與 AI 產業創新競賽？\n",
        "answer: 參加AI創新競賽是結業的其中一個門檻。\n",
        "\n",
        "#颱風\n",
        "question: 如果遇到颱風天,你們課程會順延嗎？\n",
        "answer: 如遇颱風天,本校活動、上課是否照常進行,將依行政院人事行政局公布之臺北市停班停課標準為主,相關消息將另行公告於官網、官方臉書。\n",
        "\n",
        "#學員證\n",
        "question: 我的學員證不見了,要申請,要怎麼給你們錢?\n",
        "answer: 您好,請發信至hi@aiacademy.tw 申請,以便我們作業紀錄登記；若您確定申請補發學員證,我們將製作好之後,會現場給您學員證+發票,屆時會與您收500元。\n",
        "\n",
        "#校友身分\n",
        "question: 如何核實校友身分?\n",
        "answer: 具備台灣人工智慧學校結業證書者。\n",
        "\n",
        "#學號\n",
        "question: 要如何查詢我的學號?\n",
        "answer: 請至官網,點選校友資源內的學號查詢即可。\n",
        "\n",
        "#結業證書\n",
        "question: 數位結業證書申請補發?\n",
        "answer: 申請證書,需收取500元申請費用,將開立發票,請提供發票寄件地址。\n",
        "\n",
        "question: 結業證書寄送問題\n",
        "answer: 學校將於結業典禮後㇐週內以電子郵件寄發圖靈數位證書至您提供的電子信箱\n",
        "\n",
        "question: 未收到數位結業證書?\n",
        "answer: 請至證書入口網站https://global.turingcerts.com/login (使用者登入)使用自己受訓登記的電子郵件註冊進入,即可看到自己證書。第一次登入需要先註冊,電子郵件以報名時的E-mail信箱。註冊後的登入頁面,雖然要求以手機號碼登入,但實質上是使用受訓登記的電子郵件進行登入~  可詳閱收證方使用手冊 https://taiwan-e-portfolio-alliance.gitbook.io/turing-certs-user-guidebook/\n",
        "\n",
        "\n",
        "#技術領袖全域班 入學考試\n",
        "question: 何時會寄發技術領袖全域班入學考試連結?\n",
        "answer: 技術領袖全域班考試連結會於考試前一天17:00前寄發連結並加發簡訊給應考者,線上入學考的連結於考試開始方可登入。\n",
        "\n",
        "question: 為何我未通過技術領袖全域班入學考試?\n",
        "answer: 謝謝您的來信。很遺憾您未通過技術領袖全域班入學考試。試題中,選擇題與程式題各佔50分,總分為100分,本期考生的程度都相當好,在參酌其他考生的成績後,我們會擇優錄取。\n",
        "\n",
        "question: 想報考技術領袖全域班,請問一下 有考古題嗎?\n",
        "answer: 我們沒有考古題。入學考目前focus在基礎的Python, 所以不管是坊間的參考書,或是學校官方網站的建議內容,應該都可以讓學員有能力通過入學考。謝謝\n",
        "\n",
        "question: 請問您們技術領袖全域班上課幾周? 總時數為?\n",
        "answer: 技術領袖全域班上課約十五周,為每周星期三、星期五和星期六,時間為早上 09:30到下午17:00,總計上課時數約 270小時。技術領袖全域班學員缺席達十分之一上課時數者,不予發給結業證書；您也可以參閱官網 https://aiacademy.tw/的招生訊息內的資訊。\n",
        "\n",
        "\n",
        "#產業專班\n",
        "question: 為何我未錄取產業專班?\n",
        "answer: 謝謝您的來信。由於報名實在太熱烈及踴躍、報考者都十分優秀,我們能錄取的考生非常有限,不免會有遺珠之憾,對於產業專班,校方希望提供給在職人士進修與推動產業轉型AI機會, 台灣人工智慧學校經理人班審查標準有二： 1. 從事AI相關工作經理人 2. 具備決策權與預算權的經理人 3. 若以上兩者符合,根據職稱高低以及公司產業別排序 非常的可惜未能錄取所有優秀的報考者,我們期待您未來的參與。建議報考者能就近多利用其他分校,希望及歡迎您報名其他分校或再次報考下一梯次的產業專班。\n",
        "\n",
        "#專題實作班\n",
        "question: 請問您們專題實作班上課幾周? 總時數為?\n",
        "answer: 專題實作班上課五周,為每周星期四和星期五晚間19:00到21:00,星期六時間為早上 09:00到下午17:00,總計上課時數約 46.5小時。您也可以參閱官網 https://aiacademy.tw/的招生訊息內的資訊。\n",
        "\n",
        "question: 關於【 NLP 專題實作班 】入學考試型式與範圍?\n",
        "answer: 關於入學考試型式與範圍概述如下：1. 選擇題 10-15 題 ： 機器學習 / 深度學習 / NLP / Python / PyTorch 之基礎概念 2. 手寫題 3 題 ： Python / PyTorch 不要求全對 /  有寫的要正確即可\\n以上請參考並保持平常心即可！\n",
        "\n",
        "question: 請問您們專題實作班上課幾周? 總時數為?\n",
        "answer: 產業專班上課七周,為每周星期五和星期六,時間為早上 09:00-到下午17:30,總計上課時數為 105小時。您也可以參考官網 https://aiacademy.tw/的招生訊息內的資訊。\n",
        "\n",
        "#智慧醫療專班結業門檻\n",
        "question: 結業門檻為何？\n",
        "answer: 智慧醫療專班學員需參與醫療專班創新競賽且缺席時數不超過15小時(含)即可取得結業證書。產業專班及經理人周末研修班學員需參與 AI 產業創新競賽且缺席時數不超過27小時(含)。\n",
        "\n",
        "question: 請問您們智慧醫療專班上課幾周? 總時數為?\n",
        "answer: 智慧醫療專班上課五周,為每星期六,時間為早上 09:30到下午18:00,總計上課時數為 37.5小時。您也可以參考官網 https://aiacademy.tw/的招生訊息內的資訊。\n",
        "\n",
        "question: 請問智慧醫療專班這門課有要求學員會哪一種程式語言嗎?謝謝\n",
        "answer: 智慧醫療專班這門課是為了要讓醫學相關領域的專業人士能更快速的掌握人工智慧的知識及資訊,而非專精於程式語言的學習。因此並無特別需要學會哪一種程式語言。相關的課程訊息也歡迎您參考：https://aiacademy.tw/curriculum-med/\\n若還有其他的疑問也歡迎與我們聯繫。\n",
        "\n",
        "\n",
        "#經理人週末研修班\n",
        "question: 為何我未錄取經理人週末研修班?\n",
        "answer: 謝謝您的來信。由於報名實在太熱烈及踴躍、報考者都十分優秀,我們能錄取的考生非常有限,不免會有遺珠之憾,對於經理人週末研修班,校方希望提供給在職人士進修與推動產業轉型AI機會, 台灣人工智慧學校經理人班審查標準有二： 1. 從事AI相關工作經理人 2. 具備決策權與預算權的經理人 3. 若以上兩者符合,根據職稱高低以及公司產業別排序 非常的可惜未能錄取所有優秀的報考者,我們期待您未來的參與。建議報考者能就近多利用其他分校,希望及歡迎您報名其他分校或再次報考下一梯次的經理人週末研修班。\n",
        "\n",
        "question: 經理人週末研修班需要考試或審核嗎？怎麼審核？審核標準是什麼?\n",
        "answer: 參加經理人週末研修班是不需要經過考試。但需要經過審核,審核的標準為 1. 從事AI相關工作經理人2. 具備決策權與預算權的經理人3. 若以上兩者符合,根據職稱高低排\n",
        "\n",
        "question: 請問您們經理人週末研修班上課幾週? 總時數為?\n",
        "answer: 經理人週末研修班上課十四週,為每週星期六,時間為早上 09:00到下午17:30,總計上課時數約 105小時。經理人週末研修班學員缺席達四分之一上課時數者,不予發給結業證書；您也可以參閱官網 https://aiacademy.tw/的招生訊息內的資訊。\n",
        "\n"
      ],
      "metadata": {
        "id": "Sepj2WQMfX_0"
      },
      "id": "Sepj2WQMfX_0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o_t8jTbWRds1",
        "Kiz6QzcXdbn8",
        "RcijGleDVhze",
        "rjrpVS-3ODZw",
        "tnGqEhkPy6d9",
        "46wvt85OfSLx"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7cb89cf87404376ba7178926a6ac0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c9a16d7cc6b4cd0b0769a0701178a89",
              "IPY_MODEL_092770d619964970bbe26d52a7d5f8bc",
              "IPY_MODEL_32629205012f4a44bccacfd54f276cf9"
            ],
            "layout": "IPY_MODEL_4cc08b1ed1074678ab3463cfa0d86e84"
          }
        },
        "6c9a16d7cc6b4cd0b0769a0701178a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1c30f165804993b5d2fe0c90add9c9",
            "placeholder": "​",
            "style": "IPY_MODEL_87c05a64fc134ba9af8653964182eb9f",
            "value": ""
          }
        },
        "092770d619964970bbe26d52a7d5f8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b324efe46204a2c82ad250eb303976f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebefe5b597fd4f53afbb31ae5f128586",
            "value": 1
          }
        },
        "32629205012f4a44bccacfd54f276cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e7e1dffddf1446c84e42976c9b4accf",
            "placeholder": "​",
            "style": "IPY_MODEL_75a3d492844e4de0b489c2664079ab77",
            "value": " 47/? [00:58&lt;00:00,  1.32it/s]"
          }
        },
        "4cc08b1ed1074678ab3463cfa0d86e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1c30f165804993b5d2fe0c90add9c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c05a64fc134ba9af8653964182eb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b324efe46204a2c82ad250eb303976f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ebefe5b597fd4f53afbb31ae5f128586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e7e1dffddf1446c84e42976c9b4accf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a3d492844e4de0b489c2664079ab77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}